Title	Description	Keywords	Dataset Type	Collection Period	Organism	Genes	Tissue/Cell Type	Condition	Technique	Instrument Platform	Software	Usage Restrictions	Related Datasets	Filename	User	Post ID	Likes
1000 Genomes Project	A deep catalog of human genetic variation.	genome sequencing variation human	Sequencing	2008-2015	Homo sapiens	All human genes			Next-Generation Sequencing	Illumina HiSeq	VCFtools BCFtools	Public			User1	1	0
American Gut Project	 A large-scale project to analyze the human microbiome.	microbiome gut bacteria human health	Sequencing	Ongoing	Homo sapiens	Microbial genes	Gut microbiome	Various human health conditions	16S rRNA sequencing metagenomics	Illumina MiSeq	QIIME VSEARCH	Public			User1	2	0
Jump Cell Painting	High-content imaging dataset to study cellular responses to various perturbations.	cell painting imaging phenotypes perturbations	Imaging	Ongoing	Human cell lines	Various	Human cell lines	Various perturbations	Cell Painting Assay	High-content imaging platforms	CellProfiler Cytominer	Public			User1	3	0
Cancer Cell Line Encyclopedia (CCLE)	A comprehensive genetic and pharmacologic characterization of a large panel of human cancer cell lines.	cancer cell lines genomics drug sensitivity	Genomics Transcriptomics Proteomics Metabolomics	Ongoing	Homo sapiens	Various cancer-related genes	Various cancer cell lines	Cancer	RNA sequencing microRNA profiling protein arrays genome-wide histone modification DNA methylation whole genome sequencing whole exome sequencing	Various high-throughput sequencing and profiling platforms	DepMap PRISM	DepMap Genomics of Drug Sensitivity in Cancer			User1	4	0
Ras-dependent activation of BMAL2 regulates hypoxic metabolism in pancreatic cancer	To identify drivers of malignancy in human pancreatic ductal adenocarcinoma (PDAC), we performed regulatory network analysis on a large collection of expression profiles from laser capture microdissected samples of PDAC and benign precursors. We discovered that BMAL2 plays a role in the initiation, progression, post resection survival, and KRAS activity in PDAC. Functional analysis of BMAL2 target genes led us to hypothe-size that it plays a role in regulating the response to hypoxia, a critical but poorly understood feature of PDAC physiology. Knockout of BMAL2 in multiple human PDAC cell lines revealed effects on viability and invasion, particularly under hypoxic conditions. Loss of BMAL2 also affected glycolysis and other metabolic processes. We found that BMAL2 directly regulates hypoxia-responsive target genes. We also found that BMAL2 is necessary for the stabilization of HIF1A upon exposure to hypoxia, but destabilizes HIF2A under hypoxia. These data demonstrate that BMAL2 is a master transcriptional regulator of hypoxia responses in PDAC and may serve as a long-sought molecular switch that distinguishes HIF1A- and HIF2A-dependent modes of hypoxic metabolism.  Statement of significanceWe provide a comprehensive portrait of the molecular drivers behind pancreatic cancer initiation, progression and outcome. We discover a new genetic regulator of metabolic responses to low oxygen environments, a key feature of pancreatic cancer biology. This protein, BMAL2, is a new driver of pancreatic cancer malignancy.	cancer_biology genes glycolysis pancreatic adenocarcinoma bmal2 metabolism activation cancer		2024-06-22								cc_by_nc_nd			Kenneth P Olive	5	0
Therapeutic targeting of ACLY in T-ALL in vivo	T-cell Acute Lymphoblastic Leukemia (T-ALL) is a hematological malignancy in need of novel therapeutic approaches. Here, we identify the ATP-citrate lyase ACLY as overexpressed and as a novel therapeutic target in T-ALL. To test the effects of ACLY in leukemia progression, we developed an isogenic model of NOTCH1-induced Acly conditional knockout leukemia. Importantly, we observed intrinsic antileukemic effects upon loss of ACLY, which further synergized with NOTCH1 inhibition in vivo. Metabolomic profiling upon ACLY loss revealed a metabolic crisis with reduced acetyl-CoA levels, as well as a decreased oxygen consumption rate. Gene expression profiling analyses showed that the transcriptional signature of ACLY loss very significantly correlates with the signature of MYC loss in vivo. Mechanistically, the decrease in acetyl-CoA led to reduced H3K27ac levels in Myc, resulting in transcriptional downregulation of Myc and drastically reduced MYC protein levels. Interestingly, our analyses also revealed a reciprocal relationship whereby ACLY itself is a direct transcriptional target of MYC, thus establishing a feedforward loop that is important for leukemia progression. Overall, our results identified a relevant ACLY-MYC axis and unveiled ACLY as a novel promising target for T-ALL treatment.	cancer_biology h3k27ac malignancy hematological therapeutic acly leukemia targeting vivo lymphoblastic		2024-06-20								cc_no			Daniel Herranz	6	0
Novel diagnosis- and progression-related microRNA signatures in melanoma	Melanoma, an aggressive skin cancer with a high mortality rate, has suffered from a recent increase in incidence; therefore, the search for biomarkers such as micro (mi)RNAs to aid the early detection and management of cancer patients represents a current concern.  To identify these potential biomarkers, we developed a novel and integrative strategy: we conducted a systematic review of melanoma studies following PRISMA guidelines and subsequently performed exploratory analysis and data normalization. Then, we performed individual analyses of each study followed by a miRNA meta-analysis that integrated all results while considering patient information.  In the diagnostic scenario, we unveiled twenty-four differentially expressed miRNAs - eleven upregulated and thirteen downregulated, with ten not previously directly related to the diagnosis of primary melanoma. In the ulceration scenario, we found twenty-three differentially expressed miRNAs - seven upregulated and sixteen downregulated, with thirteen not previously directly related to the diagnosis of primary melanoma. An extensive functional characterisation of these mirna signatures was carried out, providing insight into their biological role and impact on melanoma diagnosis and prognosis.  Our findings contribute to a better understanding of the molecular mechanisms and developmental processes involved in melanoma, mainly in early-stage development and ulceration, which, in turn, offers a means to develop novel resources for precisely detecting and treating melanoma.	cancer_biology microrna melanoma biomarkers ulceration novel diagnosis cancer signatures extensive		2024-06-21								cc_by_nc			Francisco Garcia-Garcia	7	0
Disruption of P2Y2 signaling promotes breast tumor cell dissemination by reducing ATP-dependent calcium elevation and actin localization to cell junctions	The tumor microenvironment and wound healing after injury both contain extremely high concentrations of the extracellular signaling molecule, adenosine triphosphate (ATP) compared to normal tissue. P2Y2 receptor, an ATP-activated purinergic receptor, is typically associated with pulmonary, endothelial, and neurological cell signaling. Here we report its role and importance in breast epithelial cell signaling and how it is altered in metastatic breast cancer. In response to ATP activation, P2Y2 receptor signaling causes an increase of intracellular Ca2+ in non-tumorigenic breast epithelial cells, while their tumorigenic and metastatic counterparts have significantly reduced Ca2+ responses. The non-tumorigenic cells respond to increased Ca2+ with actin polymerization and localization to cell edges, while the metastatic cells remained unaffected. The increase in intracellular Ca2+ after ATP stimulation was blunted using a P2Y2 antagonist, which also prevented actin mobilization and caused cell dissemination from spheroids in non-tumorigenic breast epithelial cells. Furthermore, the lack of Ca2+ concentration changes and actin mobilization in the metastatic breast cancer cells could be due to reduced P2Y2 expression, which correlates with poorer overall survival in breast cancer patients. This study elucidates rapid changes that occur after elevated intracellular Ca2+ in breast epithelial cells and how metastatic cancer cells have adapted to evade this cellular response.	cancer_biology endothelial breast tumorigenic p2y2 calcium reducing cancer tumor atp		2024-06-13								cc_no			Makenzy L Mull	8	0
A novel Nav1.5-dependent feedback mechanism driving glycolytic acidification in breast cancer metastasis	Solid tumours have abnormally high intracellular [Na+]. The activity of various Na+ channels may underlie this Na+ accumulation. Voltage-gated Na+ channels (VGSCs) have been shown to be functionally active in cancer cell lines, where they promote invasion. However, the mechanisms involved, and clinical relevance, are incompletely understood. Here, we show that protein expression of the Nav1.5 VGSC subtype strongly correlates with increased metastasis and shortened cancer-specific survival in breast cancer patients. In addition, VGSCs are functionally active in patient-derived breast tumour cells, cell lines, and cancer-associated fibroblasts. Knock down of Nav1.5 in a mouse model of breast cancer suppresses expression of invasion-regulating genes. Nav1.5 activity increases glycolysis in breast cancer cells, likely by up-regulating activity of the Na+/K+ ATPase, thus promoting H+ production and extracellular acidification. The pH of murine xenograft tumours is lower at the periphery than in the core, in regions of higher proliferation and lower apoptosis. In turn, acidic extracellular pH elevates persistent Na+ influx through Nav1.5 into breast cancer cells. Together, these findings show positive feedback between extracellular acidification and movement of Na+ into cancer cells which can facilitate invasion. These results highlight the clinical significance of Nav1.5 activity as a potentiator of breast cancer metastasis and provide further evidence supporting the use of VGSC inhibitors in cancer treatment.	cancer_biology glycolysis breast tumour tumours metastasis acidification fibroblasts cancer glycolytic		2024-06-13								cc_by			William J Brackenbury	9	0
Deep Visual Proteomics Unveils Precision Medicine Insights in Composite Small Lymphocytic and Classical Hodgkin Lymphoma	Coexistence of two cancer types in the same organ presents challenges for clinical decision-making, calling for personalized treatment strategies. Deep Visual Proteomics (DVP) combines AI driven single cell type analysis with laser microdissection and ultrasensitive mass spectrometry. In a composite case of classical Hodgkin lymphoma (cHL) and small lymphocytic lymphoma (SLL) in a single patient, we investigated the potential of DVP to inform precision oncology. We quantified the proteomic landscapes in the cHL and SLL to a depth of thousands of proteins. Our analysis revealed distinct proteome profiles in cHL and SLL populations, highlighting their clonal unrelatedness. Our data suggested standardized chemotherapy and interleukin-4 inhibition as potential strategies to manage chemo-resistance - instead of bone marrow transplantation. DVP highlighted minichromosome maintenance protein and proteasome inhibitors for cHL and H3K27 methylation and receptor tyrosine kinase inhibitors for SLL as subtype-specific treatments. Thus cell-type specific insights of DVP can guide personalized oncological treatments.	cancer_biology lymphoma oncology transplantation medicine hodgkin proteomics lymphocytic chemotherapy cancer		2024-06-13								cc_by_nd			Matthias Mann	10	0
KDM2B is required for ribosome biogenesis and its depletion unequally affects mRNA translation	KDM2B is a JmjC domain lysine demethylase, which promotes cell immortalization, stem cell self-renewal and tumorigenesis. Here we employed a multi-omics strategy to address its role in ribosome biogenesis and mRNA translation. These processes are required to sustain cell proliferation, an important cancer hallmark. Contrary to earlier observations, KDM2B promotes ribosome biogenesis by stimulating the transcription of genes encoding ribosome biogenesis factors and ribosomal proteins, particularly those involved in the biogenesis of the 40S ribosomal subunits. Knockdown of KDM2B impaired the assembly of the small and large subunit processomes, as evidenced by specific defects in pre-ribosomal RNA processing. The final outcome was a decrease in the rate of ribosome assembly and in the abundance of ribosomes, and inhibition of mRNA translation. The inhibition of translation was distributed unequally among mRNAs with different features, suggesting that mRNA-embedded properties influence how mRNAs interpret ribosome abundance. This study identified a novel mechanism contributing to the regulation of translation and provided evidence for a rich biology elicited by a pathway that depends on KDM2B, and perhaps other regulators of translation.	cancer_biology biology tumorigenesis ribosomal biogenesis depletion mrna ribosome cancer kdm2b		2024-06-06								cc_by_nc_nd			Vollter Anastas	11	0
The Universal Breast cancer Subtyping 93 finds that claudin-low breast cancer may originate from basal breast cancer.	BackgroundBreast cancer is a complex disease with diverse molecular characteristics, significantly impacting patient prognosis, outcomes, and treatment decisions. Previous studies have introduced PAM50 classifiers and claudin-low classifiers based on bulk RNA-seq samples. However, single-cell analysis has revealed the existence of distinct subtypes within the same tumor, indicating that classifiers relying on gene signatures derived from bulk samples may not accurately capture the true molecular features of breast cancer.  MethodTo address this limitation, we utilized single-cell data from breast cancer patients to define the E-M ratio parameter. We identified 93 epithelial-specific genes and developed a Universal Breast cancer Subtyping 93 (UBS93). To validate the efficacy of UBS93, we conducted separate analyses using bulk RNA-seq and single-cell RNA-seq datasets of human breast cancer cell lines, as well as bulk RNA-seq data from mice. Additionally, we compared the performance of UBS93 with that of the genefu package to highlight its advantages.  ResultsUBS93 demonstrated excellent performance in human and mouse datasets, including bulk RNA-seq and single-cell RNA-seq data. It exhibited higher epithelial specificity and accuracy compared to PAM50 genes. When predicting bulk RNA-seq data from breast cancer cell lines and mouse models, UBS93 outperformed the genefu package. Single-cell validation revealed the coexistence of basal and claudin-low subtypes in the HDQP1 cell line and two TNBC patients, suggesting a shared origin. Differential gene expression analysis identified ELF3 loss as a potential driver for basal-to-claudin-low differentiation. Experimental validation confirmed that the downregulation of ELF3 resulted in the downregulation of CLDN3, CLDN4, and CLDN7, facilitating the transition from basal to claudin-low cells.  ConclusionOur study constructed a comprehensive breast cancer classification, UBS93, based on 93 epithelial-specific genes identified using single-cell data. By applying UBS93, we unveiled the coexistence of basal and claudin-low subtypes and illuminated the molecular mechanism underlying basal-to-claudin-low differentiation, with ELF3 loss playing a significant role in this process.  BackgroundBreast cancer is a heterogeneous disease in terms of molecular alterations, cellular composition, and clinical outcomes. However, this heterogeneity poses challenges regarding clinically relevant tumor classification for prognosis and prediction [36931265] [1]. Fortunately, researchers have utilized microarray technology to develop an intrinsic breast cancer classifier called PAM50, which categorizes cancer into five subtypes: Luminal A, Luminal B, HER2-enriched, Basal-like, and Normal-like [19204204] [2]. This classification system significantly enhances the prognostic and predictive value over traditional approaches, including pathological staging, histological grading, and standard clinical biomarkers.  Through in-depth investigation of gene expression profiles in breast cancer, researchers have discovered a novel subtype characterized by low expression levels of cell adhesion components such as CLDN3, CLDN4, CLDN7, and CDH1, which is associated with mesenchymal features. This new subtype exhibits increased proliferative capacity and poorer prognosis [17493263] [3]. In response, Alexi et al. developed a classification method called the nine-cell line claudin-low predictor, categorizing breast cancer into two groups: Claudin-low and Others [20813035] [4]. However, the origin of this new subtype has been a subject of ongoing debate. Some researchers suggest that the occurrence and progression of triple-negative breast cancer from luminal epithelium are driven by carcinogenic RAS signal transduction., although this conclusion has yet to be validated in human data [34145248] [5]. Another study, based on genetic, epigenetic, and gene expression analyses, found that claudin-low breast cancer originates from three subgroups, with two subgroups associated with luminal and basal-like subtypes, and the third subgroup closely related to normal human breast stem cells [32647202] [6]. In conclusion, the origin of claudin-low breast cancer is a complex process that requires further research to explore the underlying mechanisms and contributing factors.  Single-cell transcriptomic analysis has provided us with deeper insights into the heterogeneity among different subtypes of breast cancer [35352511] [7]. By analyzing the intrinsic subtypes within individual malignant cells, it has been discovered that there exist cells of different subtypes within a single tumor. This indicates that the tumor subtypes defined by gene signatures obtained through bulk RNA sequencing may not always accurately reflect the true molecular phenotype of the tumor [36931265][1]. To gain a more comprehensive understanding of tumor cells, single-cell analysis is necessary. Additionally, there is a lack of standardized prediction for breast cancer subtypes. To address these issues, we have developed a novel epithelial cell-specific prediction factor called Universal Breast Cancer Subtyping 93 (UBS93). UBS93 classifies breast cancer into four subtypes: Basal, Claudin-low, HER2-amp, and Luminal. UBS93 focuses on epithelial-specific markers and aims to provide a more consistent and comprehensive approach for breast cancer subtype classification. This advancement holds the potential to improve the accuracy of classification, facilitate personalized treatment strategies, and guide clinical decision-making.	cancer_biology genetic biomarkers breast 93 claudin carcinogenic subtyping cancer tumor		2024-06-06								cc_no			Jing Li	12	0
An organoid co-culture model for probing systemic anti-tumor immunity in lung cancer	"Deciphering the interactions between tumor micro- and systemic immune macro-environment is essential for developing more effective cancer diagnosis and treatment strategies. Here, we established a gel-liquid interface (GLI) co-culture of lung cancer organoids (LCOs) and paired peripheral blood mononuclear cells (PBMCs), featuring with enhanced interactions of immune cells and tumor organoids, to mimic the in vivo systemic anti-tumor immunity induced by immune checkpoint inhibitors (ICI). The co-culture model recapitulates the in vivo ICI-induced T cell recruitment and subsequent tumor regression, predicting the clinical results precisely. We demonstrated that circulating tumor-reactive T cells, which are effector memory-like with high expression levels of GNLY, CD44 and CD9, can serve as an indicator of the immunotherapy efficacy. Interestingly, enhanced inflammatory signaling in blood T cells is accompanied with prompted exhaustion and compromised anti-tumor function, when encountering with organoids. Our findings suggest that the GLI co-culture can be used for developing diagnostic strategies for precision immunotherapies as well as understanding the underlying mechanisms.  Summary figure  O_FIG O_LINKSMALLFIG WIDTH=178 HEIGHT=200 SRC=""FIGDIR/small/597327v1_ufig1.gif"" ALT=""Figure 1""> View larger version (48K): org.highwire.dtl.DTLVardef@a0829dorg.highwire.dtl.DTLVardef@1df3083org.highwire.dtl.DTLVardef@1ea1065org.highwire.dtl.DTLVardef@1da9464_HPS_FORMAT_FIGEXP  M_FIG C_FIG"	cancer_biology immunotherapies lung 1da9464_hps_format_figexp systemic organoid immunotherapy cancer tumor		2024-06-06								cc_no			Peng Liu	13	0
Comprehensive single cell transcriptomics analysis of murine osteosarcoma uncovers Skp2 function in metastasis, genomic instability and immune activation and reveals additional target pathways	Osteosarcoma (OS) is the most common primary pediatric bone malignancy. One promising new therapeutic target is SKP2, encoding a substrate recognition factor of the SCF E3 ubiquitin ligase responsible for ubiquitination and proteasome degradation of substrate p27, thus driving cellular proliferation. We have shown previously that knockout of Skp2 in an immunocompetent transgenic mouse model of OS improved survival, drove apoptosis, and induced tumor inflammation. Here, we applied single-cell RNA-sequencing (scRNA-seq) to study primary OS tumors derived from Osx-Cre driven conditional knockout of Rb1 and Trp53. We showed that murine OS models recapitulate the tumor heterogeneity and microenvironment complexity observed in patient tumors. We further compared this model with OS models with functional disruption of Skp2: one with Skp2 knockout and the other with the Skp2-p27 interaction disrupted (resulting in p27 overexpression). We found reduction of T cell exhaustion and upregulation of interferon activation, along with evidence of replicative and endoplasmic reticulum-related stress in the Skp2 disruption models, and showed that interferon induction was correlated with improved survival in OS patients. Additionally, our scRNA-seq analysis uncovered decreased activities of metastasis-related gene signatures in the Skp2-disrupted OS, which we validated by observation of a strong reduction in lung metastasis in the Skp2 knockout mice. Finally, we report several potential mechanisms of escape from targeting Skp2 in OS, including upregulation of Myc targets, DNA copy number amplification and overexpression of alternative E3 ligase genes, and potential alternative lineage activation. These mechanistic insights into OS tumor biology and Skp2 function suggest novel targets for new, synergistic therapies, while the data and our comprehensive analysis may serve as a public resource for further big data-driven OS research.	cancer_biology biology dna cell metastasis transcriptomics tumors osteosarcoma tumor genomic		2024-06-06								cc_by_nc_nd			Deyou Zheng	14	0
Up-regulated transcriptional regulators in mutant RAS gene signatures: a time-resolved multi-omics study in generic epithelial cell models	The expression of mutated RAS genes drives extensive transcriptome alterations. Perturbation experiments have shown that the transcriptional responses to downstream effector pathways are partially unique and non-overlapping, suggesting a modular organization of the RAS-driven expression program. However, the relationship between individual deregulated transcription factors and the entire cancer cell-specific genetic program is poorly understood. To identify potential regulators of the RAS/MAPK-dependent fraction of the genetic program, we monitored transcriptome and proteome changes following conditional, time-resolved expression of mutant HRASG12V in human epithelial cells during neoplastic conversion. High mobility group AT hook2 (HMGA2), an architectural chromatin modulating protein and oncofetal tumour marker, was recovered as the earliest upregulated transcription factor. Knock-down of HMGA2 reverted anchorage-independent growth and epithelial-mesenchymal transition not only in HRAS-transformed cells but also in an independent, KRASG12V-driven rat epithelial model. Moreover, HMGA2 silencing reverted the deregulated expression of 60% of RAS-responsive target genes. These features qualify HMGA2 as a master regulator of mutant RAS-driven expression patterns. The delayed deregulation of FOSL1, ZEB1 and other transcription factors with known oncogenic activity suggests that HMGA2 acts in concert with a network of regulatory factors to trigger full neoplastic conversion. Although transcription factors are considered difficult to drug, the central role of HMGA2 in the transcription factor network as well as its relevance for cancer prognosis has motivated attempts to block its function using small molecular weight compounds. The further development of direct HMGA2 antagonists may prove useful in cancer cells that have developed resistance to signalling chain inhibition.	cancer_biology genes genetic epithelial transcriptome cancer tumour cell gene mutant transcriptional		2024-06-06								cc_no			Reinhold Schäfer	15	0
Mechanical compressive forces increase PI3K output signaling in breast and pancreatic cancer cells	ContextMechanical stresses, including compression, arise during cancer progression. In solid cancer, especially breast and pancreatic cancers, the rapid tumor growth and the environment remodeling explain their high intensity of compressive forces. However, the sensitivity of compressed cells to targeted therapies remains poorly known.  ResultsIn breast and pancreatic cancer cells, pharmacological PI3K inactivation decreased cell number and induced apoptosis. These effects were accentuated when we applied 2D compression forces in mechanically responsive cells. Compression selectively induced overexpression of PI3K isoforms and PI3K/AKT pathway activation. Further, transcriptional effects of PI3K inhibition and compression converged to control the expression of an autophagy regulator, GABARAP, which level was inversely associated with PI3K inhibitor sensitivity under compression. Compression alone blocked autophagy flux in all tested cells, while inactivation of basal PI3K activity restored autophagy flux only in mechanically non-responsive compressed cells.  ConclusionThis study provides direct evidence for the role of PI3K/AKT pathway in compression-induced mechanotransduction. PI3K inhibition promotes apoptosis or autophagy, explaining PI3K importance to control cancer cell survival under compression.	cancer_biology breast pancreatic pi3k remodeling cancers cells cancer tumor		2024-05-30								cc_no			Julie  Guillermet-Guibert	16	0
KDM2B is required for ribosome biogenesis and its depletion unequally affects mRNA translation	KDM2B is a JmjC domain lysine demethylase, which promotes cell immortalization, stem cell self-renewal and tumorigenesis. Here we employed a multi-omics strategy to address its role in ribosome biogenesis and mRNA translation. These processes are required to sustain cell proliferation, an important cancer hallmark. Contrary to earlier observations, KDM2B promotes ribosome biogenesis by stimulating the transcription of genes encoding ribosome biogenesis factors and ribosomal proteins, particularly those involved in the biogenesis of the 40S ribosomal subunits. Knockdown of KDM2B impaired the assembly of the small and large subunit processomes, as evidenced by specific defects in pre-ribosomal RNA processing. The final outcome was a decrease in the rate of ribosome assembly and in the abundance of ribosomes, and inhibition of mRNA translation. The inhibition of translation was distributed unequally among mRNAs with different features, suggesting that mRNA-embedded properties influence how mRNAs interpret ribosome abundance. This study identified a novel mechanism contributing to the regulation of translation and provided evidence for a rich biology elicited by a pathway that depends on KDM2B, and perhaps other regulators of translation.	cancer_biology biology tumorigenesis ribosomal biogenesis depletion mrna ribosome cancer kdm2b		2024-05-30								cc_by_nc_nd			Vollter Anastas	17	0
WITHDRAWN: Dual targeting of mitochondrial Lon peptidase 1 and chymotrypsin-like protease by small molecule BT317, as potential therapeutics in malignant astrocytoma	Withdrawal StatementThe authors have withdrawn their manuscript owing to massive revision and data validation. Therefore, the authors do not wish this work to be cited as reference for the project. If you have any questions, please contact the corresponding author.	revision cancer_biology withdrawal chymotrypsin peptidase protease authors mitochondrial manuscript withdrawn astrocytoma		2024-05-23								cc_by_nd			Daniela Bota	18	0
WITHDRAWN: LonP1 Drives Proneural Mesenchymal Transition in IDH1-R132H Diffuse Glioma	Withdrawal StatementThe authors have withdrawn their manuscript owing to massive revision and data validation. Therefore, the authors do not wish this work to be cited as reference for the project. If you have any questions, please contact the corresponding author.	mesenchymal revision cancer_biology withdrawal glioma lonp1 authors manuscript r132h withdrawn		2024-05-23								cc_by_nd			Daniela Bota	19	0
KRAS-mediated upregulation of CIP2A promotes suppression of PP2A-B56α to initiate pancreatic cancer development	Oncogenic mutations in KRAS are present in approximately 95% of patients diagnosed with pancreatic ductal adenocarcinoma (PDAC) and are considered the initiating event of pancreatic intraepithelial neoplasia (PanIN) precursor lesions. While it is well established that KRAS mutations drive the activation of oncogenic kinase cascades during pancreatic oncogenesis, the effects of oncogenic KRAS signaling on regulation of phosphatases during this process is not fully appreciated. Protein Phosphatase 2A (PP2A) has been implicated in suppressing KRAS-driven cellular transformation. However, low PP2A activity is observed in PDAC cells compared to non-transformed cells, suggesting that suppression of PP2A activity is an important step in the overall development of PDAC. In the current study, we demonstrate that KRASG12D induces the expression of both an endogenous inhibitor of PP2A activity, Cancerous Inhibitor of PP2A (CIP2A), and the PP2A substrate, c-MYC. Consistent with these findings, KRASG12D sequestered the specific PP2A subunit responsible for c-MYC degradation, B56, away from the active PP2A holoenzyme in a CIP2A-dependent manner. During PDAC initiation in vivo, knockout of B56 promoted KRASG12D tumorigenesis by accelerating acinar-to-ductal metaplasia (ADM) and the formation of PanIN lesions. The process of ADM was attenuated ex vivo in response to pharmacological re-activation of PP2A utilizing direct small molecule activators of PP2A (SMAPs). Together, our results suggest that suppression of PP2A-B56 through KRAS signaling can promote the MYC-driven initiation of pancreatic tumorigenesis.	cancer_biology tumorigenesis cip2a pancreatic cancerous adenocarcinoma b56α pp2a metaplasia cancer		2024-05-23								cc_by_nc_nd			Brittany Allen-Petersen	20	0
The Hidden Potential of PDE4 Inhibitor Rolipram: A Multifaceted Examination of its Inhibition of MMP2/9 Reveals Therapeutic Implications	A PDE4 inhibitor, Rolipram, was previously found to down-regulate (in a manner dependent on cAMP-PKA) MMP2 and MMP9 levels, important markers of epithelial-to-mesenchymal transition in human breast cancer cell lines. However, zymographic studies revealed that rolipram could also alter the enzymatic activities of these MMPs, even in the presence of the PKA inhibitor H89. This calls for more detailed investigations of the inhibitory mechanism of rolipram on MMP2 and MMP9. The prediction of ligand-based targets through online reverse screening indicated that proteases are likely targets of rolipram. Computational molecular docking also demonstrated significant binding affinities of rolipram for both MMP2 and MMP9 proteins. Concurrently, a well-known inhibitor of MMPs, SB3CT, was utilized as a positive control for this study. The best models of the docked complexes were used as initial conditions for molecular dynamics (MD) simulations to explore their dynamic behavior and stability. In particular, both the MMP2-rolipram and MMP9-rolipram complexes were found to be stable and compact for the duration of the simulation (300 ns). Several stable hydrogen bonds were also detected between the proteins and rolipram. In vitro experiments using primary cells from patients with breast cancer also showed that rolipram could alter the enzymatic activities of MMP2 and MMP9, independent of the cAMP-PKA signaling pathway. These observations indicate the ability of rolipram to control breast cancer by regressing the functions of MMP2 and MMP9, thus having  off-targets other than PDE4 to have direct control over proteins that are involved in the advancement of metastasis.	cancer_biology examination epithelial therapeutic rolipram metastasis inhibitor ligand cancer pde4		2024-05-23								cc_by			Arunima Biswas	21	0
Biological activity of a stable 6-aryl-2-benzoyl-pyridine colchicine-binding site inhibitor, 60c, in metastatic, triple-negative breast cancer	BackgroundImproving survival for patients diagnosed with metastatic disease and overcoming chemoresistance remain significant clinical challenges in treating breast cancer. Triple-negative breast cancer (TNBC) is an aggressive subtype characterized by a lack of therapeutically targetable receptors (ER/PR/HER2). TNBC therapy includes a combination of cytotoxic chemotherapies, including microtubule-targeting agents (MTAs) like paclitaxel (taxane class) or eribulin (vinca class); however, there are currently no FDA-approved MTAs that bind to the colchicine-binding site. Approximately 70% of patients who initially respond to paclitaxel will develop taxane resistance (TxR). We previously reported that an orally bioavailable colchicine-binding site inhibitor (CBSI), VERU-111, inhibits TNBC tumor growth and treats pre-established metastatic disease. To further improve the potency and metabolic stability of VERU-111, we created next-generation derivatives of its scaffold, including 60c.  Results60c shows improved in vitro potency compared to VERU-111 for taxane-sensitive and TxR TNBC models, and suppress TxR primary tumor growth without gross toxicity. 60c also suppressed the expansion of axillary lymph node metastases existing prior to treatment. Comparative analysis of excised organs for metastasis between 60c and VERU-111 suggested that 60c has unique anti-metastatic tropism. 60c completely suppressed metastases to the spleen and was more potent to reduce metastatic burden in the leg bones and kidney. In contrast, VERU-111 preferentially inhibited liver metastases and lung metastasis repression was similar. Together, these results position 60c as an additional promising CBSI for TNBC therapy, particularly for patients with TxR disease.	cancer_biology breast cancer lymph disease benzoyl fda biological metastatic tumor		2024-05-23								cc_no			Wei Li	22	0
KDM2B is required for ribosome biogenesis and its depletion unequally affects mRNA translation	KDM2B is a JmjC domain lysine demethylase, which promotes cell immortalization, stem cell self-renewal and tumorigenesis. Here we employed a multi-omics strategy to address its role in ribosome biogenesis and mRNA translation. These processes are required to sustain cell proliferation, an important cancer hallmark. Contrary to earlier observations, KDM2B promotes ribosome biogenesis by stimulating the transcription of genes encoding ribosome biogenesis factors and ribosomal proteins, particularly those involved in the biogenesis of the 40S ribosomal subunits. Knockdown of KDM2B impaired the assembly of the small and large subunit processomes, as evidenced by specific defects in pre-ribosomal RNA processing. The final outcome was a decrease in the rate of ribosome assembly and in the abundance of ribosomes, and inhibition of mRNA translation. The inhibition of translation was distributed unequally among mRNAs with different features, suggesting that mRNA-embedded properties influence how mRNAs interpret ribosome abundance. This study identified a novel mechanism contributing to the regulation of translation and provided evidence for a rich biology elicited by a pathway that depends on KDM2B, and perhaps other regulators of translation.	cancer_biology biology tumorigenesis ribosomal biogenesis depletion mrna ribosome cancer kdm2b		2024-05-23								cc_by_nc_nd			Vollter Anastas	23	0
Spatial Profiling of Metals through Matrix-Assisted Laser Desorption Ionization Mass Spectrometry Imaging	The spatial-omic analysis of biomolecules such as nucleic acids, lipids, metabolites, and proteins is advancing the study of biological systems and processes in a physio-pathological context. Here, we describe an innovative matrix-assisted laser desorption ionization mass spectrometry imaging (MALDI MSI) method to detect metals within biological tissues using instrumentation that is widely available in research and clinical laboratories. We characterize the spatial distribution of metals in diverse settings including mouse embryogenesis, genetic disorders leading to abnormal metal accumulation, and preclinical testing for improved platinum-based chemotherapy delivery through focused ultrasound across the blood-brain barrier. Spatial metal profiling will advance research studies and the clinical analysis of metal-related diseases, enabling more precise use of metal-based therapies and advances in diverse scientific fields beyond biomedicine.  One-Sentence SummarySpatial metallomic profiling maps native metals or those coordinated to xenobiotics, antibodies, and biomolecules in tissues.	cancer_biology metals biomolecules spectrometry imaging biomedicine laboratories laser ionization		2024-05-23								cc_no			Nathalie Agar	24	0
Super-Enhancer Driven ZFP36L1 Promotes PD-L1 Expression in Infiltrative Gastric Cancer	Gastric cancer (GC) is a major cause of cancer-related mortality worldwide. Despite the widespread recognition of tumor immunotherapy in treating unresectable GC, challenges, including ineffective immunotherapy and drug resistance, persist. Therefore, understanding the regulatory mechanisms of PD-L1, particularly in the context of super-enhancers (SEs) and zinc finger protein 36 ring finger protein-like 1 (ZFP36L1) RNA-binding protein, is crucial.  MethodsIn this study, we performed H3K27ac CUT&Tag sequencing, investigated the heterogeneity of SEs between two GC subtypes with differential growth patterns, and revealed the immune escape signatures driven by ZFP36L1-SE in infiltrative GC through SEs inhibitors treatment. The regulation of ZFP36L1 to PD-L1 was evaluated by quantitative PCR, western blot, flow cytometry and immunohistochemistry. Furthermore, we explored its regulatory mechanisms using a combination of molecular biology techniques, including luciferase reporter assay, GST/RNA pull-down, ChIP/RIP experiments, and in vivo functional assays.  ResultsWe demonstrated that ZFP36L1, driven by an SE, enhances IFN-{gamma}-induced PD-L1 expression, with SPI1 identified as the specific transcription factor binding to ZFP36L1-SE. Mechanistically, ZFP36L1 binds to the adenylate uridylate-rich element in the 3'UTR of HDAC3 mRNA, exacerbating its mRNA decay, and thereby facilitating PD-L1 abnormal transcriptional activation.  ConclusionsCollectively, our findings provide mechanistic insights into the role of the SPI1- ZFP36L1-HDAC3-PD-L1 signaling axis in orchestrating immune escape mechanisms in GC, thereby offering valuable insights into the potential targets for immune checkpoint therapy in GC management.	cancer_biology cancer infiltrative zfp36l1 exacerbating enhancer immunohistochemistry immunotherapy gastric tumor		2024-05-23								cc_by			Jianchun Cai	25	0
Development of fluoro-7-aminocarboxycoumarin-based mitochondrial pyruvate carrier inhibitors as anticancer agents	Reprogrammed metabolism of cancer cells offers a unique target for pharmacological intervention. In the current study, a series of novel and potentially metabolically stable fluoro-substituted aminocarboxycoumarin derivatives are evaluated for their mitochondrial pyruvate carrier (MPC) inhibition properties. Our studies indicate that the aminocarboxycoumarin template elicits potent MPC inhibitory characteristics, and specifically, structure activity relationship studies show that the N-methyl-N-benzyl structural template provides the optimal inhibitory capacity. Further respiratory experiments demonstrate that candidate compounds specifically inhibit pyruvate driven respiration without substantially affecting other metabolic fuels consistent with MPC inhibition. Further, computational homology and inhibitor docking studies illustrate that aminocarboxycoumarin binding characteristics are indicative of reversible covalent bonding with amino acids in the pyruvate binding domain. Epifluorescent microscopy experiments illustrated that FACC2 accumulates in the mitochondria to a similar extent as parent 7ACC2. Additionally, lead candidate aminocarboxycoumarin derivative D7 elicits cancer cell proliferation inhibition specifically in monocarboxylate transporter 1 (MCT1) expressing 4T1, consistent with its ability to accumulate intracellular lactate. In vivo tumor growth studies illustrate that D7 significantly reduces the tumor burden in two isogeneic murine cell lines 4T1 and 67nr. These studies provide novel MPC inhibitors with potential for anticancer applications.	cancer_biology mitochondria pyruvate aminocarboxycoumarin anticancer mitochondrial inhibitors pharmacological cancer tumor		2024-05-23								cc_no			Venkatram R Mereddy	26	0
Green Jackfruit Flour Prevents Metabolic Dysfunction-Associated Steatohepatitis and Progression to Hepatocellular Carcinoma via the AMPK and MAPK Signaling Pathways	Metabolic dysfunction-associated steatotic liver disease (MASLD), encompassing metabolic-dysfunction associated steatotic liver (MAFL) and steatohepatitis (MASH), which further progresses to hepatocellular carcinoma (HCC), is a serious public health concern. Given the paucity of approved therapeutic strategies for this lifestyle disorder, dietary interventions may prove effective. We evaluated how green jackfruit flour (JF) prevents MASH and progression to HCC and its underlying mechanisms. The study utilized two murine models that mimicked human MASLD disease: (i) a diet-induced MASH model; (ii) a MASH-HCC model induced by diet and a very low dose of CCl4. C57Bl/6 mice were fed with chow (CD) or western diet (WD) with normal (NW) or sugar water (SW) for 12 weeks, then randomized to receive either 5 kcal% green jackfruit flour (JF) or an equal volume of placebo flour (PB). The biochemical, histological, and molecular analyses were assessed. JF significantly reduced body weight, liver injury, insulin resistance, and alleviated obesity, steatosis, inflammation, fibrosis, and tumor development in WDSW or WDSW/CCl4 mice compared to placebo groups. Furthermore, JF activated AMPK (AMP-activated protein kinase) and inhibited MAPK (mitogen-activated protein kinase) signaling pathways in MASH and MASH-HCC experimental models, respectively. This was supported by sodium propionate treatment, the primary short-chain fatty acid entering the liver from JFs soluble fiber microbial fermentation, which also regulated AMPK and MAPK signaling in cellular models of MASH and HCC, respectively. Hence, our findings present strong evidence of JFs therapeutic potential in the prevention of MASH and MASH-HCC, warranting further investigation of JFs efficacy as a dietary intervention in clinical trials.	metabolic fibrosis cancer_biology flour obesity carcinoma green liver steatohepatitis		2024-05-23								cc_no			Divya P. Kumar	27	0
Therapeutic potential of SOX9 dysruption in Combined Hepatocellular Carcinoma-Cholangiocarcinoma	Combined hepatocellular carcinoma-cholangiocarcinoma (cHCC-CCA) represents a challenging subtype of primary liver cancer with limited treatment options and a poor prognosis. Recently, we and others have highlighted the context-dependent roles of the biliary-specific transcription factor SOX9 in the pathogenesis of liver cancers using various Cre applications in Sox9(flox/flox) strains, to achieve elimination for exon 2 and 3 of the Sox9 gene locus as a preventive manner. Here, we reveal the contrasting responses of developmental Sox9 elimination using Alb-Cre;Sox9(flox/flox) (Sox9 LKO) versus CRISPR/Cas9-based tumor specific acute Sox9 CKO in SB-HDTVI-based Akt-YAP1 and Akt-NRAS cHCC-CCA formation. Sox9 LKO specifically abrogates the Akt-YAP1 CCA region while robustly stimulating the proliferation of remaining poorly differentiated HCC pertaining liver progenitor cell characteristics, whereas Sox9 CKO potently prevents Akt-YAP1 and Akt-NRAS cHCC-CCA development irrespective of fate of tumor cells compared to respective controls. Additionally, we find that Akt-NRAS, but not Akt-YAP1, tumor formation is partially dependent on the Sox9-Dnmt1 cascade. Pathologically, SOX9 is indispensable for Akt-YAP1-mediated HC-to-BEC/CCA reprogramming but required for the maintenance of CCA nodules. Lastly, therapeutic elimination of Sox9 using the OPN-CreERT2 strain combined with an inducible CRISPR/Cas9-based Sox9 iKO significantly reduces Akt-YAP1 cHCC-CCA tumor burden, similar to Sox9 CKO. Thus, we contrast the outcomes of acute Sox9 deletion with developmental Sox9 knockout models, emphasizing the importance of considering adaptation mechanisms in therapeutic strategies. This necessitates the careful consideration of genetic liver cancer studies using developmental Cre and somatic mutant lines, particularly for genes involved in hepatic commitment during development. Our findings suggest that SOX9 elimination may hold promise as a therapeutic approach for cHCC-CCA and underscore the need for further investigation to translate these preclinical insights into clinical applications.	cancer_biology sox9 therapeutic hepatocellular carcinoma cancers cholangiocarcinoma cancer tumor		2024-05-23								cc_no			Sungjin Ko	28	0
Ellagic acid: a potential inhibitor of enhancer of zeste homolog-2 and protein arginine methyltransferase-5	Dysregulation of epigenetic processes, characterized by aberrant DNA methylation patterns and histone modifications, is a hallmark of cancer, driving its initiation, progression, and metastasis by silencing tumor suppressor genes or activating oncogenes. Perturbations in histone modifications such as H3K27me3 by EZH2 and H4R3me2s by PRMT5 play significant roles in these epigenetic alterations, disrupting normal gene expression and facilitating oncogene activation while suppressing tumor suppressor genes. Consequently, inhibitors targeting enzymes involved in DNA methylation, histone modification, or chromatin remodeling, such as PRMTs and PRC complexes, are promising anti-cancer agents, with several undergoing pre-clinical and clinical trials. Our screening of a phytochemical library revealed ellagic acid as an effective inhibitor of both EZH2 and PRMT5. Ellagic acid interacts strongly with the EZH2 and PRMT5:MEP50 complex, binding to their active sites through {pi}-cation interactions and hydrogen bonds. Surface Plasmon Resonance study confirmed potent binding affinities of ellagic acid, with KD values of 3.28E-06 and 6.54E-05 for EZH2 and PRMT5:MEP50 respectively. In-vitro assays validated inhibitory effects on EZH2 and PRMT5:MEP50 by reducing the levels of their catalytic products H3K27me3 and H4R3me2s respectively and induction of autophagy and apoptosis. Further In-vivo studies using mouse xenografts further demonstrated significant tumor size reductions upon oral administration of ellagic acid, with decreased expression of the proliferative marker ki67 and histone repressive marks. Taken together we showed that inhibition of EZH2 and PRMT5:MEP50 by ellagic acid could be used to develop breast cancer therapeutic drug.	cancer_biology arginine protein apoptosis methyltransferase acid remodeling metastasis inhibitor cancer tumor		2024-05-23								cc_by_nc_nd			Santosh R Kanade	29	0
Phosphodiesterase 1A physically interacts with YTHDF2 and reinforces the progression of non-small cell lung cancer	Non-small cell lung cancer (NSCLC) is the most common subtype of lung cancer, and the prognosis is poor due to distant metastasis and drug resistance. Thus, there is an urgent need to discover novel therapeutic targets and strategies to overcome cisplatin resistance and metastasis. A series of in vitro and in vivo phenotype experiments were performed to investigate the role of PDE1A in NSCLC. The RIP assay, mRNA stability assay and LC- MS/MS were performed to investigate the molecular mechanisms of PDE1A in NSCLC progression. We demonstrated that phosphodiesterase 1A (PDE1A) promoted metastasis and EMT progression of NSCLC. In addition, NSCLC cells overexpressing PDE1A promoted angiogenesis by regulating exosome release. IL-6/JAK/STAT3 signaling pathway was highly enriched in PDE1A- coexpresssed genes, and PDE1A promoted NSCLC metastasis by activating the STAT3 pathway. GO enrichment analysis of PDE1A-interacting genes showed that PDE1A might interact with YTHDF2 and participate in m6A- containing RNA binding. The binding between PDE1A and YTHDF2 was verified, and PDE1A regulated the STAT3 pathway by interacting with YTHDF2. The mechanism of YTHDF2/PDE1A complex in regulating STAT3 pathway was predicted by overlapping YTHDF2-interacting-RNAs, and genes coexpressed with YTHDF2 and STAT3. The interactions between YTHDF2 and target mRNAs were predicted, and there were three predicted targets of YTHDF2 with high scores: NRF2, SOCS2, and MET. Indeed, PDE1A interacted with YTHDF2, destabilized SOCS2, and activated STAT3 pathway. Moreover, PDE1A suppression sensitized anti-NSCLC activity of cisplatin via regulating NRF2 and MET. This work not only uncovers a novel PDE1A/YTHDF2/STAT3 pathway in NSCLC progression but also provides therapeutic strategies for treating NSCLC patients with metastasis or cisplatin- resistance.	cancer_biology genes rna angiogenesis lung cell 1a phosphodiesterase metastasis cancer		2024-05-23								cc_by			Chong Zhang	30	0
Targeting PRMT3 Impairs Methylation and Oligomerization of HSP60 to Boost Anti-Tumor Immunity by Activating cGAS/STING Signaling	Hepatocellular carcinoma (HCC) is a highly lethal cancer for which current available treatment options have limited efficacy. Immunotherapy has emerged as a promising therapeutic option for HCC, yet resistance to immunotherapy is a major challenge. Here, we uncover protein arginine methyltransferase 3 (PRMT3) as a novel driver of immunotherapy resistance in HCC. We show that PRMT3 expression is induced by activated T cells in response to immune checkpoint blockade (ICB) via an interferon-gamma (IFN{gamma})-STAT1 signaling pathway, and that high PRMT3 expression inversely correlates with tumor-infiltrating CD8+ T cells and predicts poor response to ICB in HCC patients. We demonstrate that genetic depletion and pharmacological inhibition of PRMT3 induce a profound influx of T cells into tumors and activate anti-tumor immunity to suppress HCC progression. Mechanistically, we demonstrate that PRMT3 methylates HSP60, a mitochondrial chaperone protein, at R446, and that this novel post-translational modification is required for HSP60 oligomerization and maintaining mitochondrial homeostasis. We reveal that targeting PRMT3-dependent HSP60-R446 methylation boosts anti-tumor immunity by disrupting mitochondrial function, increasing mitochondrial DNA (mtDNA) leakage, and activating the cGAS/STING pathway, a key innate immune sensor of cytosolic DNA. Importantly, we provide genetic and pharmacologic evidence that targeting PRMT3 enhances anti-PD1 efficacy and anti-tumor immunity in HCC mouse models. Our study identifies PRMT3 as a potential biomarker and therapeutic target to overcome immunotherapy resistance in HCC.	boost cancer_biology activating oligomerization carcinoma immunotherapy tumors methylation cancer tumor		2024-05-23								cc_no			Yunfei Yuan	31	0
Loss of p21-activated kinase 4 (PAK4) suppresses pancreatic tumor progression and metastasis through regulating E-cadherin	"Pancreatic ductal adenocarcinoma (PDAC) is characterized by a poor prognosis with early and frequent metastasis. While p21-activated kinase 4 (PAK4) has been implicated in cell migration, and invasion, the molecular mechanisms in PDAC remain unknown. In this study, we found that PAK4 overexpression was correlated with poor survival in PDAC patients through analysis of TCGA data. PAK4-amplified PDAC cells showed enhanced mobility in contrast with wild-type. PAK4 knockdown in PAK4 amplified cells inhibited cell migration, invasion, and displacement by increased and stabilized E-cadherin, which was attributed to decreased activity of Cdc42. PAK4 knock-in in PAK4 wild-type models enhanced cell migration, invasion, and displacement by reduced E-cadherin through elevated Cdc42 activity. PAK4 bounded to E-cadherin, Cdc42, and p120ctn in immunoprecipitation. In confocal imaging, the colocalization of PAK4, E-cadherin, p120ctn, and Cdc42 was also identified. In an orthotopic PDAC mouse model, PAK4 knockdown decreased primary tumor size and occurrence of malignant ascites by activation of E-cadherin. Notably, in patients tissue specimens, inverse correlation on expression of PAK4 and E-cadherin were also shown. In conclusion, our study highlights that PAK4 promotes invasive and metastatic behavior by regulating E-cadherin in PDAC. PAK4 could be a potential therapeutic target for PDAC patients.  Graphical abstract  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=120 SRC=""FIGDIR/small/594599v1_ufig1.gif"" ALT=""Figure 1""> View larger version (28K): org.highwire.dtl.DTLVardef@1755a23org.highwire.dtl.DTLVardef@170b2a1org.highwire.dtl.DTLVardef@1df96edorg.highwire.dtl.DTLVardef@2dc46b_HPS_FORMAT_FIGEXP  M_FIG C_FIG"	cancer_biology overexpression pancreatic kinase adenocarcinoma metastasis malignant invasive tumor suppresses		2024-05-23								cc_no			Jin Won Kim	32	0
Mathematical Modeling Unveils Optimization Strategies for Targeted Radionuclide Therapy of Blood Cancers	Targeted radionuclide therapy is based on injections of cancer-specific molecules conjugated with radioactive nuclides. Despite the specificity of this treatment, it is not devoid of side-effects limiting its use and is especially harmful for rapidly proliferating organs well perfused by blood, like bone marrow. Optimization of radioconjugates administration accounting for toxicity constraints can increase treatment efficacy. Based on our experiments on disseminated multiple myeloma mouse model treated by 225Ac-DOTA-daratumumab, we developed a mathematical model which investigation highlighted the following principles for optimization of targeted radionuclide therapy. 1) Nuclide to antibody ratio importance. The density of radioconjugates on cancer cells determines the density of radiation energy deposited in them. Low labeling ratio as well as accumulation of unlabeled antibodies and antibodies attached to decay products in the bloodstream can mitigate cancer radiation damage due to excessive occupation of specific receptors by antibodies devoid of radioactive nuclides. 2) Cancer binding capacity-based dosing. The rate of binding of drug to cancer cells depends on the total number of their specific receptors, which therefore can be estimated from the pharmacokinetic curve of diagnostic radioconjugates. Injection of doses significantly exceeding cancer binding capacity should be avoided since radioconjugates remaining in the bloodstream have negligible efficacy to toxicity ratio. 3) Particle range-guided multi-dosing. The use of short-range particle emitters and high-affinity antibodies allows for robust treatment optimization via initial saturation of cancer binding capacity, enabling redistribution of further injected radioconjugates and deposited dose towards still viable cells that continue expressing specific receptors.  SignificanceMathematical modeling yields general principles for optimization of targeted radionuclide therapy in mouse models of multiple myeloma that can be extrapolated on another cancer models and on clinical setting.	cancer_biology myeloma radiation pharmacokinetic blood mathematical cancers therapy cancer optimization		2024-05-23								cc_by			Maxim Kuznetsov	33	0
Transposable Elements Shape Stemness in Normal and Leukemic Hematopoiesis	Despite most acute myeloid leukemia (AML) patients achieving complete remission after induction chemotherapy, two-thirds will relapse with fatal disease within five years. AML is organized as a cellular hierarchy sustained by leukemia stem cells (LSC) at the apex, with LSC properties directly linked to tumor progression, therapy failure, and disease relapse 1-5. Despite the central role of LSC in poor patient outcomes, little is known about the genetic determinants driving their stemness properties. As LSCs share many functional and molecular properties with normal hematopoietic stem cells (HSC) 6, we investigated accessible chromatin unique across normal hematopoietic and cancer cell states and identified transposable elements (TEs) as genetic determinants of both primitive populations in comparison with their downstream mature progeny. A clinically-relevant TE chromatin accessibility-based LSCTE121 signature was developed that enabled patient classification based on survival outcomes. Through functional assays, primitive cell specific-TE subfamilies were found to serve as docking sites for stem cell-associated regulators of genome topology or lineage-specific transcription factors, including LYL1 in LSCs. Finally, using chromatin editing tools, we establish that chromatin accessibility at LTR12C elements in LSCs are necessary to maintain stemness properties. Our work identifies TEs as genetic drivers of primitive versus mature cell states, where distinct TE subfamilies account for stemness properties in normal versus leukemic hematopoietic stem cells.	cancer_biology stemness shape transposable leukemic leukemia myeloid hematopoiesis chemotherapy cancer tumor		2024-05-16								cc_by_nc			Mathieu  Lupien	34	0
Enhancer plasticity in endometrial tumorigenesis demarcates non-coding somatic mutations and 3D-genome alterations boosting the oncogenic driver ESR1	The incidence and mortality of Endometrial Cancer (EC) is on the rise. 85% of ECs depend on Estrogen Receptor alpha (ER) for proliferation, but little is known about its transcriptional regulation in these tumors.  We generated epigenomics, transcriptomics and Hi-C datastreams in healthy and tumor endometrial tissues, identifying robust ER reprogramming and profound alterations in 3D genome organization that lead to a gain of tumor-specific enhancer activity during EC development. Integration with endometrial cancer risk single-nucleotide polymorphisms, as well as WGS data from primary tumors and metastatic samples revealed a striking enrichment of risk variants and non-coding somatic mutations at tumor-enriched ER sites. Through machine learning-based predictions and interaction proteomics analyses, we identified an enhancer mutation which alters 3D genome conformation, impairing recruitment of the transcriptional repressor EHMT2/G9a/KMT1C, thereby alleviating transcriptional repression of ESR1 in EC.  In summary, we identified a complex genomic-epigenomic interplay in EC development and progression, altering 3D genome organization to enhance expression of the critical driver ER.	cancer_biology endometrial tumorigenesis mutations tumor transcriptomics genome tumors cancer coding		2024-05-16								cc_by_nc_nd			Wilbert Zwart	35	0
CDC42 Inhibitors Alter Patterns of Vessel Arborization in Skin and Tumors in vivo	Tumors that arise in the epidermis must develop a vascular supply to grow beyond a millimeter in depth. This process requires CDC42 GTPases such as CDC42, RhoJ and RhoQ. Despite this dependence on angiogenesis for growth, melanoma tumors are minimally responsive to current anti-angiogenesis agents, highlighting the need for more effective drugs in this class. Here we integrate antibody infusion, optical tissue clearing, multiphoton imaging, and three-dimensional semi-automated tracing to develop a quantitative approach to measure changes in vascular architecture in skin and skin tumors. This new approach uncovered differences in vessel arborization in the skin of RhoJ KO mice as compared to wild-type mice. Furthermore, novel small molecules that inhibit CDC42 GTPases inhibited both tumor growth and vessel branching within tumors to a similar degree as Braf inhibitors, which are commonly used to treat melanoma. In contrast to Braf inhibitors, however, which only affected tumor vasculature, CDC42 inhibitors affected vascularization in both tumor and normal skin without apparent toxicity to endothelial or stromal cells. These novel CDC42 inhibitors similarly blocked vessel branching in human cell-based micro-physiological models of normal and tumor vessels. RNA sequencing revealed reduced expression of multiple angiogenesis-related genes in drug-treated skin. Taken together, these studies identify a new class of pharmacologic agents that inhibit vessel branching in both normal skin and tumors with potential utility for treating skin cancer and skin diseases characterized by pathologic angiogenesis.	cancer_biology arborization endothelial angiogenesis patterns cdc42 tumors inhibitors cancer tumor		2024-05-16								cc_no			Anand K Ganesan	36	0
Constitutive Photomorphogenesis Protein 1 homolog (COP1) sustains nuclear factor-4 alpha function in human hepatocyte models	Constitutive Photomorphogenesis Protein 1 homolog (COP1) is a conserved E3 ligase with key roles in several biological systems. Prior work in hepatocyte derived tumors categorized COP1 as an oncogene but its role in untransformed hepatocytes remains largely unexplored. Here we have investigated the role of COP1 in primary human hepatocytes as well as in two transformed hepatocyte models, HepG2 and HuH-7 cells. Contrary to a previous report, COP1 suppression via siRNA had no noticeable impact on HepG2 and HuH-7 proliferation and was associated with contrasting rather than congruent transcriptome changes. Clustering analyses identified patterns indicative of perturbed metabolism in primary hepatocytes and HepG2 cells whereas patterns pointed to cell proliferation impacts in HuH-7 cells. In HepG2 and primary hepatocytes, COP1 suppression reduced the expression important hepatic regulators and markers, which could be restored by the introduction of a siRNA resistant COP1 transgene. COP1 downregulation reduced hepatic nuclear factor-4 alpha (HNF4A) abundance and function, as assessed by lower abundance of key HNF4A targets and reduced APOB secretion. HNF4A restoration partially rescued COP1 silencing in HepG2 cells. This study identifies COP1 as a key regulator of hepatocyte function, in part via HNF4A. COP1 was required to maintain HNF4A abundance and function in primary hepatocytes and in HepG2 cells, but not in HuH-7 cells. Lastly, by demonstrating contrasting roles of COP1 in HuH-7 and HepG2 cells, our findings also challenge previous work linking COP1 to hepatic tumorigenesis.	cancer_biology photomorphogenesis tumorigenesis homolog protein hepatocytes hnf4a cop1 tumors hepatocyte hepatic		2024-05-09								cc_by			Sébastien Soubeyrand	37	0
RGS10 deficiency facilitates distant metastasis by inducing epithelial-mesenchymal transition in breast cancer	AbstractDistant metastasis is the major cause of death in patients with breast cancer. Epithelial-mesenchymal transition (EMT) contributes to breast cancer metastasis. Regulator of G protein-signaling (RGS) proteins modulate metastasis in various cancers. This study identified a novel role for RGS10 in EMT and metastasis in breast cancer. RGS10 protein levels were significantly lower in breast cancer tissues compared to normal breast tissues, and deficiency in RGS10 protein predicted a worse prognosis in patients with breast cancer. RGS10 protein levels were lower in the highly aggressive cell line MDA-MB-231 than in the poorly aggressive, less invasive cell lines MCF7 and SKBR3. Silencing RGS10 in SKBR3 cells enhanced EMT and caused SKBR3 cell migration and invasion. The ability of RGS10 to suppress EMT and metastasis in breast cancer was dependent on lipocalin-2 and miR-539-5p. These findings identify RGS10 as a tumor suppressor, prognostic biomarker, and potential therapeutic target for breast cancer.	mesenchymal cancer_biology epithelial breast cancers metastasis death invasive cancer tumor		2024-05-09								cc_by			Xi Gu	38	0
In vitro efficacy and in vivo toxicity and retention of targeted nanoformulated carboplatin in a sustained release carrier for treatment of osteosarcoma	Objectiveevaluate 1) if targeting of platinum magnetic nanoclusters will promote uptake in osteosarcoma cells in vitro, 2) targeting will improve uptake and delivery in murine OSA in vivo compared to free carboplatin, 3) incorporation into a sustained release carrier (SRC) will prolong local retention in vivo.  MethodsComplex stability and peptide loading was assessed. Drug release was tested at pH 7.4 and 5.5 and cellular uptake and cytotoxity determined for canine, human and mouse osteosarcoma. Subcutaneous murine osteosarcoma was induced and optimal dose and time until tumor growth were established. Tumor bearing mice were equally distributed between 8 treatment (0.5mg carboplatin/mouse) and 1 control group and sacrificed at 8 predetermined time points between 1 hour and 8 days. Blood, tumor site and organs were harvested for tissue ferron and platinum content analysis (ICP-MS).  ResultsCarboplatin was preferentially released at pH5.5. Targeting increased cellular uptake for carboplatin 15.2-fold, and decreased IC50 at 24h and 48h. At 2 weeks, a SC injection of 1-1.56 live cells/mouse reliably resulted in a palpable tumor. Plasma platinum peaked prior to 6 hours while plasma ferron peaked at 24-48 hours. Intratumoral delivery did not lead to a sustained local presence while local delivery in a SRC after surgery did.  ConclusionsTargeting of MNC-carboplatin is possible with an increased osteosarcoma cell uptake in vitro. In vivo metastatic uptake could not be assessed due to lack of metastases, but local delivery in a SRC yielded high local, and low systemic platinum concentrations in mice.	cancer_biology platinum surgery nanoformulated vitro nanoclusters osteosarcoma carboplatin tumor treatment		2024-05-09								cc_by_nc_nd			Marije Risselada	39	0
Targeting SCD triggers lipotoxicity of cancer cells and enhances anti-tumor immunity in breast cancer brain metastasis mouse models	Breast cancer brain metastases (BCBM) are a significant cause of mortality and are incurable. Thus, identifying BCBM targets that reduce morbidity and mortality is critical. BCBM upregulate Stearoyl-CoA Desaturase (SCD), an enzyme that catalyzes the synthesis of monounsaturated fatty acids, suggesting a potential metabolic vulnerability of BCBM. In this study, we tested the effect of a brain-penetrant clinical-stage inhibitor of SCD (SCDi), on breast cancer cells and mouse models of BCBM. Lipidomics, qPCR, and western blot were used to study the in vitro effects of SCDi. Single-cell RNA sequencing was used to explore the effects of SCDi on cancer and immune cells in a BCBM mouse model. Pharmacological inhibition of SCD markedly reshaped the lipidome of breast cancer cells and resulted in endoplasmic reticulum stress, DNA damage, loss of DNA damage repair, and cytotoxicity. Importantly, SCDi alone or combined with a PARP inhibitor prolonged the survival of BCBM-bearing mice. When tested in a syngeneic mouse model of BCBM, scRNAseq revealed that pharmacological inhibition of SCD enhanced antigen presentation by dendritic cells, was associated with a higher interferon signaling, increased the infiltration of cytotoxic T cells, and decreased the proportion of exhausted T cells and regulatory T cells in the tumor microenvironment (TME). Additionally, pharmacological inhibition of SCD decreased engagement of immunosuppressive pathways, including the PD-1:PD-L1/PD-L2 and PVR/TIGIT axes. These findings suggest that SCD inhibition could be an effective strategy to intrinsically reduce tumor growth and reprogram anti-tumor immunity in the brain microenvironment to treat BCBM.	cancer_biology endoplasmic immunosuppressive lipotoxicity cells mouse pharmacological cancer tumor		2024-05-09								cc_no			Alessandro Sammarco	40	0
Lipid availability influences ferroptosis sensitivity in cancer cells by regulating polyunsaturated fatty acid trafficking	Ferroptosis is a form of cell death caused by lipid peroxidation that is emerging as a target for cancer therapy, highlighting the need to identify factors that govern ferroptosis susceptibility. Lipid peroxidation occurs primarily on phospholipids containing polyunsaturated fatty acids (PUFAs). Here, we show that even though extracellular lipid limitation reduces cellular PUFA levels, lipid-starved cancer cells are paradoxically more sensitive to ferroptosis. Using mass spectrometry-based lipidomics with stable isotope fatty acid labeling, we show that lipid limitation induces a fatty acid trafficking pathway in which PUFAs are liberated from triglycerides to synthesize highly unsaturated PUFAs such as arachidonic acid and adrenic acid. These PUFAs then accumulate in phospholipids, particularly ether phospholipids, to promote ferroptosis sensitivity. Therefore, PUFA levels within cancer cells do not necessarily correlate with ferroptosis susceptibility. Rather, how cancer cells respond to extracellular lipid levels by trafficking PUFAs into proper phospholipid pools dictates their sensitivity to ferroptosis.	cancer_biology lipidomics polyunsaturated lipid trafficking spectrometry ferroptosis therapy cancer		2024-05-09								cc_by_nc_nd			Evan C Lien	41	0
Unveiling Novel Double-Negative Prostate Cancer Subtypes Through Single-Cell RNA Sequencing Analysis	"Recent advancements in single-cell RNA sequencing (scRNAseq) have facilitated the discovery of previously unrecognized subtypes within prostate cancer (PCa), offering new insights into disease heterogeneity and progression. In this study, we integrated scRNAseq data from multiple studies, comprising both publicly available cohorts and data generated by our research team, and established the HuPSA (Human Prostate Single cell Atlas) and the MoPSA (Mouse Prostate Single cell Atlas) datasets. Through comprehensive analysis, we identified two novel double-negative PCa populations: KRT7 cells characterized by elevated KRT7 expression, and progenitor-like cells marked by SOX2 and FOXA2 expression, distinct from NEPCa, and displaying stem/progenitor features. Furthermore, HuPSA-based deconvolution allowed for the re-classification of human PCa specimens, validating the presence of these novel subtypes. Leveraging these findings, we developed a user-friendly web application, ""HuPSA-MoPSA"" (https://pcatools.shinyapps.io/HuPSA-MoPSA/), for visualizing gene expression across all newly-established datasets. Our study provides comprehensive tools for PCa research and uncovers novel cancer subtypes that can inform clinical diagnosis and treatment strategies.  Graph abstract  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=161 SRC=""FIGDIR/small/553009v3_ufig1.gif"" ALT=""Figure 1""> View larger version (44K): org.highwire.dtl.DTLVardef@efa7c3org.highwire.dtl.DTLVardef@1ef0c4eorg.highwire.dtl.DTLVardef@110f8c0org.highwire.dtl.DTLVardef@13b2ed4_HPS_FORMAT_FIGEXP  M_FIG C_FIG"	13b2ed4_hps_format_figexp cancer_biology rna sequencing 553009v3_ufig1 prostate cancer unveiling		2024-05-02								cc_by_nc_nd			SIYUAN CHENG	42	0
Decoil: Reconstructing extrachromosomal DNA structural heterogeneity from long-read sequencing data	Circular extrachromosomal DNA (ecDNA) is a form of oncogene amplification found across cancer types and associated with poor outcome in patients. EcDNA can be structurally complex and contain rearranged DNA sequences derived from multiple chromosome locations. As the structure of ecDNA can impact oncogene regulation and may indicate mechanisms of its formation, disentangling it at high resolution from sequencing data is essential. Even though methods have been developed to identify and reconstruct ecDNA in cancer genome sequencing, it remains challenging to resolve complex ecDNA structures, in particular amplicons with shared genomic footprints. We here introduce Decoil, a computational method which combines a breakpoint-graph approach with LASSO regression to reconstruct complex ecDNA and deconvolve co-occurring ecDNA elements with overlapping genomic footprints from long-read nanopore sequencing. Decoil outperforms de-novo assembly and alignment-based methods in simulated longread sequencing data for both simple and complex ecDNAs. Applying Decoil on whole genome sequencing data uncovered different ecDNA topologies and explored ecDNA structure heterogeneity in neuroblastoma tumors and cell lines, indicating that this method may improve ecDNA structural analyzes in cancer.	cancer_biology reconstructing sequencing dna data neuroblastoma extrachromosomal tumors cancer		2024-05-02								cc_by_nc_nd			Anton G. Henssen	43	0
PTBP2 promotes cell survival and autophagy in Chronic Myeloid Leukemia by stabilizing BNIP3	Polypyrimidine tract binding protein 2 (PTBP2) regulates alternative splicing in neuronal, muscle, and Sertoli cells. PTBP2 and its paralog, PTBP1, which plays a role in B-cell development, was found to be expressed aberrantly in myeloid leukemia. Genetic ablation of Ptbp2 in the cells resulted in decreased cellular proliferation and repopulating ability, decreased reactive oxygen species (ROS), and altered mitochondrial morphology. The sensitivity of CML cells to imatinib increased after the knockout of Ptbp2. RNA immunoprecipitation followed by sequencing (RIP-seq) and functional assays confirmed that PTBP2 binds to Bcl-2 Interacting Protein 3 (Bnip3)-3UTR and stabilizes its expression. Our study also suggests that PTBP2 promotes autophagy, as evidenced by the low levels of LC3-II expression in Ptbp2-knockout cells treated with Bafilomycin A1. This effect was restored upon overexpression of Bnip3 in the knockout cells. Notably, when KCL22-NTC cells were subcutaneously injected into the flanks of mice, they gave rise to malignant tumors, unlike Ptbp2-KO-KCL22 cells. This underscores the role of PTBP2 in promoting cell proliferation and tumor formation while enhancing autophagy through Bnip3, thereby supporting the role of PTBP2 as an oncogene in CML.	cancer_biology autophagy ptbp2 myeloid leukemia stabilizing tumors tumor		2024-05-02								cc_no			Soumen chakraborty	44	0
Aberrant cytoplasmic localization of MLH1 characterizes a sub-clonal breast cancer cell population that seeds recurrence	Estrogen receptor positive (ER+) breast cancer is one of the most common causes of cancer-related death in women. Mortality is largely driven by recurrence of treatment-resistant disease after many years of apparent response, making the molecular events that cause recurrence a critical area of investigation. Loss of expression of MLH1, a tumor suppressor best studied in its role in mismatch repair, induces resistance of ER+ breast cancer cells to standard estrogen-targeting therapies. It does so by delinking cell cycle progression from estrogen regulation, a role distinct from its function in mismatch repair. MLH1 loss, as currently clinically diagnosed by detecting genomic instability or by immunohistochemistry for absence of protein, occurs in 12-15% of all cancers. Here, we demonstrate that sub-clonal, patient-derived mutations in MLH1, which neither impact protein abundance nor contribute sufficiently to genomic instability to be detected diagnostically, seed endocrine treatment resistance by enabling estrogen-independent growth in vitro, ex vivo in patient-derived organoids (p=0.005) and in vivo (p=0.0001). The mechanism underlying this endocrine treatment resistance is aberrant localization of MLH1 to the cytoplasm in vitro and in vivo (p=0.04), which precludes cell cycle arrest in response to endocrine therapy while simultaneously rendering cells acutely dependent on CDK4/6 activity. Consequently, administration of CDK4/6 inhibitors causes extreme regression in cells with cytoplasmic MLH1 compared to control cell populations with nuclear localization of MLH1 in vitro (p=0.00000009), ex vivo (p=0.01) and in vivo (p=0.01). As aberrant cytoplasmic localization occurs in an additional [~]12% of ER+ breast cancer patients, it constitutes a new, major contributor to MLH1 dysregulation. The potential applicability of cytoplasmic MLH1 as a predictor of responsiveness to existing targeted therapies in a hard-to-treat breast cancer subtype posits an update of current clinical diagnostic criteria and therapeutic strategies. This is particularly important in the adjuvant setting where identification of biomarkers predicting responsiveness to CDK4/6 inhibitors remains an urgent, unmet clinical need.	cancer_biology estrogen aberrant breast cytoplasmic recurrence cancers immunohistochemistry cancer tumor		2024-05-02								cc_no			Svasti Haricharan	45	0
Aberrant cytoplasmic localization of MLH1 characterizes a sub-clonal breast cancer cell population that seeds recurrence	Estrogen receptor positive (ER+) breast cancer is one of the most common causes of cancer-related death in women. Mortality is largely driven by recurrence of treatment-resistant disease after many years of apparent response, making the molecular events that cause recurrence a critical area of investigation. Loss of expression of MLH1, a tumor suppressor best studied in its role in mismatch repair, induces resistance of ER+ breast cancer cells to standard estrogen-targeting therapies. It does so by delinking cell cycle progression from estrogen regulation, a role distinct from its function in mismatch repair. MLH1 loss, as currently clinically diagnosed by detecting genomic instability or by immunohistochemistry for absence of protein, occurs in 12-15% of all cancers. Here, we demonstrate that sub-clonal, patient-derived mutations in MLH1, which neither impact protein abundance nor contribute sufficiently to genomic instability to be detected diagnostically, seed endocrine treatment resistance by enabling estrogen-independent growth in vitro, ex vivo in patient-derived organoids (p=0.005) and in vivo (p=0.0001). The mechanism underlying this endocrine treatment resistance is aberrant localization of MLH1 to the cytoplasm in vitro and in vivo (p=0.04), which precludes cell cycle arrest in response to endocrine therapy while simultaneously rendering cells acutely dependent on CDK4/6 activity. Consequently, administration of CDK4/6 inhibitors causes extreme regression in cells with cytoplasmic MLH1 compared to control cell populations with nuclear localization of MLH1 in vitro (p=0.00000009), ex vivo (p=0.01) and in vivo (p=0.01). As aberrant cytoplasmic localization occurs in an additional [~]12% of ER+ breast cancer patients, it constitutes a new, major contributor to MLH1 dysregulation. The potential applicability of cytoplasmic MLH1 as a predictor of responsiveness to existing targeted therapies in a hard-to-treat breast cancer subtype posits an update of current clinical diagnostic criteria and therapeutic strategies. This is particularly important in the adjuvant setting where identification of biomarkers predicting responsiveness to CDK4/6 inhibitors remains an urgent, unmet clinical need.	cancer_biology estrogen aberrant breast cytoplasmic recurrence cancers immunohistochemistry cancer tumor		2024-05-02								cc_no			Svasti Haricharan	46	0
Magnetic particle imaging reveals that iron-labeled extracellular vesicles accumulate in brains of mice with metastases	"The incidence of breast cancer remains high worldwide and is associated with a significant risk of metastasis to the brain that can be fatal; this is due, in part, to the inability of therapeutics to cross the blood brain barrier (BBB). Extracellular vesicles (EVs) have been found to cross the BBB and further, have been used to deliver drugs to tumors. EVs from different cell types appear to have different patterns of accumulation and retention as well as efficiency of bioactive cargo delivery to recipient cells in the body. Engineering EVs as delivery tools to treat brain metastases, therefore, will require an understanding of the timing of EV accumulation, and their localization relative to metastatic sites. Magnetic particle imaging (MPI) is a sensitive and quantitative imaging method that directly detects superparamagnetic iron. Here, we demonstrate MPI as a novel tool to characterize EV biodistribution in metastatic disease after labeling EVs with superparamagnetic iron oxide (SPIO) nanoparticles. Iron-labeled EVs (FeEVs) were collected from iron-labeled parental primary 4T1 tumor cells and brain-seeking 4T1BR5 cells, followed by injection into mice with orthotopic tumors or brain metastases. MPI quantification revealed that FeEVs were retained for longer in orthotopic mammary carcinomas compared to SPIOs. MPI signal due to iron could only be detected in brains of mice bearing brain metastases after injection of FeEVs, but not SPIOs, or FeEVs when mice did not have brain metastases. These findings indicate the potential use of EVs as a therapeutic delivery tool in primary and metastatic tumors.  TOC Graphic  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=99 SRC=""FIGDIR/small/584146v2_ufig1.gif"" ALT=""Figure 1""> View larger version (20K): org.highwire.dtl.DTLVardef@8cf21org.highwire.dtl.DTLVardef@56b6f0org.highwire.dtl.DTLVardef@104626eorg.highwire.dtl.DTLVardef@da60cd_HPS_FORMAT_FIGEXP  M_FIG C_FIG"	iron cancer_biology disease carcinomas mice imaging metastases tumors cancer tumor extracellular		2024-05-02								cc_by_nc			Ashley V Makela	47	0
Transcriptional remodeling of the Stromal and Endothelial Microenvironment in MGUS to Multiple Myeloma Progression	"The role of the bone marrow microenvironment (BME) in the transition from monoclonal gammopathy of undetermined significance (MGUS) into clinically active multiple myeloma (MM) is not completely determined. To address this issue, we performed single-cell RNA sequencing (scRNA-seq) of non-hematopoietic BME cells as well as plasma cells (PC) from two genetically engineered mouse models of MM termed BIc{gamma}1and MIc{gamma}1that recapitulate the progression of MGUS into MM. Our results identify distinct transcriptional dynamics between endothelial cells (EC) and mesenchymal stem cells (MSC). While EC acquire a stress state during MGUS, a proliferating and angiogenic profile characterizes MM. On the other hand, MSC compromised their differentiation potential, exhibiting a more inflammatory profile that initiates from the MGUS stage. Interestingly, we identified an interferon (IFN)-related myeloma signature in malignant EC of the BIc{gamma}1model, which is also expressed in MSC but not observed in the more aggressive MIc{gamma}1model and can be identified in MSC from a subgroup of MM patients. The analysis of the EC and MSC interactions with malignant PC revealed stage-specific interactions that contribute to angiogenesis, immunomodulation, and MM extravasation. Finally, the translational relevance of our results in humans was confirmed on MSC from newly diagnosed patients with monoclonal gammopathies at different stages of the disease. In summary, these results show a remodeling of the non-hematopoietic BME in MM progression, providing potential targets at the tumor-niche interface that may hold clinical significance and complement existing immunotherapies.    O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=84 SRC=""FIGDIR/small/589777v3_ufig1.gif"" ALT=""Figure 1""> View larger version (31K): org.highwire.dtl.DTLVardef@15c2133org.highwire.dtl.DTLVardef@187b9b7org.highwire.dtl.DTLVardef@1b1ac86org.highwire.dtl.DTLVardef@1b5af01_HPS_FORMAT_FIGEXP  M_FIG C_FIG KEY POINTSO_LIEC stress pre-vascular state in MGUS, shifts to angiogenic in MM, while MSC early transcriptional changes in MGUS persist in overt MM. C_LIO_LIIdentification of a myeloma-specific IFN signature in the non-hematopoietic BME that could define a subgroup of MM patients. C_LI"	cancer_biology microenvironment 1b5af01_hps_format_figexp immunotherapies myeloma remodeling immunomodulation endothelial tumor transcriptional		2024-05-02								cc_by_nc_nd			Felipe Prosper	48	0
RGS10 deficiency facilitates distant metastasis by inducing epithelial-mesenchymal transition in breast cancer	AbstractDistant metastasis is the major cause of death in patients with breast cancer. Epithelial-mesenchymal transition (EMT) contributes to breast cancer metastasis. Regulator of G protein-signaling (RGS) proteins modulate metastasis in various cancers. This study identified a novel role for RGS10 in EMT and metastasis in breast cancer. RGS10 protein levels were significantly lower in breast cancer tissues compared to normal breast tissues, and deficiency in RGS10 protein predicted a worse prognosis in patients with breast cancer. RGS10 protein levels were lower in the highly aggressive cell line MDA-MB-231 than in the poorly aggressive, less invasive cell lines MCF7 and SKBR3. Silencing RGS10 in SKBR3 cells enhanced EMT and caused SKBR3 cell migration and invasion. The ability of RGS10 to suppress EMT and metastasis in breast cancer was dependent on lipocalin-2 and miR-539-5p. These findings identify RGS10 as a tumor suppressor, prognostic biomarker, and potential therapeutic target for breast cancer.	mesenchymal cancer_biology epithelial breast cancers metastasis death invasive cancer tumor		2024-04-25								cc_by			Xi Gu	49	0
Disruption of Circadian Clock Induces Abnormal Mammary Morphology and Aggressive Basal Tumorigenesis by Enhancing LILRB4 Signaling	Epidemiological studies have shown that circadian rhythm disruption (CRD) is associated with the risk of breast cancer. However, the role of CRD in mammary gland morphology and aggressive basal mammary tumorigenesis and the molecular mechanisms underlying CRD and cancer risk remain unknown. To investigate the effect of CRD on aggressive tumorigenesis, a genetically engineered mouse model that recapitulates the human basal type of breast cancer was used for this study. The effect of CRD on mammary gland morphology was investigated using wild-type mice model. The impact of CRD on the tumor microenvironment was investigated using the tumors from LD12:12 and CRD mice via scRNA seq. ScRNA seq was substantiated by multiplexing immunostaining, flow cytometry, and realtime PCR. The effect of LILRB4 immunotherapy on CRD-induced tumorigenesis was also investigated. Here we identified the impact of CRD on basal tumorigenesis and mammary gland morphology and identified the role of LILRB4 on CRD-induced lung metastasis. We found that chronic CRD disrupted mouse mammary gland morphology and increased tumor burden, and lung metastasis and induced an immunosuppressive tumor microenvironment by enhancing LILRB4a expression. Moreover, CRD increased the M2-macrophage and regulatory T-cell populations but decreased the M1-macrophage populations. Furthermore, targeted immunotherapy against LILRB4 reduced CRD-induced immunosuppressive microenvironment and lung metastasis. These findings identify and implicate LILRB4a as a link between CRD and aggressive mammary tumorigenesis. This study also establishes the potential role of the targeted LILRB4a immunotherapy as an inhibitor of CRD-induced lung metastasis.	cancer_biology mammary tumorigenesis disruption abnormal aggressive tumors immunostaining cancer tumor		2024-04-25								cc_no			Tapasree Roy Sarkar	50	0
Peristromal niches protect lung cancers from targeted therapies through a combined effect of multiple molecular mediators	Targeted therapies directed against oncogenic signaling addictions, such as inhibitors of ALK in ALK+ NSCLC often induce strong and durable clinical responses. However, they are not curative in metastatic cancers, as some tumor cells persist through therapy, eventually developing resistance. Therapy sensitivity can reflect not only cell-intrinsic mechanisms but also inputs from stromal microenvironment. Yet, the contribution of tumor stroma to therapeutic responses in vivo remains poorly defined. To address this gap of knowledge, we assessed the contribution of stroma-mediated resistance to therapeutic responses to the frontline ALK inhibitor alectinib in xenograft models of ALK+ NSCLC. We found that stroma-proximal tumor cells are partially protected against cytostatic effects of alectinib. This effect is observed not only in remission, but also during relapse, indicating the strong contribution of stroma-mediated resistance to both persistence and resistance. This therapy-protective effect of the stromal niche reflects a combined action of multiple mechanisms, including growth factors and extracellular matrix components. Consequently, despite improving alectinib responses, suppression of any individual resistance mechanism was insufficient to fully overcome the protective effect of stroma. Focusing on shared collateral sensitivity of persisters offered a superior therapeutic benefit, especially when using an antibody-drug conjugate with bystander effect to limit therapeutic escape. These findings indicate that stroma-mediated resistance might be the major contributor to both residual and progressing disease and highlight the limitation of focusing on suppressing a single resistance mechanism at a time.	cancer_biology lung molecular tumor disease therapies relapse cancers therapy peristromal		2024-04-25								cc_no			Andriy Marusyk	51	0
The invasion phenotypes of glioblastoma depend on plastic and reprogrammable cell states	Glioblastoma (GBM), the most common primary brain cancer in adults, is characterized by rapid local invasion along diverse routes, such as infiltration of white matter tracts and penetration of perivascular spaces. We investigate the hypothesis that GBM invasion routes correlate with the transcriptional states of individual cells and identify regulators of route-specific invasion. Utilizing patient-derived GBM xenograft models, we integrate single-cell transcriptomics and spatial proteomics, revealing that mesenchymal and oligodendrocyte progenitor-like GBM cells migrate perivascularly, while neural progenitor and astrocyte-like GBM cells invade diffusely. Computational reconstruction identifies ANXA1 as a perivascular invasion driver and lineage-restricted transcription factors RFX4 and HOPX as drivers of diffuse invasion, predictive of patient survival. Genetic ablation of these genes alters invasion phenotypes and extends survival in xenografted mice, clarifying the role of cell states in GBM invasion, and highlighting potential therapeutic targets for selective invasion route targeting in GBM patients.	cancer_biology genetic cell reprogrammable phenotypes proteomics plastic glioblastoma transcriptomics cancer		2024-04-25								cc_by_nc_nd			Sven Nelander	52	0
An imbalance between proliferation and differentiation underlies the development of microRNA-defective pineoblastoma	Mutations in the microRNA processing genes DICER1 and DROSHA drive several cancers that resemble embryonic progenitors. To understand how microRNAs regulate tumorigenesis, we ablated Drosha or Dicer1 in the developing pineal gland to emulate the pathogenesis of pineoblastoma, a brain tumor that resembles undifferentiated precursors of the pineal gland. Accordingly, these mice develop pineal tumors marked by loss of microRNAs, including the let-7/miR-98-5p family, and de-repression of microRNA target genes. Pineal tumors driven by loss of Drosha or Dicer1 mimic tumors driven by Rb1 loss, as they exhibit upregulation of S-phase genes and homeobox transcription factors that regulate pineal development. Blocking proliferation of these tumors facilitates expression of pinealocyte maturation markers, with a concomitant reduction in embryonic markers. Select embryonic markers remain elevated, however, as the microRNAs that normally repress these target genes remain absent. One such microRNA target gene is the oncofetal transcription factor Plagl2, which regulates expression of pro-growth genes, and inhibiting their signaling impairs tumor growth. Thus, we demonstrate that tumors driven by loss of microRNA processing may be therapeutically targeted by inhibiting downstream drivers of proliferation.	cancer_biology microrna tumorigenesis imbalance defective cancers pineoblastoma pathogenesis tumors tumor underlies		2024-04-25								cc_by_nc_nd			Kenneth S Chen	53	0
Transcriptional Characterization of the Stromal and Endothelial Bone Marrow Microenvironment during Progression from MGUS to Multiple Myeloma	"The role of the bone marrow microenvironment (BME) in the transition from monoclonal gammopathy of undetermined significance (MGUS) into clinically active multiple myeloma (MM) is not completely determined. To address this issue, we performed single-cell RNA sequencing (scRNA-seq) of non-hematopoietic BME cells as well as plasma cells (PC) from two genetically engineered mouse models of MM termed BIc{gamma}1and MIc{gamma}1that recapitulate the progression of MGUS into MM. Our results identify distinct transcriptional dynamics between endothelial cells (EC) and mesenchymal stem cells (MSC). While EC acquire a stress state during MGUS, a proliferating and angiogenic profile characterizes MM. On the other hand, MSC compromised their differentiation potential, exhibiting a more inflammatory profile that initiates from the MGUS stage. Interestingly, we identified an interferon (IFN)-related myeloma signature in malignant EC of the BIc{gamma}1model, which is also expressed in MSC but not observed in the more aggressive MIc{gamma}1model and can be identified in MSC from a subgroup of MM patients. The analysis of the EC and MSC interactions with malignant PC revealed stage-specific interactions that contribute to angiogenesis, immunomodulation, and MM extravasation. Finally, the translational relevance of our results in humans was confirmed on MSC from newly diagnosed patients with monoclonal gammopathies at different stages of the disease. In summary, these results show a remodeling of the non-hematopoietic BME in MM progression, providing potential targets at the tumor-niche interface that may hold clinical significance and complement existing immunotherapies.    O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=84 SRC=""FIGDIR/small/589777v3_ufig1.gif"" ALT=""Figure 1""> View larger version (31K): org.highwire.dtl.DTLVardef@15c2133org.highwire.dtl.DTLVardef@187b9b7org.highwire.dtl.DTLVardef@1b1ac86org.highwire.dtl.DTLVardef@1b5af01_HPS_FORMAT_FIGEXP  M_FIG C_FIG KEY POINTSO_LIEC stress pre-vascular state in MGUS, shifts to angiogenic in MM, while MSC early transcriptional changes in MGUS persist in overt MM. C_LIO_LIIdentification of a myeloma-specific IFN signature in the non-hematopoietic BME that could define a subgroup of MM patients. C_LI"	cancer_biology bone 1b5af01_hps_format_figexp myeloma immunotherapies marrow immunomodulation endothelial tumor transcriptional		2024-04-25								cc_by_nc_nd			Felipe Prosper	54	0
Nonlinear progression across the occult transition establishes cancer lethality	"Cancer screening is based upon a linear model of growth and invasion. Yet, early dissemination during the lengthy pre-diagnostic phase suggests that nonlinearity in growth can also occur. Therefore, we quantitatively traced the invisible and visible phases of tumorigenesis in the mammary gland for more than two-thousand tumors. Dynamic mathematical models of the invisible phase revealed an occult checkpoint resulting in nonlinear progression of transformed field cells. We found that expansile fields have increased dwell time at the occult checkpoint resulting in a large reservoir of image detectable precursors prior to invasion. In contrast, slowly proliferating lesions disseminate early and then transition rapidly through an occult checkpoint in a process we term nascent lethality. Our data illustrate how nonlinear growth across an occult checkpoint can account for a paradoxical increase in early-stage cancer detection without a dramatic reduction in metastatic burden.  Graphical Abstract  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=160 SRC=""FIGDIR/small/590826v1_ufig1.gif"" ALT=""Figure 1""> View larger version (46K): org.highwire.dtl.DTLVardef@1ebefe2org.highwire.dtl.DTLVardef@d1efd4org.highwire.dtl.DTLVardef@d84bd2org.highwire.dtl.DTLVardef@59cf9b_HPS_FORMAT_FIGEXP  M_FIG C_FIG HighlightsO_LIGrowth during the invisible phase of tumorigenesis is a nonlinear process C_LIO_LIField size and field growth rate are uncoupled from metastatic potential C_LIO_LIOccult transition rates vary by genotype C_LIO_LINascent lethal lesions are currently undetectable C_LI"	cancer_biology tumorigenesis transition lethality occult nonlinear tumors 59cf9b_hps_format_figexp cancer d84bd2org		2024-04-25								cc_no			Joshua C Snyder	55	0
An Alternatively Spliced Gain-of-Function NT5C2 Isoform Contributes to Thiopurine Resistance in Acute Lymphoblastic Leukemia	"Relapse-specific mutations do not account for all chemotherapy failures in patients with B-cell acute lymphoblastic leukemia (B-ALL). By mining RNA-seq datasets of paired diagnostic/relapse pediatric B-ALL samples, we discovered pervasive alternative splicing (AS) patterns linked to relapse and affecting drivers of resistance to glucocorticoids, anti-folates, and thiopurines. Most splicing variations represent exon skipping, ""poison"" exon inclusion, and intron retention, phenocopying well-documented loss-of-function mutations. In contrast, relapse-associated AS of NT5C2 mRNA yields an isoform with a cryptic 24-nt in-frame exon 6a. Inclusion of the extra 8 amino acids into this enzyme results in elevated nucleosidase activity, a known consequence of gain-of-function mutations in NT5C2 and a common determinant of 6-mercaptopurine resistance. Furthermore, in B-ALL cells NT5C2ex6a and the R238W hotspot variant confers comparable levels of resistance to 6-mercaptopurine in vitro and in vivo. These results support a role for alternative splicing as a prevalent mechanism driving chemotherapy resistance in relapsed B-ALL.  Statement of significanceMutations in chemoresistance genes are found in relapsed/refractory acute lymphoblastic leukemia. However, in this low-mutational-burden disease, up to 30% of cases have no known relapse-specific genetic alterations. Our identification of aberrant splicing as an alternative mechanism of acquired drug resistance fills this gap and suggests new opportunities for therapeutic interventions."	cancer_biology genetic mutations leukemia spliced chemotherapy thiopurine nt5c2 lymphoblastic		2024-04-18								cc_no			Andrei Thomas-Tikhonenko	56	0
KSR1 regulates small-cell lung carcinoma tumor initiation and therapy resistance	Small-cell lung cancer (SCLC) is designated a recalcitrant cancer due to its five-year relative survival rate of less than 7%. First line SCLC treatment has changed modestly in the last 40 years. The NeuroD1 subtype of SCLC (SCLC-N) commonly harbors MYC amplifications and other hallmarks of aggressive behavior. Finding novel therapeutic options that effectively eliminate residual disease observed after initial response to therapy is essential to improving SCLC patient outcome. Here we show that Kinase Suppressor of Ras 1 (KSR1), a molecular scaffold for the Raf/MEK/ERK signaling cascade is critical for clonogenicity and tumor initiation in vitro and in vivo in the highly aggressive, metastatic and therapy resistant NeuroD1 subtype of SCLC. Tumor-initiating cells (TICs) are reported as the sanctuary population within the bulk tumor responsible for therapeutic resistance and relapse. Previous studies concluded ERK activation was inhibitory to growth and tumor development. We show that signaling through KSR1 is conserved in SCLC-N and that it regulates tumor initiation through interaction with ERK. We further show that KSR1 mediates cisplatin resistance in SCLC-N cells. While 50% of control SCLC-N cells show resistance after 6 weeks of exposure to cisplatin, CRISPR/Cas9-mediated KSR1 knockout prevents resistance in >90% of SCLC-N cells. KSR1 KO also significantly enhances the ability of cisplatin to decrease SCLC-N TICs, indicating that targeting KSR1 might be selectively toxic to cells responsible for therapeutic resistance and tumor initiation. Thus, KSR1 function in SCLC-N serves as a novel model for understanding the role of KSR1-dependent signaling in normal and malignant tissues. These findings shed light on a key distinct protein responsible for regulation in SCLC-N tumors, and a potential subtype specific therapeutic target.  ImpactGenetic manipulation of the MAPK molecular scaffold, KSR1 in NeuroD1-subtype small-cell lung cancer cells reveals its contribution to cisplatin resistance in tumor initiation via ERK signaling.	cancer_biology lung cell relapse carcinoma therapy malignant tumors cancer tumor		2024-04-11								cc_no			Robert E Lewis	57	0
The neuroendocrine transition in prostate cancer is dynamic and dependent on ASCL1	Lineage plasticity is a recognized hallmark of cancer progression that can shape therapy outcomes. The underlying cellular and molecular mechanisms mediating lineage plasticity remain poorly understood. Here, we describe a versatile in vivo platform to identify and interrogate the molecular determinants of neuroendocrine lineage transformation at different stages of prostate cancer progression. Adenocarcinomas reliably develop following orthotopic transplantation of primary mouse prostate organoids acutely engineered with human-relevant driver alterations (e.g., Rb1-/-; Trp53-/-; cMyc+ or Pten-/-; Trp53-/-; cMyc+), but only those with Rb1 deletion progress to ASCL1+ neuroendocrine prostate cancer (NEPC), a highly aggressive, androgen receptor signaling inhibitor (ARSI)-resistant tumor. Importantly, we show this lineage transition requires a native in vivo microenvironment not replicated by conventional organoid culture. By integrating multiplexed immunofluorescence, spatial transcriptomics and PrismSpot to identify cell type-specific spatial gene modules, we reveal that ASCL1+ cells arise from KRT8+ luminal epithelial cells that progressively acquire transcriptional heterogeneity, producing large ASCL1+;KRT8- NEPC clusters. Ascl1 loss in established NEPC results in transient tumor regression followed by recurrence; however, Ascl1 deletion prior to transplantation completely abrogates lineage plasticity, yielding adenocarcinomas with elevated AR expression and marked sensitivity to castration. The dynamic feature of this model reveals the importance of timing of therapies focused on lineage plasticity and offers a platform for identification of additional lineage plasticity drivers.	cancer_biology transition tumor ascl1 adenocarcinomas prostate transcriptomics cancer neuroendocrine immunofluorescence		2024-04-11								cc_by			Charles Sawyers	58	0
Establishing the foundations for a data-centric AI approach for virtual drug screening through a systematic assessment of the properties of chemical data	Researchers have adopted model-centric artificial intelligence (AI) approaches in cheminformatics by using newer, more sophisticated AI methods to take advantage of growing chemical libraries. It has been shown that complex deep learning methods outperform conventional machine learning (ML) methods in QSAR and ligand-based virtual screening1-3 but such approaches generally lack explanability. Hence, instead of developing more sophisticated AI methods (i.e., pursuing a model-centric approach), we wanted to explore the potential of a data-centric AI paradigm for virtual screening. A data-centric AI is an intelligent system that would automatically identify the right type of data to collect, clean and curate for later use by a predictive AI and this is required given the large volumes of chemical data that exist in chemical databases - PubChem alone has over 100 million unique compounds. However, a systematic assessment of the attributes and properties of suitable data is needed. We show here that it is not the result of deficiencies in current AI algorithms but rather, poor understanding and erroneous use of chemical data that ultimately leads to poor predictive performance. Using a new benchmark dataset of BRAF ligands that we developed, we show that our best performing predictive model can achieve an unprecedented accuracy of 99% with a conventional ML algorithm (SVM) using a merged molecular representation (Extended+ ECFP6 fingerprints), far surpassing past performances of virtual screening platforms using sophisticated deep learning methods. Thus, we demonstrate that it is not necessary to resort to the use of sophisticated deep learning algorithms for virtual screening because conventional ML can perform exceptionally well if given the right data and representation. We also show that the common use of decoys for training leads to high false positive rates and its use for testing will result in an over-optimistic estimation of a models predictive performance. Another common practice in virtual screening is defining compounds that are above a certain pharmacological threshold as inactives. Here, we show that the use of these so-called inactive compounds lowers a models sensitivity/recall. Considering that some target proteins have a limited number of known ligands, we wanted to also observe how the size and composition of the training data impact predictive performance. We found that an imbalance training dataset where inactives outnumber actives led to a decrease in recall but an increase in precision, regardless of the model or molecular representation used; and overall, we observed a decrease in the models accuracy. We highlight in this study some of the considerations that one needs to take into account in future development of data-centric AI for CADD.	cancer_biology researchers cheminformatics screening chemical pharmacological algorithm virtual algorithms assessment drug		2024-04-04								cc_by			Allen Chong	59	0
Vesicle-mediated mitochondrial clearance underlies an actionable metabolic vulnerability in triple-negative breast cancer	Selective autophagy of mitochondria is known to promote survival and progression of cancer cells in various malignancies including triple-negative breast cancer (TNBC). Here, we aimed to identify the essential metabolic adaptations that support mitochondrial quality control with the goal to uncover actionable metabolic vulnerabilities with therapeutic potential. Using an integrated approach of proteomics and untargeted and stable-isotope resolved metabolomics, coupled with functional experimental analyses, we define an alternative mechanism to mitophagy enabled by an onco-metabolic program of heightened extracellular sphingomyelin salvaging in TNBC that facilitates extracellular vesicle (EV)-mediated intracellular clearance of mitochondrial damage. Targeting of the cancer cell sphingolipid onco-metabolic pathway via repurposing of eliglustat, a selective small molecule inhibitor of glucosylceramide synthase (UGCG), resulted in ceramide-induced lethal mitophagy and attenuated tumor growth and prolonged overall survival at clinically achievable doses in an orthotopic syngeneic mouse model of TNBC. Our study defines a mechanism of aberrant sphingolipid metabolism that underlies an actionable metabolic vulnerability for anti-cancer treatment.	metabolic cancer_biology triple breast mitochondria sphingomyelin proteomics mitochondrial cancer tumor		2024-04-04								cc_no			Johannes F Fahrmann	60	0
Onco-Circuit Addiction and Onco-Nutrient mTORC1 Signaling Vulnerability in a Model of Aggressive T Cell Malignancy	How genetic lesions drive cell transformation and whether they can be circumvented without compromising function of non-transformed cells are enduring questions in oncology. Here we show that in mature T cells--in which physiologic clonal proliferation is a cardinal feature-- constitutive MYC transcription and Tsc1 loss in mice modeled aggressive human malignancy by reinforcing each others oncogenic programs. This cooperation was supported by MYC-induced large neutral amino acid transporter chaperone SLC3A2 and dietary leucine, which in synergy with Tsc1 deletion overstimulated mTORC1 to promote mitochondrial fitness and MYC protein overexpression in a positive feedback circuit. A low leucine diet was therapeutic even in late-stage disease but did not hinder T cell immunity to infectious challenge, nor impede T cell transformation driven by constitutive nutrient mTORC1 signaling via Depdc5 loss. Thus, mTORC1 signaling hypersensitivity to leucine as an onco-nutrient enables an onco-circuit, decoupling pathologic from physiologic utilization of nutrient acquisition pathways.	cancer_biology malignancy genetic aggressive oncology vulnerability addiction disease mtorc1 physiologic pathologic		2024-04-04								cc_no			Ming O Li	61	0
Small extracellular vesicles promote stiffness-mediated metastasis	"Tissue stiffness is a critical prognostic factor in breast cancer and is associated with metastatic progression. Here we show an alternative and complementary hypothesis of tumor progression whereby physiological matrix stiffness affects the quantity and protein cargo of small EVs produced by cancer cells, which in turn drive their metastasis. Primary patient breast tissue produces significantly more EVs from stiff tumor tissue than soft tumor adjacent tissue. EVs released by cancer cells on matrices that model human breast tumors (25 kPa; stiff EVs) feature increased adhesion molecule presentation (ITG2{beta}1, ITG6{beta}4, ITG6{beta}1, CD44) compared to EVs from softer normal tissue (0.5 kPa; soft EVs), which facilitates their binding to extracellular matrix (ECM) protein collagen IV, and a 3-fold increase in homing ability to distant organs in mice. In a zebrafish xenograft model, stiff EVs aid cancer cell dissemination through enhanced chemotaxis. Moreover, normal, resident lung fibroblasts treated with stiff and soft EVs change their gene expression profiles to adopt a cancer associated fibroblast (CAF) phenotype. These findings show that EV quantity, cargo, and function depend heavily on the mechanical properties of the extracellular microenvironment.  Graphical Abstract  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=200 SRC=""FIGDIR/small/545937v3_ufig1.gif"" ALT=""Figure 1""> View larger version (42K): org.highwire.dtl.DTLVardef@1be1dbdorg.highwire.dtl.DTLVardef@928710org.highwire.dtl.DTLVardef@1e14e9borg.highwire.dtl.DTLVardef@efdb7f_HPS_FORMAT_FIGEXP  M_FIG C_FIG"	cancer_biology mediated fibroblasts stiffness efdb7f_hps_format_figexp metastasis tumors vesicles cancer tumor extracellular		2024-03-28								cc_no			Denis Wirtz	62	0
Tumor-infiltrating nerves functionally alter brain circuits and modulate behavior in a male mouse model of head-and-neck cancer	Cancer patients often experience changes in mental health, prompting an exploration into whether nerves infiltrating tumors contribute to these alterations by impacting brain functions. Using a mouse model for head and neck cancer and neuronal tracing we show that tumor-infiltrating nerves connect to distinct brain areas. The activation of this neuronal circuitry altered behaviors (decreased nest-building, increased latency to eat a cookie, and reduced wheel running). Tumor-infiltrating nociceptor neurons exhibited heightened calcium activity and brain regions receiving these neural projections showed elevated Fos as well as increased calcium responses compared to non-tumor-bearing counterparts.  The genetic elimination of nociceptor neurons decreased brain Fos expression and mitigated the behavioral alterations induced by the presence of the tumor. While analgesic treatment restored nesting and cookie test behaviors, it did not fully restore voluntary wheel running indicating that pain is not the exclusive driver of such behavioral shifts. Unraveling the interaction between the tumor, infiltrating nerves, and the brain is pivotal to developing targeted interventions to alleviate the mental health burdens associated with cancer.  Significance StatementHead and neck cancers are infiltrated by sensory nerves which connect to a pre-existing circuit that includes areas in the brain. Neurons within this circuit are altered and mediate modifications in behavior.	infiltrating cancer_biology brain cancers mouse tumors cancer tumor		2024-03-28								cc_by_nc_nd			Paola Drapkin Vermeer	63	0
Multiplexed 3D Analysis of Immune States and Niches in Human Tissue	"Tissue homeostasis and the emergence of disease are controlled by changes in the proportions of resident and recruited cells, their organization into cellular neighbourhoods, and their interactions with acellular tissue components. Highly multiplexed tissue profiling (spatial omics)1 makes it possible to study this microenvironment in situ, usually in 4-5 micron thick sections (the standard histopathology format)2. Microscopy-based tissue profiling is commonly performed at a resolution sufficient to determine cell types but not to detect subtle morphological features associated with cytoskeletal reorganisation, juxtracrine signalling, or membrane trafficking3. Here we describe a high-resolution 3D imaging approach able to characterize a wide variety of organelles and structures at sub-micron scale while simultaneously quantifying millimetre-scale spatial features. This approach combines cyclic immunofluorescence (CyCIF) imaging4 of over 50 markers with confocal microscopy of archival human tissue thick enough (30-40 microns) to fully encompass two or more layers of intact cells. 3D imaging of entire cell volumes substantially improves the accuracy of cell phenotyping and allows cell proximity to be scored using plasma membrane apposition, not just nuclear position. In pre-invasive melanoma in situ5, precise phenotyping shows that adjacent melanocytic cells are plastic in state and participate in tightly localised niches of interferon signalling near sites of initial invasion into the underlying dermis. In this and metastatic melanoma, mature and precursor T cells engage in an unexpectedly diverse array of juxtracrine and membrane-membrane interactions as well as looser ""neighbourhood"" associations6 whose morphologies reveal functional states. These data provide new insight into the transitions occurring during early tumour formation and immunoediting and demonstrate the potential for phenotyping of tissues at a level of detail previously restricted to cultured cells and organoids."	tissue cancer_biology melanoma 3d imaging4 immune multiplexed human microscopy immunofluorescence immunoediting		2024-03-28								cc_by_nc_nd			Peter Karl Sorger	64	0
Three-dimensional assessments are necessary to determine the true, spatially-resolved composition of tissues	Methods for spatially resolved cellular profiling using thinly cut sections have enabled in-depth quantitative tissue mapping to study inter-sample and intra-sample differences in normal human anatomy and disease onset and progression. These methods often profile extremely limited regions, which may impact the evaluation of heterogeneity due to tissue sub-sampling. Here, we applied CODA, a deep learning-based tissue mapping platform, to reconstruct the three-dimensional (3D) microanatomy of grossly normal and cancer-containing human pancreas biospecimens obtained from individuals who underwent pancreatic resection. To compare inter-and intra-sample heterogeneity, we assessed bulk and spatially resolved tissue composition in a cohort of two-dimensional (2D) whole slide images (WSIs) and a cohort of thick slabs of pancreas tissue that were digitally reconstructed in 3D from serial sections. To demonstrate the marked under sampling of 2D assessments, we simulated the number of WSIs and tissue microarrays (TMAs) necessary to represent the compositional heterogeneity of 3D data within 10% error to reveal that tens of WSIs and hundreds of TMA cores are sometimes needed. We show that spatial correlation of different pancreatic structures decay significantly within a span of microns, demonstrating that 2D histological sections may not be representative of their neighboring tissues. In sum, we demonstrate that 3D assessments are necessary to accurately assess tissue composition in normal and abnormal specimens and in order to accurately determine neoplastic content. These results emphasize the importance of intra-sample heterogeneity in tissue mapping efforts.	cancer_biology anatomy pancreatic microanatomy pancreas necessary tissues composition cancer spatially assessments		2024-03-28								cc_by_nd			Denis Wirtz	65	0
Spatial Effects of Infiltrating T cells on Neighbouring Cancer Cells and Prognosis in Stage III CRC patients	Colorectal cancer (CRC) is one of the most frequently occurring cancers, but prognostic biomarkers identifying patients at risk of recurrence are still lacking. In this study, we aimed to investigate in more detail the spatial relationship between intratumoural T cells, cancer cells, and cancer cell hallmarks, as prognostic biomarkers in stage III colorectal cancer patients. We conducted multiplexed imaging of 56 protein markers at single cell resolution on resected fixed tissue from stage III CRC patients who received adjuvant 5-fluorouracil-based chemotherapy. Images underwent segmentation for tumour, stroma and immune cells, and cancer cell  state protein marker expression was quantified at a cellular level. We developed a Python package for estimation of spatial proximity, nearest neighbour analysis focusing on cancer cell - T cell interactions at single-cell level. In our discovery cohort (MSK), we processed 462 core samples (total number of cells: 1,669,228) from 221 adjuvant 5FU-treated stage III patients. The validation cohort (HV) consisted of 272 samples (total number of cells: 853,398) from 98 stage III CRC patients. While there were trends for an association between percentage of cytotoxic T cells (across the whole cancer core), it did not reach significance (Discovery cohort: p = 0.07, Validation cohort: p = 0.19). We next utilized our region-based nearest neighbourhood approach to determine the spatial relationships between cytotoxic T cells, helper T cells and cancer cell clusters. In the both cohorts, we found that lower distance between cytotoxic T cells, T helper cells and cancer cells was significantly associated with increased disease-free survival. An unsupervised trained model that clustered patients based on the median distance between immune cells and cancer cells, as well as protein expression profiles, successfully classified patients into low-risk and high-risk groups (Discovery cohort: p = 0.01, Validation cohort: p = 0.003).	cancer_biology biomarkers tumour prognosis cells stage cancers patients chemotherapy cancer		2024-03-28								cc_by_nc_nd			Jochen H. M. Prehn	66	0
Effect of C-to-T transition at CpG sites on tumor suppressor genes in tumor development in cattle evaluated by somatic mutation analysis in enzootic bovine leukosis	Oncogenic transformation of normal cells is caused by mutations and chromosomal abnormalities in cancer-related genes. Enzootic bovine leukosis (EBL) is a malignant B-cell lymphoma caused by bovine leukemia virus (BLV) infection in cattle. Although a small fraction of BLV-infected cattle develops EBL after a long latent period, the mechanisms for oncogenesis in EBL cattle remain largely unknown. In this study, we analyzed the types and patterns of somatic mutations in cancer cells from 36 EBL cases, targeting 21 cancer-related genes. Various somatic mutations were identified in 8 genes, TP53, NOTCH1, KMT2D, CREBBP, KRAS, PTEN, CARD11, and MYD88. In addition, TP53 gene was found to be mutated in 69.4% of EBL cases, with most being biallelic mutations. In some cases, associations were observed between the ages at which cattle had developed EBL and somatic mutation patterns; young onset of EBL possibly occurs due to congenital mutations, high impact mutations affecting protein translation, and biallelic mutations. Furthermore, nucleotide substitution patterns indicated that cytosine at CpG sites tended to be converted to thymine in many EBL cases, which was considered to be the result of spontaneous deamination of 5-methylctosine. These results demonstrate how somatic mutations have occurred in cancer cells leading to EBL development, thereby explaining its pathogenic mechanism. These findings will contribute to a better understanding and future elucidation of disease progression in BLV infection.  ImportanceEnzootic bovine leukosis (EBL) is a malignant and lethal disease in cattle. Currently, there are no effective vaccines or therapeutic methods against bovine leukemia virus (BLV) infection, resulting in severe economic losses in livestock industry. This study provides a renewed hypothesis to explain the general mechanisms of EBL onset by combining the previous finding that several integration sites of BLV provirus can affect the increase in survival and proliferation of infected cells. We demonstrate that two additional random events are necessary for oncogenic transformation in infected cell clones, elucidating the reason why only few infected cattle develop EBL. Further exploration of somatic mutation and BLV integration sites could support this hypothesis more firmly, potentially contributing to the development of novel control methods for EBL onset.	cancer_biology genes lymphoma virus cattle leukosis provirus leukemia cancer tumor bovine		2024-03-28								cc_by_nc_nd			Asami Nishimori	67	0
Stochastic variation in the FOXM1 transcription program mediates replication stress tolerance.	Oncogene-induced replication stress (RS) is a vulnerability of cancer cells that forces reliance on the intra-S-phase checkpoint to ensure faithful genome duplication. Inhibitors of the crucial intra-S-phase checkpoint kinases ATR and CHK1 have been developed, but persistent proliferation and resistance to these drugs remain problematic. Understanding drug tolerance mechanisms is impeded by analysis of bulk samples, which neglect tumor heterogeneity and often fail to accurately interpret cell cycle-mediated resistance. Here, by combining intracellular immunostaining and RNA-sequencing of single cells, we characterized the transcriptomes of oncogenic RAS-expressing cells that exhibit variable levels of RS when challenged with a CHK1 inhibitor in combination with the chemotherapeutic drug gemcitabine. We identified 40 genes differentially expressed between tolerant and sensitive cells, including several FOXM1 target genes. While complete knockdown of FOXM1 impeded cell proliferation, a partial knockdown protected cells against DNA damage, and improved recovery from drug-induced RS. Our results suggest that low levels of FOXM1 expression protects subsets of oncogenic RAS-expressing cells against DNA damage during drug-induced replication stress.	cancer_biology stress transcription stochastic dna replication mediates transcriptomes immunostaining cancer tumor		2024-03-28								cc_by_nc_nd			Bart Westendorp	68	0
Fatty acids are not a significant contributor to the TCA cycle in cancer cell lines: evidence of incomplete fatty acid oxidation.	Fatty acid (FA) oxidation (FAO) is upregulated in many cancers, which has been contextualised to thereby be significantly fuel the TCA cycle and generate vast amounts of ATP to support cancer cell viability. However, direct evidence of this is lacking. Here, we set out to determine the capacity of FAO in a pan-cancer setting and if this relates to the amount of carbon FAO contributes to the TCA cycle relative to other substrates. We profiled the baseline FAO rate and capacity of 27 cancer cell lines from 10 tissue origins, and then selected 6 cancer cell lines that represented the diversity of this panel. Despite the diverse range of FAO rates, we consistently found that exogenous long-chain FAs (LCFAs) were a minor (<10%) TCA cycle substrate in all cells compared to glucose and glutamine. Glucose withdrawal significantly increased FAO rates, while glucose and/or glutamine deprivation marginally increased incorporation of 13C-palmitate into TCA cycle metabolites. Palmitate alone modestly assisted cataplerosis but did not sustain TCA cycle fluxes, leading to reduced cell viability. The low contribution of fatty acids to the TCA cycle in cancer cells may be explained by incomplete oxidation of LCFAs of varying chain lengths of saturations to produce shortened acyl-carnitines. Overall, our results provide significant insights into mitochondrial FA metabolism in cultured cancer cells and challenges the belief that the oxidation of FAs is a complete process, contributing significant fuel for the TCA cycle and ATP generation.	cancer_biology upregulated cell oxidation cancers cataplerosis incomplete fatty cancer atp		2024-03-28								cc_by_nd			Andrew J Hoy	69	0
Stable and Oscillatory Hypoxia Differentially Regulate Invasibility of Breast Cancer Associated Fibroblasts	"As local regions in the tumor outstrip their oxygen supply, hypoxia can develop, affecting not only the cancer cells, but also other cells in the microenvironment, including cancer associated fibroblasts (CAFs). Hypoxia is also not necessarily stable over time, and can fluctuate or oscillate. Hypoxia Inducible Factor-1 is the master regulator of cellular response to hypoxia, and can also exhibit oscillations in its activity. To understand how stable, and fluctuating hypoxia influence breast CAFs, we measured changes in gene expression in CAFs in normoxia, hypoxia, and oscillatory hypoxia, as well as measured change in their capacity to resist, or assist breast cancer invasion. We show that hypoxia has a profound effect on breast CAFs causing activation of key pathways associated with fibroblast activation, but reduce myofibroblast activation and traction force generation. We also found that oscillatory hypoxia, while expectedly resulted in a ""sub-hypoxic"" response in gene expression, it resulted in specific activation of pathways associated with actin polymerization and actomyosin maturation. Using traction force microscopy, and a nanopatterned stromal invasion assay, we show that oscillatory hypoxia increases contractile force generation vs stable hypoxia, and increases heterogeneity in force generation response, while also additively enhancing invasibility of CAFs to MDA-MB-231 invasion. Our data show that stable and unstable hypoxia can regulate many mechnobiological characteristics of CAFs, and can contribute to transformation of CAFs to assist cancer dissemination and onset of metastasis."	cancer_biology breast hypoxic oscillatory fibroblasts cancer tumor hypoxia		2024-03-28								cc_by_nc_nd			Kshitiz	70	0
Advancing CAR T-Cell Therapy: Simultaneously Attack Tumor and Immunosuppressive Cells in the Tumor Microenvironment	Chimeric antigen receptor (CAR) T-cell therapy has encountered limited success in solid tumors. The lack of dependable antigens and the immunosuppressive tumor microenvironment (TME) are major challenges. Within the TME, tumor cells along with immunosuppressive cells employ an immune-evasion mechanism that upregulates programmed death ligand 1 (PD-L1) to deactivate effector T cells; this makes PD-L1 a reliable, universal target for solid tumors. We developed a novel PD-L1 CAR (MC9999) using our humanized anti-PD-L1 monoclonal antibody, designed to simultaneously target tumor and immunosuppressive cells. The antigen-specific antitumor effects of MC9999 CAR T-cells were observed consistently across four solid tumor models: breast cancer, lung cancer, melanoma, and glioblastoma multiforme (GBM). Notably, intravenous administration of MC9999 CAR T-cells eradicated intracranially established LN229 GBM tumors, suggesting penetration of the blood-brain barrier. The proof-of-concept data demonstrate the cytolytic effect of MC9999 CAR T-cells against immunosuppressive cells, including microglia HMC3 cells and M2 macrophages. Furthermore, MC9999 CAR T-cells elicited cytotoxicity against primary tumor-associated macrophages within GBM tumors. The concept of targeting both tumor and immunosuppressive cells with MC9999 was further validated using CAR T-cells derived from cancer patients. These findings establish MC9999 as a foundation for the development of effective CAR T-cell therapies against solid tumors.	cancer_biology immunosuppressive advancing attack therapy glioblastoma tumors cancer tumor		2024-03-28								cc_no			Hong Qin	71	0
ANP32E drives vulnerability to ATR inhibitors by inducing R-loops-dependent Transcription Replication Conflicts in Triple Negative Breast Cancer	Oncogene-induced replicative stress (RS) plays a central role in tumor progression, leading to genomic instability by eliciting transcription replication conflicts (TRCs), which represent the major source of R-loops, that ultimately favors the onset of the DNA damage response (DDR). We investigated the pathogenic contribution of chromatin factors in increasing TRCs and R-loop frequencies in cancer. We found that in breast cancer patients the concomitant upregulation of MYC and the H2A.Z-specific chaperone ANP32E correlated with an increase genome instability. Genome-wide profiling revealed that the ANP32E-dependent increases turnover of H2A.Z altered RNApol II processivity, leading to accumulation of long R-loops at TRCs. We showed that ANP32E upregulation increases TRCs and activates an ATR-dependent DDR, which predispose cancer cells to R-loop-mediated genomic fragility. By exploiting the vulnerability of ANP32E-expressing cancer cells to ATR inhibitors, we found that tumors relied on this DDR pathway, whose inhibition halted their pro-metastatic capacity.	cancer_biology transcription breast dna anp32e genome tumors inhibitors cancer tumor		2024-03-28								cc_no			alessio Zippo	72	0
Mutational synergy with CREBBP loss in lymphomagenesis identified through forward insertional mutagenesis in a new DLBCL mouse model	Loss-of-function mutations in the gene encoding the acetyltransferase CREBBP have been reported in numerous cancers but are particularly frequent in lymphoid malignancies. However, the functional significance of CREBBP loss in transformation and disease progression, most likely through cooperation with secondary genetic hits, has not yet been fully unravelled. Similarly, the contribution of the initial cell population sustaining CREBBP loss in the course of disease remains elusive. Here, we developed a new lymphoma mouse model integrating Crebbp loss at various stages of B cell development with a transposon-based insertional mutagenesis system. We demonstrated that Crebbp loss from the HSPC compartment resulted in an aggressive DLBCL-like disease, recapitulating well-characterised histological and molecular features of the human disease, as well as the recently described enhanced CD24 expression. More importantly, we identified candidate genes functionally equivalent to patient mutated genes. Those genes, mainly related to B cell development and cellular signalling, may represent novel therapeutic targets. Overall, this new model provides a powerful resource in which to conduct future mechanistic and therapeutic studies.	cancer_biology lymphoma insertional malignancies disease mutagenesis mouse cancers mutational lymphomagenesis lymphoid		2024-03-28								cc_by			Brian J P Huntly	73	0
HNF&alpha is a target of the Wnt/beta-catenin pathway and regulates colorectal carcinogenesis	Hepatocyte nuclear factor 4alpha (HNF4) is a transcription factor involved in liver function. Dysregulation of HNF4 leads to hepatocarcinogenesis. However, the role and mechanism of HNF4 in colorectal cancer is still unknown. Here we demonstrate that HNF4 is upregulated in colorectal cancers. and HNF4 upregulation promotes colorectal tumorigenesis. Notably, expression levels of HNF4 are positively correlated with the Wnt/{beta}-catenin signaling pathway in colorectal cancer patients. Further, we showed that HNF4 is transcriptionally activated by Wnt/{beta}-catenin/TCF3 and is at least partially responsible for the oncognesis activity of the Wnt signaling in colorectal cancer. Our findings indicate that HNF4 is a direct target of that Wnt/{beta}-catenin pathway and could play an important role in colorectal carcinogenesis.  Author SummaryHere we demonstrate that HNF4 is upregulated in colorectal cancers and HNF4 upregulation promotes colorectal tumorigenesis. Notably, expression level of HNF4 are positively correlated with the Wnt/{beta}-catenin pathway in colorectal cancer patients. Further, we showed that HNF4 is transcriptionally activated by Wnt/{beta}-catenin/TCF3 and is at least partially responsible for the oncognesis activity of the Wnt signaling pathway in colorectal cancer.	cancer_biology tumorigenesis alpha carcinogenesis catenin colorectal hepatocarcinogenesis beta cancers cancer		2024-03-28								cc_by			Jianwei Sun	74	0
A 3D in vitro assay to study combined immune cell infiltration and cytotoxicity	"Immune cell-mediated killing of cancer cells in a solid tumor is prefaced by a multi-step infiltration cascade of invasion, directed migration, and cytotoxic activities. In particular, immune cells must invade and migrate through a series of different extracellular matrix (ECM) boundaries and domains before reaching and killing their target tumor cells. These infiltration events are a central challenge to the clinical success of CAR T cells against solid tumors. The current standard in vitro cell killing assays measure cell cytotoxicity in an obstacle-free, two-dimensional (2D) microenvironment, which precludes the study of 3D immune cell-ECM interactions. Here, we present a 3D combined infiltration/cytotoxicity assay based on an oil-in-water microtechnology. This assay measures stromal invasion following extravasation, migration through the stromal matrix, and invasion of the solid tumor in addition to cell killing. We compare this 3D cytotoxicity assay to the benchmark 2D assay through tumor assembloid cocultures with immune cells and engineered immune cells. This assay is amenable to an array of imaging techniques, which allows direct observation and quantification of each stage of infiltration in different immune and oncological contexts. We establish the 3D infiltration/cytotoxicity assay as an important tool for the mechanistic study of immune cell interactions with the tumor microenvironment.  Graphical Abstract  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=134 SRC=""FIGDIR/small/586980v1_ufig1.gif"" ALT=""Figure 1""> View larger version (61K): org.highwire.dtl.DTLVardef@6a161dorg.highwire.dtl.DTLVardef@d1e5d3org.highwire.dtl.DTLVardef@47b87corg.highwire.dtl.DTLVardef@a0e051_HPS_FORMAT_FIGEXP  M_FIG The 3D combined infiltration/cytotoxicity assay captures three important steps of immune cell infiltration into the solid tumor microenvironment: (1) circulating immune cells extravasate and invade the stromal matrix, (2) immune cells migrate through the stromal matrix to reach the tumor core, and (3) immune cells that successfully navigate the stroma must cross a basement membrane boundary secreted by the cancer cells to contact and kill the cancer cells within a solid tumor.  C_FIG"	cancer_biology cytotoxicity 3d microtechnology cell killing vitro tumors infiltration cancer tumor		2024-03-28								cc_no			Denis Wirtz	75	0
The lipid droplet protein DHRS3 is a regulator of melanoma cell state	Lipid droplets are fat storage organelles composed of a protein envelope and lipid rich core. Regulation of this protein envelope underlies differential lipid droplet formation and function. In melanoma, lipid droplet formation has been linked to tumor progression and metastasis, but it is unknown whether lipid droplet proteins play a role. To address this, we performed proteomic analysis of the lipid droplet envelope in melanoma. We found that lipid droplet proteins were differentially enriched in distinct melanoma states; from melanocytic to undifferentiated. DHRS3, which converts all-trans-retinal to all-trans-retinol, is upregulated in the MITFLO/undifferentiated/neural crest-like melanoma cell state and reduced in the MITFHI/melanocytic state. Increased DHRS3 expression is sufficient to drive MITFHI/melanocytic cells to a more undifferentiated/invasive state. These changes are due to retinoic acid mediated regulation of melanocytic genes. Our data demonstrate that melanoma cell state can be regulated by expression of lipid droplet proteins which affect downstream retinoid signaling.	cancer_biology melanoma organelles lipid protein cell dhrs3 proteins tumor		2024-03-28								cc_no			Richard M White	76	0
NPRL2 gene therapy induces effective antitumor immunity in KRAS/STK11 mutant anti-PD1 resistant metastatic non-small cell lung cancer (NSCLC) in a humanized mouse model	NPRL2/TUSC4 is a tumor suppressor gene whose expression is reduced in many cancers including NSCLC. Restoration of NPRL2 expression in cancer cells induces DNA damage which leads to cell cycle arrest and apoptosis. We investigated the antitumor immune responses to NPRL2 gene therapy in aPD1R/ KRAS/STK11mt NSCLC in a humanized mouse model. Humanized mice were generated by transplanting fresh human cord blood derived CD34 stem cells into sub-lethally irradiated NSG mice. Lung metastases were developed from KRAS/STK11mt/aPD1R A549 cells in humanized mice and treated with NPRL2 gene-loaded cationic lipid nanoparticles (DOTAP-NPRL2) with or without pembrolizumab (aPD1). NPRL2 treatment reduced lung metastases significantly, whereas pembrolizumab was ineffective. The antitumor effect was greater in humanized than non-humanized mice suggesting that an immune response contributed to antitumor activity. NPRL2 combined with pembrolizumab was not synergistic in the KRAS/STK11mt/aPD1R tumors but was synergistic in the KRASwt/aPD1S H1299 tumors. Consistent with the A549 humanized mouse model, NPRL2 showed a significantly strong antitumor effect on KRASmt/aPD1R LLC2 syngeneic tumors, whereas aPD1 was ineffective. The antitumor effect of NPRL2 was correlated with increased infiltration of human cytotoxic immune cells and Ag-presenting HLA-DR+ DC, CD11c DC, and downregulation of myeloid and regulatory T cells in the TME. The antitumor effect of NPRL2 was significantly abolished upon in-vivo depletion of CD8 T, macrophages, and CD4 T cells. However, the antitumor effect remained unaffected upon in-vivo depletion of NK cells. A distinct pattern of gene expression profile was found in lung met after NPRL2 treatment in humanized mice. The expression of genes associated with T cell functions, including IFN{gamma}, CD8b, CD7, TNFSF18, ITGA1, GATA3, and TBX21 was significantly increased, whereas the expression of genes associated with negative regulation of T cell functions, including FOXP3, TGFB1, TGFB2, and IL-10RA were strongly inhibited upon NPRL2 treatment. NPRL2 downregulated the expression of T cell co-inhibitory molecules, including CTLA4, ICOS, LAG3, PDCD1, CD274, IDO1, PDCD1LG2, CD47, and KLRB1. Tumors established from NPRL2 stably expressing cells in humanized mice exhibited significantly slower growth compared to controls. TME analysis showed an increased presence of human CD45+, CD3+ T, CD8+ T cells, and HLA-DR+ dendritic cells and a decreased percentage of Treg, CD3+PD1+T cells, MDSC, and CD163+ TAM in NPRL2-expressing tumors. In-vitro, NPRL2 stably expressing cells showed a substantial increase in colony formation inhibition and heightened sensitivity to carboplatin in colony formation, apoptosis, and PARP cleavage assays. Stable expression of NPRL2 resulted in the downregulation of MAPK and AKT-mTOR growth signaling through inhibition of pAKT, pmTOR, pPRAS40, p4E-BP1, and pS6 expression. Taken together, these data suggest that NPRL2 gene therapy induces antitumor activity on KRAS/STK11mt/aPD1R tumors through DC-mediated antigen presentation and cytotoxic immune cell activation.	cancer_biology myeloid cancers mouse therapy tumors nprl2 cancer tumor mutant		2024-03-28								cc_by_nc_nd			ISMAIL M MERAZ	77	0
Dual-view jointly learning improves personalized drug synergy prediction	BackgroundAccurate and robust estimation of the synergistic drug combination is important for precision medicine. Although some computational methods have been developed, some predictions are still unreliable especially for the cross-dataset predictions, due to the complex mechanism of drug combinations and heterogeneity of cancer samples.  MethodsWe have proposed JointSyn that utilizes dual-view jointly learning to predict sample-specific effects of drug combination from drug and cell features. JointSyn capture the drug synergy related features from two views. One view is the embedding of drug combination on cancer cell lines, and the other view is the combination of two drugs embeddings on cancer cell lines. Finally, the prediction net uses the features learned from the two views to predict the drug synergy of the drug combination on the cell line. In addition, we used the fine-tuning method to improve the JointSyns performance on the unseen subset within a dataset or cross dataset.  ResultsJointSyn outperforms existing state-of-the-art methods in predictive accuracy and robustness across various benchmarks. Each view of JointSyn captures drug synergy-related characteristics and make complementary contributes to the final accurate prediction of drug combination. Moreover, JointSyn with fine-tuning improves its generalization ability to predict a novel drug combination or cancer sample only using a small number of experimental measurements. We also used JointSyn to generate an estimated atlas of drug synergy for pan-cancer and explored the differential pattern among cancers.  ConclusionsThese results demonstrate the potential of JointSyn to predict drug synergy, supporting the development of personalized combinatorial therapies. The source code is available on GitHub at https://github.com/LiHongCSBLab/JointSyn.	cancer_biology therapies prediction medicine cancers combinatorial learning synergy cancer improves drug		2024-03-28								cc_by_nc_nd			Hong Li	78	0
Identifying and targeting key driver genes for collagen production within the 11q13/14 breast cancer amplicon	Genetic studies indicate that breast cancer can be divided into several basic molecular groups. One of these groups, termed IntClust-2, is characterized by amplification of a small portion of chromosome 11 and has a median survival of only five years. Several cancer-relevant genes occupy this portion of chromosome 11, and it is thought that overexpression of a combination of driver genes in this region is responsible for the poor outcome of women in this group. In this study we used a gene editing method to knock out, one by one, each of 198 genes that are located within the amplified region of chromosome 11 and determined how much each of these genes contributed to the survival of breast cancer cells. In addition to well-known drivers such as CCND1 and PAK1, we identified two different genes (SERPINH1 and P4HA3), that encode proteins involved in collagen synthesis and organization. Using both in vitro and in vivo functional analyses, we determined that P4HA3 and/or SERPINH1 provide a critical driver function on IntClust-2 basic processes, such as viability, proliferation, and migration. Inhibiting these enzymes via genetic or pharmacologic means reduced collagen synthesis and impeded oncogenic signaling transduction in cell culture models, and a small-molecule inhibitor of P4HA3 was effective in treating 11q13 tumor growth in an animal model. As collagen has a well-known association with tissue stiffness and aggressive forms of breast cancer, we believe that the two genes we identified provide an opportunity for a new therapeutic strategy in IntClust-2 breast cancers.	cancer_biology genes 14 genetic chromosome breast cancers 11q13 cancer tumor		2024-03-28								cc_no			Jonathan Chernoff	79	0
PTEN and ARID1A haploinsufficiency equip colonic epithelium for oncogenic transformation	Normal aged tissues are thought to exist as a patchwork of mutant clones. However, the relevance of driver mutations in normal tissue in terms of cancer initiation has not been well described. Here, we sought a quantitative understanding of how different cancer drivers achieve an age-related mutational footprint in the human colonic epithelium and to relate the clonal behaviours they generate to cancer risk. Metanalysis of contemporary multiregional sampling studies of colorectal tumours revealed many of the weak or moderate cancer drivers are trunk mutations present in the last common ancestor from which cancers arise. To study the processes by which such driver mutations could contribute to cancer predisposition, immunohistochemistry was used to detect PTEN, SMAD4 and ARID1A deficient clones in normal colon FFPE surgical resection samples (N=182 patients). Age-related changes in clone size and frequency identified positive biases in clone dynamics that acted to increase the mutational footprint for ARID1A and PTEN but not SMAD4. In vitro engineered monoallelic loss of PTEN and ARID1A implicated specific altered downstream pathways and acquired pro-oncogenic cellular fates corresponding to haploinsufficiency for these genes. In situ analysis confirmed enhanced proliferation in both PTEN and ARID1A deficient clones and creation of an immune exclusive microenvironment associated with ARID1A deficiency. The behaviours resulting from haploinsufficiency of PTEN and ARID1A exemplify how priming of the tissue through somatic mosaicism could contribute alternative combinations of genetic events leading to transformation.	epithelium genes haploinsufficiency cancer_biology genetic colonic pten arid1a cancers immunohistochemistry cancer		2024-03-28								cc_by_nd			Douglas J Winton	80	0
A Novel Liver Cancer-Selective Histone Deacetylase Inhibitor Is Effective Against Hepatocellular Carcinoma and Induces Durable Responses with Immunotherapy	"Hepatocellular cancer (HCC) progression is facilitated by gene-silencing chromatin histone hypoacetylation due to histone deacetylases (HDACs) activation. However, inhibiting HDACs -- an effective treatment for lymphomas -- has shown limited success in solid tumors. We report the discovery of a class of HDAC inhibitors (HDACi) that demonstrates exquisite selective cytotoxicity against human HCC cells. The lead compound STR-V-53 (3) showed a favorable safety profile in mice and robustly suppressed tumor growth in orthotopic xenograft models of HCC. When combined with the anti-HCC drug sorafenib, STR-V-53 showed greater in vivo efficacy. Moreover, STR-V-53 combined with anti-PD1 therapy increased the CD8+ to regulatory T-cell (Treg) ratio and survival in an orthotopic HCC model in immunocompetent mice. This combination therapy resulted in durable responses in 40% of the mice. Transcriptomic analysis revealed that STR-V-53 primed HCC cells to immunotherapy through HDAC inhibition, impaired glucose-regulated transcription, impaired DNA synthesis, upregulated apoptosis, and stimulated the immune response pathway. Collectively, our data demonstrate that the novel HDACi STR-V-53 is an effective anti-HCC agent that can induce profound responses when combined with standard immunotherapy.  Graphical Abstract  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=146 SRC=""FIGDIR/small/587062v2_ufig1.gif"" ALT=""Figure 1""> View larger version (28K): org.highwire.dtl.DTLVardef@28281corg.highwire.dtl.DTLVardef@617aa9org.highwire.dtl.DTLVardef@1bc198dorg.highwire.dtl.DTLVardef@31852e_HPS_FORMAT_FIGEXP  M_FIG C_FIG"	cancer_biology immunocompetent hepatocellular carcinoma liver tumors immunotherapy cancer tumor		2024-03-28								cc_no			Adegboyega K Oyelere	81	0
Hypercholesterolemia-induced impairment in sorafenib functionality is overcome by avasimibe co-treatment	Avasimibe; a cholesterol-lowering drug with a proven safety in clinical trials, has recently been repositioned as an anticancer agent in various preclinical investigations. A study from our group reported that hypercholesterolemia promotes hepatocellular carcinoma (HCC) cell survival and hampers the anticancer effect of sorafenib, a kinase inhibitor. In the present study, we demonstrate that in HCC under hypercholesterolemic conditions the anticancer property of sorafenib is potentiated by avasimibe (AVA) co-treatment. Further, to elucidate the role of hypercholesterolemia on sorafenib efficacy, in vitro and in vivo models of HCC were used. In vitro, co-treatment of both drugs synergistically inhibited HCC cell viability and induced cell death under normal and hypercholesterolemic conditions. At the molecular level, downregulation of ERK signalling and induction of endoplasmic reticulum stress are likely to contribute to the combinatorial cytotoxic effect of sorafenib and avasimibe in vitro. In mice, fed on a high-cholesterol diet (HCD), the efficacy of sorafenib was restored by co-administration of AVA. Collectively, these findings suggest that impairment in the efficacy of sorafenib because of hypercholesterolemic phenotype could be restored by AVA co-treatment, which may have implications towards treatment strategy.  HighlightsO_LICholesterol impedes sorafenib efficacy in Hepatocellular carcinoma cells. C_LIO_LIAvasimibe restores the functionality of sorafenib under hypercholesterolemic environment. C_LIO_LICombine treatment of sorafenib and avasimibe synergistically enhances cytotoxicity in hepatocellular carcinoma. C_LIO_LISorafenib and avasimibe treatment in the presence of LDLc.is associated with diminished ERK activation and increased ER stress. C_LI	cancer_biology avasimibe impairment cholesterol hypercholesterolemia hypercholesterolemic carcinoma combinatorial highlightso_licholesterol overcome treatment		2024-03-28								cc_by_nc_nd			Manoj Kumar Bhat	82	0
Novel synthetic ecteinascidins exhibit potent anti-melanoma activity by suppressing super-enhancer-driven oncogenic transcription	The dynamic cellular transitions exhibited by skin cutaneous melanoma (SKCM) cells present a significant challenge to current therapeutic approaches, emphasizing the critical need for innovative treatments. Lurbinectedin, a marine-derived compound belonging to the ecteinascidin family, has recently gained approval for the treatment of metastatic small-cell lung cancer (SCLC). In this study, we demonstrate the efficacy of lurbinectedin against SKCM cells, irrespective of their driver mutations or phenotypic states. Additionally, we have developed two novel derivatives of lurbinectedin, termed ecubectedin and PM54, both of which exhibit potent cytotoxic effects on SKCM cells. Moreover, these analogs demonstrate robust anti-tumor activity in melanoma xenograft models, including those resistant to current therapies, leading to prolonged animal survival. Mechanistically, our investigation reveals that these novel synthetic ecteinascidins markedly suppress oncogenic super-enhancer (SE)-mediated gene expression in SKCM cells through a multifaceted mechanism. They bind to and inhibit the activity of promoters of lineage-specific master transcription factors, as well as promoters of genes encoding ubiquitous transcription factors/coactivators, which are highly enriched at oncogenic SEs. These mechanisms likely synergize to disrupt the expression of cancer-promoting genes. Overall, our findings highlight the potential of synthetic ecteinascidins as promising therapeutics for cancers characterized by diverse transcriptional landscapes, particularly in cases where conventional therapeutic options have failed due to the heterogeneity of malignant cell population	cancer_biology melanoma transcription cancers potent therapeutics ecteinascidins enhancer cancer tumor		2024-03-28								cc_no			Frederic Coin	83	0
Novel synthetic ecteinascidins exhibit potent anti-melanoma activity by suppressing super-enhancer-driven oncogenic transcription	The dynamic cellular transitions exhibited by skin cutaneous melanoma (SKCM) cells present a significant challenge to current therapeutic approaches, emphasizing the critical need for innovative treatments. Lurbinectedin, a marine-derived compound belonging to the ecteinascidin family, has recently gained approval for the treatment of metastatic small-cell lung cancer (SCLC). In this study, we demonstrate the efficacy of lurbinectedin against SKCM cells, irrespective of their driver mutations or phenotypic states. Additionally, we have developed two novel derivatives of lurbinectedin, termed ecubectedin and PM54, both of which exhibit potent cytotoxic effects on SKCM cells. Moreover, these analogs demonstrate robust anti-tumor activity in melanoma xenograft models, including those resistant to current therapies, leading to prolonged animal survival. Mechanistically, our investigation reveals that these novel synthetic ecteinascidins markedly suppress oncogenic super-enhancer (SE)-mediated gene expression in SKCM cells through a multifaceted mechanism. They bind to and inhibit the activity of promoters of lineage-specific master transcription factors, as well as promoters of genes encoding ubiquitous transcription factors/coactivators, which are highly enriched at oncogenic SEs. These mechanisms likely synergize to disrupt the expression of cancer-promoting genes. Overall, our findings highlight the potential of synthetic ecteinascidins as promising therapeutics for cancers characterized by diverse transcriptional landscapes, particularly in cases where conventional therapeutic options have failed due to the heterogeneity of malignant cell population	cancer_biology melanoma transcription cancers potent therapeutics ecteinascidins enhancer cancer tumor		2024-03-28								cc_no			Frederic Coin	84	0
YTHDC1 m6A-dependent and m6A-independent functions converge to preserve DNA damage response.	Cells have evolved a robust and highly regulated DNA damage response to preserve their genomic integrity. Although increasing evidence highlights the relevance of RNA regulation, our understanding of its impact on a fully efficient DNA damage response remains limited. Here, through a targeted CRISPR-knockout screen, we identified RNA binding proteins and modifiers that participate in mediating the p53 response. Among the top hits, m6A reader YTHDC1 was identified as a master regulator of p53 expression. YTHDC1 binds to the transcription start sites of TP53 and other genes involved in DNA damage response, promoting their transcriptional elongation. YTHDC1 deficiency leads to reduced TP53 expression, and also retention of introns leading to aberrant protein production of key DNA damage factors. While intron retention is dependent on m6A, YTHDC1 favors TP53 transcriptional pause-release independently of m6A. Depletion of YTHDC1 causes genomic instability and aberrant cancer cell proliferation mediated by genes regulated by YTHDC1. Our results uncover YTHDC1 as an orchestrator of the DNA damage response through distinct mechanisms of co-transcriptional mRNA regulation.	cancer_biology genes rna cancer dna mrna functions m6a ythdc1 converge		2024-03-28								cc_by_nc_nd			Maite Huarte	85	0
Androgen deprivation therapy-resistant club cells are linked to myeloid cell-driven immunosuppression in the prostate tumor microenvironment	Prostate cancer treatment resistance is a significant challenge facing the field. Genomic and transcriptomic profiling have partially elucidated the mechanisms through which cancer cells escape treatment, but their relation toward the tumor microenvironment (TME) remains elusive. Here we present a comprehensive transcriptomic landscape of the prostate TME at multiple points in the standard treatment timeline employing single-cell RNA-sequencing and spatial transcriptomics data from 110 patients. We identify club-like cells as a key epithelial cell subtype that acts as an interface between the prostate and the immune system. Tissue areas enriched with club-like cells have depleted androgen signaling and upregulated expression of luminal progenitor cell markers. Club-like cells display a senescence-associated secretory phenotype and their presence is linked to increased polymorphonuclear myeloid-derived suppressor cell (PMN-MDSC) activity. Our results indicate that club-like cells partake in inducing myeloid inflammation previously associated with androgen deprivation therapy resistance, providing a rationale for their therapeutic targeting.	cancer_biology myeloid immunosuppression androgen prostate transcriptomics cancer tumor		2024-03-28								cc_no			Matti Nykter	86	0
CPT1A Mediates Radiation Sensitivity in Colorectal Cancer	The prevalence and mortality rates of colorectal cancer (CRC) are increasing worldwide. Radiation resistance hinders radiotherapy, a standard treatment for advanced CRC, leading to local recurrence and metastasis. Elucidating the molecular mechanisms underlying radioresistance in CRC is critical to enhance therapeutic efficacy and patient outcomes. Bioinformatic analysis and tumour tissue examination were conducted to investigate the CPT1A mRNA and protein levels in CRC and their correlation with radiotherapy efficacy. Furthermore, lentiviral overexpression and CRISPR/Cas9 lentiviral vectors, along with in vitro and in vivo radiation experiments, were used to explore the effect of CPT1A on radiosensitivity. Additionally, transcriptomic sequencing, molecular biology experiments, and bioinformatic analyses were employed to elucidate the molecular mechanisms by which CPT1A regulates radiosensitivity. CPT1A was significantly downregulated in CRC and negatively correlated with responsiveness to neoadjuvant radiotherapy. Functional studies suggested that CPT1A mediates radiosensitivity, influencing reactive oxygen species (ROS) scavenging and DNA damage response. Transcriptomic and molecular analyses highlighted the involvement of the peroxisomal pathway. Mechanistic exploration revealed that CPT1A downregulates the FOXM1-SOD1/SOD2/CAT axis, moderating cellular ROS levels after irradiation and enhancing radiosensitivity. CPT1A downregulation contributes to radioresistance in CRC by augmenting the FOXM1-mediated antioxidant response. Thus, CPT1A is a potential biomarker of radiosensitivity and a novel target for overcoming radioresistance, offering a future direction to enhance CRC radiotherapy.	cancer_biology overexpression colorectal radiation tumour cpt1a radiotherapy sensitivity biomarker cancer		2024-03-28								cc_by			Yi Ding	87	0
MAP4 kinase-regulated reduced CLSTN1 expression in medulloblastoma is associated with increased invasiveness	De-regulated protein expression contributes to tumor growth and progression in medulloblastoma (MB), the most common malignant brain tumor in children. MB is associated with impaired differentiation of specific neural progenitors, suggesting that the deregulation of proteins involved in neural physiology could contribute to the transformed phenotype in MB.  Calsynthenin 1 (CLSTN1) is a neuronal protein involved in cell-cell interaction, vesicle trafficking, and synaptic signaling. We previously identified CLSTN1 as a putative target of the pro-invasive kinase MAP4K4, which we found to reduce CLSTN1 surface expression. Herein, we explored the expression and functional significance of CLSTN1 in MB. We found that CLSTN1 expression is decreased in primary MB tumors compared to tumor-free cerebellum or brain tissues. CLSTN1 is expressed in laboratory-established MB cell lines, where it localized to the plasma membrane, intracellular vesicular structures, and regions of cell-cell contact. The reduction of CLSTN1 expression significantly increased growth factor-driven invasiveness. Pharmacological inhibition of MAP4 kinases caused increased CLSTN1 expression and CLSTN1 accumulation in cell-cell contacts. Co-culture of tumor cells with astrocytes increased CLSTN1 localization in cell-cell contacts, which was further enhanced by MAP4K inhibition.  Our study revealed a repressive function of CLSTN1 in growth-factor-driven invasiveness in MB and its potential implication in homologous and heterologous interactions of the tumor cells with cells in their microenvironment.	cancer_biology medulloblastoma clstn1 map4 kinase invasiveness astrocytes tumors tumor map4k4		2024-03-21								cc_by_nc_nd			Martin Baumgartner	88	0
Cancer-Associated Hypercalcemia Signals Through the Hindbrain to cause Anorexia	Hypercalcemia, caused by tumor secretion of parathyroid hormone-related protein (PTHrP), is associated with anorexia and weight loss. We demonstrate that overexpression of PTHrP by tumor cells in a transgenic model of breast cancer causes anorexia and rapid weight loss. These changes are accompanied by activation of neurons in the area postrema (AP), the nucleus tractus solitarius (NTS) and the parabrachial nucleus (PBN), a hindbrain circuit regulating food intake. Blocking hypercalcemia prevents anorexia and activation of these brain centers in tumor bearing mice, whereas injecting calcium activates the same circuit in wild-type mice. Neurons in the AP express the calcium-sensing receptor (CaSR) and the same AP/NTS/PBN circuit is stimulated by treating WT mice with cinacalcet, an allosteric activator of the CaSR. Finally, treating diet-induced obese mice with cinacalcet reduces food intake and causes weight loss. These results suggest that CaSR-expressing neurons in the AP might be a pharmacologic target for obesity.	cancer_biology overexpression hypercalcemia anorexia obesity signals hindbrain cancer tumor		2024-03-21								cc_by_nc			John J. Wysolmerski	89	0
Effect of C-to-T transition at CpG sites on tumor suppressor genes in tumor development in cattle evaluated by somatic mutation analysis in enzootic bovine leukosis	Oncogenic transformation of normal cells is caused by mutations and chromosomal abnormalities in cancer-related genes. Enzootic bovine leukosis (EBL) is a malignant B-cell lymphoma caused by bovine leukemia virus (BLV) infection in cattle. Although a small fraction of BLV-infected cattle develops EBL after a long latent period, the mechanisms for oncogenesis in EBL cattle remain largely unknown. In this study, we analyzed the types and patterns of somatic mutations in cancer cells from 36 EBL cases, targeting 21 cancer-related genes. Various somatic mutations were identified in 8 genes, TP53, NOTCH1, KMT2D, CREBBP, KRAS, PTEN, CARD11, and MYD88. In addition, TP53 gene was found to be mutated in 69.4% of EBL cases, with most being biallelic mutations. In some cases, associations were observed between the ages at which cattle had developed EBL and somatic mutation patterns; young onset of EBL possibly occurs due to congenital mutations, high impact mutations affecting protein translation, and biallelic mutations. Furthermore, nucleotide substitution patterns indicated that cytosine at CpG sites tended to be converted to thymine in many EBL cases, which was considered to be the result of spontaneous deamination of 5-methylctosine. These results demonstrate how somatic mutations have occurred in cancer cells leading to EBL development, thereby explaining its pathogenic mechanism. These findings will contribute to a better understanding and future elucidation of disease progression in BLV infection.  ImportanceEnzootic bovine leukosis (EBL) is a malignant and lethal disease in cattle. Currently, there are no effective vaccines or therapeutic methods against bovine leukemia virus (BLV) infection, resulting in severe economic losses in livestock industry. This study provides a renewed hypothesis to explain the general mechanisms of EBL onset by combining the previous finding that several integration sites of BLV provirus can affect the increase in survival and proliferation of infected cells. We demonstrate that two additional random events are necessary for oncogenic transformation in infected cell clones, elucidating the reason why only few infected cattle develop EBL. Further exploration of somatic mutation and BLV integration sites could support this hypothesis more firmly, potentially contributing to the development of novel control methods for EBL onset.	cancer_biology genes lymphoma virus cattle leukosis provirus leukemia cancer tumor bovine		2024-03-21								cc_by_nc_nd			Asami Nishimori	90	0
Systematic annotation of orphan RNAs reveals blood-accessible molecular barcodes of cancer identity and cancer-emergent oncogenic drivers	From extrachromosomal DNA to neo-peptides, the broad reprogramming of the cancer genome leads to the emergence of molecules that are specific to the cancer state. We recently described orphan non-coding RNAs (oncRNAs) as a class of cancer-specific small RNAs with the potential to play functional roles in breast cancer progression1. Here, we report a systematic and comprehensive search to identify, annotate, and characterize cancer-emergent oncRNAs across 32 tumor types. We also leverage large-scale in vivo genetic screens in xenografted mice to functionally identify driver oncRNAs in multiple tumor types. We have not only discovered a large repertoire of oncRNAs, but also found that their presence and absence represent a digital molecular barcode that faithfully captures the types and subtypes of cancer. Importantly, we discovered that this molecular barcode is partially accessible from the cell-free space as some oncRNAs are secreted by cancer cells. In a large retrospective study across 192 breast cancer patients, we showed that oncRNAs can be reliably detected in the blood and that changes in the cell-free oncRNA burden captures both short-term and long-term clinical outcomes upon completion of a neoadjuvant chemotherapy regimen. Together, our findings establish oncRNAs as an emergent class of cancer-specific non-coding RNAs with potential roles in tumor progression and clinical utility in liquid biopsies and disease monitoring.	cancer_biology biopsies molecular rnas dna barcodes annotation cancer tumor chemotherapy		2024-03-21								cc_by_nc_nd			Hani Goodarzi	91	0
Illuminating the Dark Cancer Phosphoproteome Through a Machine-Learned Co-Regulation Map of 26,280 Phosphosites	Mass spectrometry-based phosphoproteomics offers a comprehensive view of protein phosphorylation, but limited knowledge about the regulation and function of most phosphosites restricts our ability to extract meaningful biological insights from phosphoproteomics data. To address this, we combine machine learning and phosphoproteomic data from 1,195 tumor specimens spanning 11 cancer types to construct CoPheeMap, a network mapping the co-regulation of 26,280 phosphosites. Integrating network features from CoPheeMap into a machine learning model, CoPheeKSA, we achieve superior performance in predicting kinase-substrate associations. CoPheeKSA reveals 24,015 associations between 9,399 phosphosites and 104 serine/threonine kinases, including many unannotated phosphosites and under-studied kinases. We validate the accuracy of these predictions using experimentally determined kinase-substrate specificities. By applying CoPheeMap and CoPheeKSA to phosphosites with high computationally predicted functional significance and cancer-associated phosphosites, we demonstrate the effectiveness of these tools in systematically illuminating phosphosites of interest, revealing dysregulated signaling processes in human cancer, and identifying under-studied kinases as putative therapeutic targets.	cancer_biology 280 phosphosites spectrometry kinases phosphoproteomics 26 phosphoproteome cancer tumor		2024-03-21								cc_no			Bing Zhang	92	0
CDK12 Loss Promotes Prostate Cancer Development While Exposing Vulnerabilities to Paralog-Based Synthetic Lethality	Biallelic loss of cyclin-dependent kinase 12 (CDK12) defines a unique molecular subtype of metastatic castration-resistant prostate cancer (mCRPC). It remains unclear, however, whether CDK12 loss per se is sufficient to drive prostate cancer development--either alone, or in the context of other genetic alterations--and whether CDK12-mutant tumors exhibit sensitivity to specific pharmacotherapies. Here, we demonstrate that tissue-specific Cdk12 ablation is sufficient to induce preneoplastic lesions and robust T cell infiltration in the mouse prostate. Allograft-based CRISPR screening demonstrated that Cdk12 loss is positively associated with Trp53 inactivation but negatively associated with Pten inactivation--akin to what is observed in human mCRPC. Consistent with this, ablation of Cdk12 in prostate organoids with concurrent Trp53 loss promotes their proliferation and ability to form tumors in mice, while Cdk12 knockout in the Pten-null prostate cancer mouse model abrogates tumor growth. Bigenic Cdk12 and Trp53 loss allografts represent a new syngeneic model for the study of androgen receptor (AR)-positive, luminal prostate cancer. Notably, Cdk12/Trp53 loss prostate tumors are sensitive to immune checkpoint blockade. Cdk12-null organoids (either with or without Trp53 co-ablation) and patient-derived xenografts from tumors with CDK12 inactivation are highly sensitive to inhibition or degradation of its paralog kinase, CDK13. Together, these data identify CDK12 as a bona fide tumor suppressor gene with impact on tumor progression and lends support to paralog-based synthetic lethality as a promising strategy for treating CDK12-mutant mCRPC.	cancer_biology cdk12 cancer paralog prostate tumors lethality tumor		2024-03-21								cc_by			Arul M. Chinnaiyan	93	0
Consequences of platelet-educated cancer cells on the expression of inflammatory and metastatic glycoproteins.	Cancer-associated thrombosis, a major cause of mortality in cancer patients, exhibits a 4 to 7 times higher incidence compared to the general population. Platelet activation by tumor cells contributes to this pro-thrombotic state. Cancer cell-educated platelets have also been described to be implicated in promoting metastasis. Intriguingly, our team, among others, unveils a reverse process, wherein platelets educate cancer cells by transferring lipids, RNAs, and proteins. Here, focusing on colorectal and pancreatic cancers, our study investigates genes and proteins mediating platelet education of cancer cells. We demonstrated, for the first time, that platelets can educate cancer cells by inducing changes in the transcription of genes related to glycosylation, inflammation, and metastasis in cancer cells themselves. These results indicate a direct impact of platelets on cancer cell phenotype. This novel insight suggests potential therapeutic avenues for cancer treatment, disrupting platelet-mediated alterations and influencing the course of cancer progression.	glycoproteins cancer_biology platelet cancers cells thrombosis thrombotic metastatic cancer tumor		2024-03-21								cc_no			Christophe Dubois	94	0
Targeting Diffuse Midline Glioma with a novel anti-CD99 Antibody	Diffuse midline gliomas (DMGs) are devastating brain tumors that occur primarily in children. The salient feature of these tumors is the presence of a H3K27M mutation (K27M), associated with the worst prognosis. We identified the cell surface antigen CD99 as notably expressed in DMGs, particularly in K27M+DMGs. We found that the increased expression of CD99 in K27M+DMGs was a result of the onco-histone K27M mutation. In K27M+DMG cells, CD99 inactivation impaired tumor growth by inducing cell differentiation, indicating an oncogenic role of CD99 enabled by blocking differentiation. We then developed a novel therapeutic anti-CD99 chimeric antibody, 10D1, with a membrane-proximal binding epitope, and evaluated its antitumor efficacy in preclinical models of K27M+DMG. 10D1 suppressed DMG growth in vitro and in vivo by inducing apoptosis. When combined with radiation treatment, 10D1 exhibited improved antitumor efficiency and xenograft survival, providing a strong justification for its clinical development as a therapy for DMGs.  Statement of SignificanceThis study emphasizes that CD99 overexpression occurs due to the H3K27M mutation in Diffuse Midline Gliomas (DMGs). This heightened expression suppresses apoptosis, inhibits differentiation, and induces radio-resistance in DMGs. This research justifies using a novel CD99 antibody alone or combined with radiation therapy in human pediatric clinical trials.	cancer_biology overexpression antibody h3k27m cd99 apoptosis glioma targeting novel tumors tumor		2024-03-21								cc_no			Sujatha Venkataraman	95	0
BET inhibition induces GDH1-dependent glutamine metabolic remodeling and vulnerability in liver cancer	Bromodomain and extra-terminal domain (BET) proteins, which function partly through MYC, are critical epigenetic readers and emerging therapeutic targets in cancer. Whether and how BET inhibition simultaneously induces metabolic remodeling remains unclear. Here we find that even transient BET inhibition by JQ-1 and other pan-BET inhibitors blunts liver cancer cell proliferation and tumor growth. BET inhibition decreases glycolytic gene expression but enhances mitochondrial glucose and glutamine oxidative metabolism revealed by metabolomics and isotope labeling analysis. Specifically, BET inhibition downregulates miR-30a to upregulate glutamate dehydrogenase 1 (GDH1) independent of MYC, which produces -ketoglutarate for mitochondrial oxidative phosphorylation (OXPHOS). Targeting GDH1 or OXPHOS is synthetic lethal to BET inhibiton, and combined BET and OXPHOS inhibition therapeutically prevents liver tumor growth in vitro and in vivo. Together, we uncover an important epigenetic-metabolic crosstalk whereby BET inhibition induces MYC- independent and GDH1-dependendent glutamine metabolic remodeling that can be exploited for innovative combination therapy of liver cancer.	metabolic cancer_biology glutamine remodeling therapy liver cancer tumor glycolytic		2024-03-21								cc_by_nc_nd			Fuming Li	96	0
UDP-6-glucose dehydrogenase in hormonally responsive breast cancers	Survival for metastatic breast cancer is low and thus, continued efforts to treat and prevent metastatic progression are critical. Estrogen is shown to promote aggressive phenotypes in multiple cancer models irrespective of estrogen receptor (ER) status. Similarly, UDP-Glucose 6-dehydrogenase (UGDH) a ubiquitously expressed enzyme involved in extracellular matrix precursors, as well as hormone processing increases migratory and invasive properties in cancer models. While the role of UGDH in cellular migration is defined, how it intersects with and impacts hormone signaling pathways associated with tumor progression in metastatic breast cancer has not been explored. Here we demonstrate that UGDH knockdown blunts estrogen-induced tumorigenic phenotypes (migration and colony formation) in ER+ and ER- breast cancer in vitro. Knockdown of UGDH also inhibits extravasation of ER- breast cancer ex vivo, primary tumor growth and animal survival in vivo in both ER+ and ER- breast cancer. We also use single cell RNA-sequencing to demonstrate that our findings translate to a human breast cancer clinical specimen. Our findings support the role of estrogen and UGDH in breast cancer progression provide a foundation for future studies to evaluate the role of UGDH in therapeutic resistance to improve outcomes and survival for breast cancer patients.	cancer_biology udp breast tumor tumorigenic cancers invasive dehydrogenase cancer glucose		2024-03-21								cc_by_nc_nd			C. Rory Goodwin	97	0
How clinically relevant are prostate cancer cell lines? A comprehensive characterisation and multiomics comparison.	Cell line experiments arguably remain the most used tool in preclinical cancer research, despite their limitations. With almost 95% drugs entering human trials failing, and up to 90% preclinical research failing before even being tested in humans, we must shift the pre-clinical paradigm. A range of in silico, in vitro, in vivo and ex vivo approaches are gaining popularity, with the aim of potentially replacing cell line use. However, we cannot ignore the plethora of historical data from cell lines, nor write off their future use- especially within advanced bioengineered models. Therefore, we must question if and how cell lines hold clinical relevance. This study evaluates the clinical characteristics of 46 prostate cancer cell lines against worldwide data and investigates the biological features of seven cell lines in depth, comparing them to over 10,000 well characterised human cases from 24 studies in nine countries. Clinical features compared included age, ethnicity, Gleason grade, cancer type, treatment history and multiomics variables included mutations, copy number alterations, structural variants, microsatellite instability, mRNA and protein expression, and tumour mutational burden. We found that the most used cell lines accurately represent a minute proportion of prostate cancer patients. Furthermore, we recommend a pipeline for tailoring selection of clinically relevant cell lines with the ultimate aim of increasing the scientific methodology behind choosing a cell line.	cancer_biology tumour cell 90 prostate clinically multiomics bioengineered cancer		2024-03-21								cc_by			Zahra Ahmed	98	0
Ether lipids influence cancer cell fate by modulating iron uptake	Cancer cell fate has been widely ascribed to mutational changes within protein-coding genes associated with tumor suppressors and oncogenes. In contrast, the mechanisms through which the biophysical properties of membrane lipids influence cancer cell survival, dedifferentiation and metastasis have received little scrutiny. Here, we report that cancer cells endowed with a high metastatic ability and cancer stem cell-like traits employ ether lipids to maintain low membrane tension and high membrane fluidity. Using genetic approaches and lipid reconstitution assays, we show that these ether lipid-regulated biophysical properties permit non-clathrin-mediated iron endocytosis via CD44, leading directly to significant increases in intracellular redox-active iron and enhanced ferroptosis susceptibility. Using a combination of in vitro three-dimensional microvascular network systems and in vivo animal models, we show that loss of ether lipids also strongly attenuates extravasation, metastatic burden and cancer stemness. These findings illuminate a mechanism whereby ether lipids in carcinoma cells serve as key regulators of malignant progression while conferring a unique vulnerability that can be exploited for therapeutic intervention.	iron genes cancer_biology genetic cancer ether cell carcinoma lipids tumor		2024-03-21								cc_by_nc_nd			Robert A Weinberg	99	0
Single-cell profiling reveals the intratumor heterogeneity and immunosuppressive microenvironment in cervical adenocarcinoma	BackgroundCervical adenocarcinoma (ADC) is more aggressive compared to other types of cervical cancer (CC), such as squamous cell carcinoma (SCC). The tumor immune microenvironment (TIME) and tumor heterogeneity are recognized as pivotal factors in cancer progression and therapy. However, the disparities in TIME and heterogeneity between ADC and SCC are poorly understood.  MethodsWe performed single-cell RNA sequencing on 11 samples of ADC tumor tissues, with other 4 SCC samples served as controls. The immunochemistry and multiplexed immunofluorescence were conducted to validate our findings.  ResultsCompared to SCC, ADC exhibited unique enrichments in several sub-clusters of epithelial cells with elevated stemness and hyper-malignant features, including the Epi_10_CYSTM1 cluster. ADC displayed a highly immunosuppressive environment characterized by the enrichment of regulatory T cells (Tregs) and tumor-promoting neutrophils. The Epi_10_CYSTM1 cluster recruits Tregs via ALCAM-CD6 signaling, while Tregs reciprocally induce stemness in the Epi_10_CYSTM1 cluster through TGF{beta} signaling. Importantly, our study revealed that the Epi_10_CYSTM1 cluster could serve as a valuable predictor of lymph node metastasis for CC patients.  ConclusionsThis study highlights the significance of ADC-specific cell clusters in establishing a highly immunosuppressive microenvironment, ultimately contributing to the heightened aggressiveness and poorer prognosis of ADC compared to SCC.	cancer_biology microenvironment immunosuppressive cervical adenocarcinoma carcinoma intratumor cancer tumor		2024-03-21								cc_by			Liang Weng	100	0
CDK4 and CDK6 upregulation promotes DNA replication stress, genomic instability and resistance to EGFR targeted therapy in lung cancer	Genetic interactions impact both normal human physiology and human diseases, such as cancer. Here, we study genetic interactions through the lens of human lung cancers driven by oncogenic forms of the epidermal growth factor receptor (EGFR), which we and others previously showed harbor a rich landscape of genetic co-alterations and potential genetic interactions. Among the most common genetic co-alterations with oncogenic EGFR are genomic amplifications of cell cycle regulators CDK4 or CDK6, which have been implicated in EGFR inhibitor clinical resistance, although the mechanism underlying this effect is not well characterized. We show that CDK4/6 upregulation overcomes EGFR inhibitor-induced G1/S cell cycle arrest in association with increased replication stress, DNA damage and genomic instability. These biological effects arising in CDK4/6 upregulated tumors help to enable resistance to EGFR targeted therapies through established genetic resistance mechanisms. Combinatorial EGFR and CDK4/6 inhibitor treatment alleviated genomic instability and EGFR inhibitor resistance in patient-derived preclinical models. This study reveals mechanistic and clinical impacts of the genetic interaction between oncogenic EGFR and CDK4/6 co-alterations in human lung cancer.	cancer_biology genetic lung dna cancers therapy tumors cancer cdk4		2024-03-14								cc_no			Collin M. Blakely	101	0
Proteomic Analysis Reveals Trilaciclib-Induced Senescence	"Trilaciclib, a CDK4/6 inhibitor, was approved as a myeloprotective agent for protecting bone marrow from chemotherapy-induced damage in extensive-stage small cell lung cancer (ES-SCLC). This is achieved through the induction of a temporary halt in the cell cycle of bone marrow cells. While it has been studied in various cancer types, its potential in haematological cancers remains unexplored. This research aimed to investigate the efficacy of trilaciclib in haematological cancers. Utilizing mass spectrometry-based proteomics, we examined the alterations induced by trilaciclib in the chronic myeloid leukaemia (CML) cell line, K562. Interestingly, trilaciclib promoted senescence in these cells rather than cell death, as observed in acute myeloid leukaemia (AML), acute lymphoblastic leukaemia (ALL), and myeloma cells. In K562 cells, trilaciclib hindered cell cycle progression and proliferation by stabilising CDK4/6 and downregulating cell cycle-related proteins, along with the concomitant activation of autophagy pathways. Additionally, trilaciclib-induced senescence was also observed in the non-small cell lung carcinoma cell line (NSCLC), A549. These findings highlight trilaciclibs potential as a therapeutic option for haematological cancers and underscore the need to carefully balance senescence induction and autophagy modulation in CML treatment, as well as in NSCLC.  ABSTRACT GRAPHIC  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=109 SRC=""FIGDIR/small/584620v1_ufig1.gif"" ALT=""Figure 1""> View larger version (30K): org.highwire.dtl.DTLVardef@a52d70org.highwire.dtl.DTLVardef@4a1da0org.highwire.dtl.DTLVardef@1df00dborg.highwire.dtl.DTLVardef@1b16758_HPS_FORMAT_FIGEXP  M_FIG C_FIG"	cancer_biology cancer reveals myeloma trilaciclib carcinoma cancers analysis senescence chemotherapy proteomic		2024-03-14								cc_by_nc_nd			Jose Luis Marin-Rubio	102	0
Assessing Long-Term Stored Tissues for Multi-Omics Data Quality and Proteogenomics Suitability	As research into the complexities of cancer biology deepens, the integration of multi-omics analyses has emerged as a powerful approach to unravel the complex molecular basis of cancers. However, challenges related to sample availability, including size, collection procedures, and storage duration, hinder the broad application of this methodology. Despite these limitations, there is a growing interest in exploring the potential of archived samples to expand the scope of multi-omics research. Our study aims to investigate the impact of storage duration on the measurment in genomic, transcriptomic, and proteomic profiles of archived samples, demonstrating their viability for advancing our understanding of cancer biology. To comprehensively address these trends and limitations, we systematically examined archived samples collected over a decade, focusing on their transcriptomic, proteomic, and phosphoproteomic attributes. Analysis revealed intricate patterns and dynamic shifts, especially in long-term transcriptomic data, with observed declines in read counts related to protein coding and gene coverage. However, these changes did not compromise the fundamental gene expression landscape. Proteomic result also demonstrated that storage period did not significantly influence proteomic measurement. Comparisons of housekeeping gene (HKG) and housekeeping protein (HKP) expressions unveiled consistent transcriptomic levels across samples, while distinctive proteomic disparities between tumor and normal tissues. In conclusion, the challenges posed by limited sample availability in multi-omics studies can be partially overcome through the strategic integration of archived samples. While technical shifts were evident in certain aspects of transcriptomic data, core gene expression patterns remained robust, and the functionality of essential transcription factors (TFs) and kinases remained unaffected. These findings underscore the potential of archived samples as valuable resources for multi-omics research, providing a broader landscape for investigating cancer biology and paving the way for more comprehensive insights into this intricate field.	cancer_biology transcriptomic suitability proteogenomics cancers assessing tissues stored cancer tumor biology		2024-03-14								cc_no			Kwang Pyo Kim	103	0
Deciphering molecular mechanisms of synergistic growth reduction in kinase inhibitor combinations	In cancer treatment, the persistent challenge of unresponsiveness of certain patients to drugs or the development of resistance post-treatment remains a significant concern. Drug combinations that synergistically reduce tumor growth emerge as a promising avenue to address this issue. Here, we aimed to characterize the mechanism of action of two synergistic drug combinations that target PI3K together with MEK1 or with TAK1 and used time course measurements of phosphoproteomics and transcriptomics in response to single inhibitors and their combinations. Our analysis untangled those responses driven by single drugs and responses that were unique to the combinations. We observed a high overlap between single-drug responses and their combinations, suggesting that single-drug mechanisms dominate the mechanism of action of the combinations of the kinase inhibitors. Despite a high overlap, both drug combinations exhibited a synergistic modulation of several cell fate regulators found at the convergence points of the targeted pathways, including the key regulator of intrinsic apoptosis BCL2L11. Interestingly, the responses in both combinations were largely limited to the targeted pathways, namely PI3K/AKT and MAPKs, with very limited change of any other additional cell fate decision pathways. In addition, we observed a strong downregulation of nucleotide metabolism and tRNA biosynthesis uniquely in the combinations, which could be attributed to the reduced activity of mTOR and ATF4. Our approach provides insights into the molecular mechanisms affected by the PI3Ki-TAK1i and PI3Ki-MEKi combinations and can serve as a flexible framework for dissecting drug combination responses based on multi-omics measurements.	cancer_biology deciphering molecular reduction biosynthesis apoptosis kinase inhibitor transcriptomics cancer tumor		2024-03-14								cc_by			Eirini Tsirvouli	104	0
Hybrid protein language models for fitness prediction and design	The ability to accurately model the fitness landscape of protein sequences is critical to a wide range of applications, from quantifying the effects of human variants on disease likelihood, to predicting immune-escape mutations in viruses and designing novel biotherapeutic proteins. Deep generative models of protein sequences trained on multiple sequence alignments have been the most successful approaches so far to address these tasks. The performance of these methods is however contingent on the availability of sufficiently deep and diverse alignments for reliable training. Their potential scope is thus limited by the fact many protein families are hard, if not impossible, to align. Large language models trained on massive quantities of non-aligned protein sequences from diverse families seek to address these problems. However, their performance has not yet matched that of their alignment-based counterparts. This talk will introduce hybrid strategies to leverage the strengths from both model classes	biotherapeutic fitness hybrid protein design proteins hard prediction massive mia meeting		2019-02-14											Pascal Notin	105	0
Unsupervised viral antibody escape prediction for future-proof vaccines	Effective pandemic preparedness relies on predicting immune-evasive viral mutations to ensure early detection of variants of concern and to design future-proofed vaccines and therapeutics. However, current experimental strategies for viral evolution prediction are not available early in a pandemic since  they require host polyclonal antibodies.  Furthermore, the existing paradigm for vaccine evaluation relies on retrospective evaluation against past variants, instead of proactive evaluation against future viral evolution. To address these limitations, we developed EVEscape, a model which integrated fitness predictions from evolutionary models, structure-based features that assess antibody binding potential, and biochemical distances between mutated and wild-type residues. EVEscape quantifies the viral escape potential of mutations at scale and has the advantage of being applicable before surveillance sequencing, experimental scans, or 3D structures of antibody complexes are available. Using only information available pre-pandemic, EVEscape is as accurate as high-throughput experimental scans at anticipating pandemic variation for SARS-CoV-2 and is generalizable to other viruses. Using EVEscape we forecast future SARS-CoV-2 evolution and present a novel and proactive approach for evaluating  and designing vaccines.	antibodies viruses future vaccine prediction antibody vaccines viral mia meeting		2019-02-14											Noor Youssef, Sarah Faye Gurev	106	0
Accurate proteome-wide missense variant effect prediction with Alpha Missens	The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present Alpha Missense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89% of missense variants as either likely benign or likely pathogenic.	proteome genes genome alpha missense accurate genetic prediction pathogenicity pathogenic mia meeting		2019-03-13											Žiga Avsec	107	0
Alpha Missens	The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present Alpha Missense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89% of missense variants as either likely benign or likely pathogenic.	genes genome alpha missens genetic pathogenicity pathogenic mia meeting		2019-03-13											Jun Cheng	108	0
Testing data-driven hypotheses post-clustering	This primer talk is motivated by the practice of testing data-driven hypotheses. In the biomedical sciences, it has become increasingly common to collect massive datasets without a pre-specified research question. In this setting, a data analyst might use the data both to generate a research question, and to test the associated null hypothesis. For example, in single-cell RNA-sequencing analyses, researchers often first cluster the cells, and then test for differences in the expected gene expression levels between the clusters to quantify up- or down-regulation of genes, annotate known cell types, and identify new cell types. However, this popular practice is invalid from a statistical perspective: once we have used the data to generate hypotheses, standard statistical inference tools are no longer valid. To tackle this problem, I developed a conditional selective approach to test for a difference in means between pairs of clusters obtained via hierarchical and k-means clustering. The proposed approach has appropriate statistical guarantees (e.g., selective Type 1 error control), and we demonstrate its use on single-cell RNA-sequencing data.	genes data research post biomedical researchers clustering rna testing hypotheses mia meeting		2019-03-20											Yiqun Chen	109	0
Data thinning to avoid double dipping	"""Double dipping"" is the practice of using the same data to fit and validate a model. Problems typically arise when standard statistical procedures are applied in settings involving double dipping. To avoid the challenges surrounding double dipping, a natural approach is to fit a model on one dataset, and then validate the model on another independent dataset. When we only have access to one dataset, we typically accomplish this via sample splitting. Unfortunately, in some problems, sample splitting is unattractive or impossible. In this talk, we are motivated by unsupervised problems that arise in the analysis of single cell RNA sequencing data, where sample splitting does not allow us to avoid double dipping. We first propose Poisson thinning, which splits a single observation drawn from a Poisson distribution into two independent pseudo-observations. We show that Poisson count splitting allows us to avoid double dipping in unsupervised settings. We next generalize the Poisson thinning framework to a variety of distributions, and refer to this general framework as ""data thinning"". Data thinning is applicable far beyond the context of single-cell RNA sequencing data, and is particularly useful for problems where sample splitting is unattractive or impossible."	statistical data avoid sequencing sample double thinning dipping mia meeting		2019-03-20											Lucy Gao	110	0
SPLASH unifies genomic analysis and discovery through a paradigm shift to statistics-first	Myriad mechanisms diversify the sequence content of DNA and of RNA transcripts. Currently, these events are detected using tools that first require alignment to a necessarily incomplete reference genome alignment in the first step; this incompleteness is especially prominent in human genetic diseases such as cancer, in the microbial world, and in non—model organisms where it severely limits the speed and scope of discovery. Second, today the next step in analysis requires as a custom choice of bioinformatic procedure to follow it: for example, to detect splicing, RNA editing, or V(D)J recombination among many others.  I will present the theory for why SPLASH, a new statistics-first analytic approach captures myriad forms of genome regulation, without a reference or sample metadata, by performing statistical inference directly on raw sequencing reads. By design, SPLASH as an algorithm is highly efficient. Thanks to joint work with Professor Sebastian Deorowicz’s group, SPLASH is now implemented so that it is efficient and simple to run. A snapshot of its findings include new insights into RNA splicing, cancer transcriptomes, single cell RNA-editing, mobile genetic elements and discovers new genes non-model organisms.	genome cancer statistics bioinformatic splash genomic genetic paradigm discovery dna mia meeting		2019-04-03											Julia Salzman	111	0
Statistical and algorithmic challenges in reference-free analysis	Today’s genomics workflows typically begin by aligning sequencing data to a reference. In addition to being slow, this has many statistical drawbacks. Even in the intensely studied human genome, it was found that understudied populations have large amounts of sequence missing from the current reference; such blind spots may exacerbate health disparities. Reference-based methods are additionally limited in their detection of novel biology: reads from unannotated isoforms may be mismapped or discarded completely. In recent work we introduce a unifying paradigm, SPLASH, which directly analyzes raw sequencing data, using a statistical test to detect a signature of regulation: sample-specific sequence variation. SPLASH detects many types of variation and can be efficiently run at scale, providing a unifying statistical approach to genomic analysis that enables expansive discovery without metadata or references. In this primer I’ll discuss some of the challenges of reference-free analysis, and provide the algorithmic and statistical background for our proposed solution, SPLASH.	statistical drawbacks genomics reference exacerbate algorithmic challenges biology genomic analysis mia meeting		2019-04-03											Tavor Baharav	112	0
Single-cell models for state-dependent eQTL analysis	As single-cell RNA-seq datasets grow larger and more complex, they enable richer analyses of how gene expression varies between cells and people. However, methods designed for bulk data fail to account for the unique structure of single-cell gene expression. Researchers are now developing statistical models tailored to single-cell-resolution data for a variety of applications. In this primer, I will focus on single-cell models for the task of mapping expression quantitative trait loci (eQTLs) to find genetic variants associated with a gene's expression. Single-cell eQTL models have the potential to capture disease-relevant, state-dependent regulatory effects with the right statistical models and representations of cell state. This primer will discuss the evolution of statistical models for eQTL mapping from pseudobulk to single-cell resolution, representations of single-cell states for state-dependent analyses, and outstanding computational challenges.	analysis state researchers disease computational genetic eqtl rna single cell mia meeting		2019-04-10											Aparna Nathan	113	0
Scalable single-cell models for robust cell-state-dependent eQTL mapping	Modelling cell state-dependent genetic associations with single-cell gene expression exhibits statistical and computational challenges. First, parametrization of single-cell gene expression profiles is not a straightforward task because individual genes exhibit distinct distributions. Second, current single-cell datasets consist of hundreds of thousands to millions of cells, which constrains the ability to test associations in a scalable manner. In this talk, I will introduce a new generalizable approach to robustly identify cell state-dependent eQTLs in single-cell data. To overcome the challenge of gene expression parametrization, we implemented a non-parametric bootstrap procedure to compute empirically calibrated p-values for variant-gene expression associations. To speed up the computation, we used the Julia programming language and pre-computed covariate-adjusted gene expression profiles with a linear mixed model before testing cell state-dependent eQTL interactions. Finally, I will demonstrate an application of this approach to identify autoimmune disease risk loci with context-specific effects in memory T cells.	genes autoimmune scalable computation mapping computational genetic eqtl robust cell mia meeting		2019-04-10											Jose Alquicira-Hernandez	114	0
Protein language models learn evolutionary statistics of interacting sequence motifs	Protein language models (pLMs) have exhibited remarkable capabilities in protein structure prediction and design. However, the extent to which they comprehend the intrinsic biophysics of protein structures remains uncertain. We present a suite of analyses that dissect how the flagship pLM ESM-2 predicts structure. Motivated by a consistent error of protein isoforms predicted as structured fragments, we developed a completely unsupervised method to uniformly evaluate any pLM, allowing us to compare coevolutionary statistics to linear models. We further identified that ESM-2 does not require full context for predicting inter-residue contacts. Our study highlights the current limitations of pLMs and contributes to a deeper understanding of their underlying mechanisms, paving the way for more reliable protein structure predictions.	statistics protein learn study biophysics analyses prediction evolutionary language mia meeting		2019-05-01											Sergey Ovchinnikov	115	0
Combining protein language and structure models to redesign E. coli proteome with a reduced amino acid alphabet	All known organisms need all 20 canonical amino acids to survive and reproduce, yet use of different amino acids must’ve evolved over time. Unfortunately, even the last universal common ancestor used all 20, so there is no way to observe how life might have looked without all of them. Here, we’re trying to synthesize such an organism by designing a strain of E. coli using only 19 canonical amino acids, starting from redesigning essential genes one at a time with the goal of preserving fitness. Since there are many diverse genes to design, we’re repurposing and extending machine learning-driven protein design methods to accomplish this task. Each of the currently available methods is capturing specific properties of the design landscape due to its approach and training data provided to the models. Protein language models like ESM have access to a vast number of sequences and can learn patterns favored by nature. Methods using AlphaFold as a loss function like AFDesign or MCMC hallucination are aware of the final structure of the protein, but are susceptible to adversarial examples. Finally, models which perform “inverse folding” like ProteinMPNN have both sequence and structure information and can output structure-aware designs. We’re developing optimization methods which combine these models as part of the design process to find sequences which are scored highly by models coming from different approaches, and how this translates to their biological properties. The experimental results show that our methods can generate designs comparable with wild-type versions in fitness with a small number of attempts.	genes amino protein proteinmpnn coli redesign alphabet 20 mia meeting		2019-05-01											Simon Kozlov	116	0
Protein Design with Deep Learning: Progress, Challenges, and Next Steps	The human proteome comprises tens of thousands of proteins, each tailored for a specific function by the selective pressures of evolution. The field of protein design seeks to develop proteins with new or enhanced functions at will, ultimately bypassing the evolutionary clock. In this talk, we discuss general machine-learning methods for accelerating the crucial components of protein design, with a particular focus on the underlying models. We begin with an overview of the protein design field and discuss traditional approaches. We then focus on two important subtasks, fixed-backbone design and protein-protein docking, and critique deep learning approaches with an emphasis on the modeling considerations that attribute to their success. Finally, we highlight some limitations and outstanding challenges in the field and potential next steps.	proteome protein challenges deep design proteins evolution evolutionary learning mia meeting		2019-05-08											Matthew McPartlon	117	0
Unlocking Generative AI for Drug Discovery with Zero-shot Models	Generative AI has the potential to greatly incrase the speed, quality, and controllability of drug design. Traditional discovery requires time and resource intensive screening of large libraries, which also offer little control on the output molecules, which can result in suboptimal candidates. Here, we show how generative deep learning models can produce molecules and representations that could be used for downstream design of new molecules with specified functions.	intensive learning unlocking screening models drug libraries generative discovery mia meeting		2019-05-08											Joshua Meier	118	0
Geometric deep learning and generative models for protein target discovery	Computational therapeutic target discovery requires deciphering the cell types in which proteins act and their interactions. We present PINNACLE, a contextual AI model for single-cell protein biology. Using a multi-organ single-cell atlas, PINNACLE learns from contextualized protein interaction networks, producing 394,760 protein representations from 156 cell types across 24 tissues. PINNACLE’s embedding space reflects cellular and tissue organization, enabling zero-shot retrieval of tissue hierarchy. Pretrained PINNACLE representations can power a range of tasks: enhancing 3D structure-based representations in immuno-oncology, predicting drug effects across cell types and states, and identifying therapeutic targets in a cell-type-specific manner. We used PINNACLE to nominate protein targets for rheumatoid arthritis and inflammatory bowel disease, identifying predictive cell type contexts. Drugs bind to protein pockets, areas where proteins interact with ligand molecules, a challenging task due to biomolecular interactions and sequence-structure dependencies. We developed PocketGen, a sequence-structure generative model that optimizes protein pockets to serve as optimal binders for ligand molecules. PocketGen iteratively refines the sequence and structure of pockets by maximizing binding affinity with the ligand and sequence-structure consistency. Using a graph transformer for all-atom structure modeling and a protein language model for sequence prediction, PocketGen can help optimize protein pockets with high binding affinity, strong structural validity and generation efficiency.	oncology protein learning biology biomolecular proteins geometric generative discovery mia meeting		2019-05-29											Marinka Zitnik	119	0
Multimodal protein language models for deciphering protein function	Understanding the relationship between a protein's amino acid sequence and its structure or function is a long-standing challenge with far-reaching implications for therapeutic development, as the effects of drugs are often directly linked to proteins. Current protein language models (PLMs) capture evolutionary relationships based on sequences but fall short of directly acquiring protein functions from multimodal molecular data, including protein sequences and structures, peptides, and domains. We develop a multimodal protein language model that integrates textual protein descriptions with a sequence-structure PLM to create a more comprehensive and functionally insightful model of proteins. This integration promises to bridge the current gap in PLMs, transitioning from understanding the structural aspects of proteins to gaining a functional view of vast protein space. The model allows scientists to express their queries in natural language and interact with protein models in an open-ended manner. It allows for text-based prediction of protein targets, multimodal protein captioning, and Q&A sessions with scientists with varying levels of expertise, among others. Trained on a new dataset of protein-text instructions, the model can generalize to new phenotypes in a zero-shot manner, making it versatile for diverse tasks even when functional annotations are scarce. We conclude with an outlook for the future with “AI scientists” as generative agents capable of skeptical learning and reasoning to empower biomedical research.	function scientists deciphering protein biomedical multimodal proteins molecular language mia meeting		2019-05-29											Owen Queen, Yepeng Huang, Marinka Zitnik	120	0
Hybrid protein language models for fitness prediction and design	The ability to accurately model the fitness landscape of protein sequences is critical to a wide range of applications, from quantifying the effects of human variants on disease likelihood, to predicting immune-escape mutations in viruses and designing novel biotherapeutic proteins. Deep generative models of protein sequences trained on multiple sequence alignments have been the most successful approaches so far to address these tasks. The performance of these methods is however contingent on the availability of sufficiently deep and diverse alignments for reliable training. Their potential scope is thus limited by the fact many protein families are hard, if not impossible, to align. Large language models trained on massive quantities of non-aligned protein sequences from diverse families seek to address these problems. However, their performance has not yet matched that of their alignment-based counterparts. This talk will introduce hybrid strategies to leverage the strengths from both model classes	biotherapeutic fitness hybrid protein design proteins hard prediction massive mia meeting		2020-02-14											Pascal Notin	121	0
Unsupervised viral antibody escape prediction for future-proof vaccines	Effective pandemic preparedness relies on predicting immune-evasive viral mutations to ensure early detection of variants of concern and to design future-proofed vaccines and therapeutics. However, current experimental strategies for viral evolution prediction are not available early in a pandemic since  they require host polyclonal antibodies.  Furthermore, the existing paradigm for vaccine evaluation relies on retrospective evaluation against past variants, instead of proactive evaluation against future viral evolution. To address these limitations, we developed EVEscape, a model which integrated fitness predictions from evolutionary models, structure-based features that assess antibody binding potential, and biochemical distances between mutated and wild-type residues. EVEscape quantifies the viral escape potential of mutations at scale and has the advantage of being applicable before surveillance sequencing, experimental scans, or 3D structures of antibody complexes are available. Using only information available pre-pandemic, EVEscape is as accurate as high-throughput experimental scans at anticipating pandemic variation for SARS-CoV-2 and is generalizable to other viruses. Using EVEscape we forecast future SARS-CoV-2 evolution and present a novel and proactive approach for evaluating  and designing vaccines.	antibodies viruses future vaccine prediction antibody vaccines viral mia meeting		2020-02-14											Noor Youssef, Sarah Faye Gurev	122	0
Accurate proteome-wide missense variant effect prediction with Alpha Missens	The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present Alpha Missense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89% of missense variants as either likely benign or likely pathogenic.	proteome genes genome alpha missense accurate genetic prediction pathogenicity pathogenic mia meeting		2020-03-13											Žiga Avsec	123	0
Alpha Missens	The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present Alpha Missense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89% of missense variants as either likely benign or likely pathogenic.	genes genome alpha missens genetic pathogenicity pathogenic mia meeting		2020-03-13											Jun Cheng	124	0
Testing data-driven hypotheses post-clustering	This primer talk is motivated by the practice of testing data-driven hypotheses. In the biomedical sciences, it has become increasingly common to collect massive datasets without a pre-specified research question. In this setting, a data analyst might use the data both to generate a research question, and to test the associated null hypothesis. For example, in single-cell RNA-sequencing analyses, researchers often first cluster the cells, and then test for differences in the expected gene expression levels between the clusters to quantify up- or down-regulation of genes, annotate known cell types, and identify new cell types. However, this popular practice is invalid from a statistical perspective: once we have used the data to generate hypotheses, standard statistical inference tools are no longer valid. To tackle this problem, I developed a conditional selective approach to test for a difference in means between pairs of clusters obtained via hierarchical and k-means clustering. The proposed approach has appropriate statistical guarantees (e.g., selective Type 1 error control), and we demonstrate its use on single-cell RNA-sequencing data.	genes data research post biomedical researchers clustering rna testing hypotheses mia meeting		2020-03-20											Yiqun Chen	125	0
Data thinning to avoid double dipping	"""Double dipping"" is the practice of using the same data to fit and validate a model. Problems typically arise when standard statistical procedures are applied in settings involving double dipping. To avoid the challenges surrounding double dipping, a natural approach is to fit a model on one dataset, and then validate the model on another independent dataset. When we only have access to one dataset, we typically accomplish this via sample splitting. Unfortunately, in some problems, sample splitting is unattractive or impossible. In this talk, we are motivated by unsupervised problems that arise in the analysis of single cell RNA sequencing data, where sample splitting does not allow us to avoid double dipping. We first propose Poisson thinning, which splits a single observation drawn from a Poisson distribution into two independent pseudo-observations. We show that Poisson count splitting allows us to avoid double dipping in unsupervised settings. We next generalize the Poisson thinning framework to a variety of distributions, and refer to this general framework as ""data thinning"". Data thinning is applicable far beyond the context of single-cell RNA sequencing data, and is particularly useful for problems where sample splitting is unattractive or impossible."	statistical data avoid sequencing sample double thinning dipping mia meeting		2020-03-20											Lucy Gao	126	0
SPLASH unifies genomic analysis and discovery through a paradigm shift to statistics-first	Myriad mechanisms diversify the sequence content of DNA and of RNA transcripts. Currently, these events are detected using tools that first require alignment to a necessarily incomplete reference genome alignment in the first step; this incompleteness is especially prominent in human genetic diseases such as cancer, in the microbial world, and in non—model organisms where it severely limits the speed and scope of discovery. Second, today the next step in analysis requires as a custom choice of bioinformatic procedure to follow it: for example, to detect splicing, RNA editing, or V(D)J recombination among many others.  I will present the theory for why SPLASH, a new statistics-first analytic approach captures myriad forms of genome regulation, without a reference or sample metadata, by performing statistical inference directly on raw sequencing reads. By design, SPLASH as an algorithm is highly efficient. Thanks to joint work with Professor Sebastian Deorowicz’s group, SPLASH is now implemented so that it is efficient and simple to run. A snapshot of its findings include new insights into RNA splicing, cancer transcriptomes, single cell RNA-editing, mobile genetic elements and discovers new genes non-model organisms.	genome cancer statistics bioinformatic splash genomic genetic paradigm discovery dna mia meeting		2020-04-03											Julia Salzman	127	0
Statistical and algorithmic challenges in reference-free analysis	Today’s genomics workflows typically begin by aligning sequencing data to a reference. In addition to being slow, this has many statistical drawbacks. Even in the intensely studied human genome, it was found that understudied populations have large amounts of sequence missing from the current reference; such blind spots may exacerbate health disparities. Reference-based methods are additionally limited in their detection of novel biology: reads from unannotated isoforms may be mismapped or discarded completely. In recent work we introduce a unifying paradigm, SPLASH, which directly analyzes raw sequencing data, using a statistical test to detect a signature of regulation: sample-specific sequence variation. SPLASH detects many types of variation and can be efficiently run at scale, providing a unifying statistical approach to genomic analysis that enables expansive discovery without metadata or references. In this primer I’ll discuss some of the challenges of reference-free analysis, and provide the algorithmic and statistical background for our proposed solution, SPLASH.	statistical drawbacks genomics reference exacerbate algorithmic challenges biology genomic analysis mia meeting		2020-04-03											Tavor Baharav	128	0
Single-cell models for state-dependent eQTL analysis	As single-cell RNA-seq datasets grow larger and more complex, they enable richer analyses of how gene expression varies between cells and people. However, methods designed for bulk data fail to account for the unique structure of single-cell gene expression. Researchers are now developing statistical models tailored to single-cell-resolution data for a variety of applications. In this primer, I will focus on single-cell models for the task of mapping expression quantitative trait loci (eQTLs) to find genetic variants associated with a gene's expression. Single-cell eQTL models have the potential to capture disease-relevant, state-dependent regulatory effects with the right statistical models and representations of cell state. This primer will discuss the evolution of statistical models for eQTL mapping from pseudobulk to single-cell resolution, representations of single-cell states for state-dependent analyses, and outstanding computational challenges.	analysis state researchers disease computational genetic eqtl rna single cell mia meeting		2020-04-10											Aparna Nathan	129	0
Scalable single-cell models for robust cell-state-dependent eQTL mapping	Modelling cell state-dependent genetic associations with single-cell gene expression exhibits statistical and computational challenges. First, parametrization of single-cell gene expression profiles is not a straightforward task because individual genes exhibit distinct distributions. Second, current single-cell datasets consist of hundreds of thousands to millions of cells, which constrains the ability to test associations in a scalable manner. In this talk, I will introduce a new generalizable approach to robustly identify cell state-dependent eQTLs in single-cell data. To overcome the challenge of gene expression parametrization, we implemented a non-parametric bootstrap procedure to compute empirically calibrated p-values for variant-gene expression associations. To speed up the computation, we used the Julia programming language and pre-computed covariate-adjusted gene expression profiles with a linear mixed model before testing cell state-dependent eQTL interactions. Finally, I will demonstrate an application of this approach to identify autoimmune disease risk loci with context-specific effects in memory T cells.	genes autoimmune scalable computation mapping computational genetic eqtl robust cell mia meeting		2020-04-10											Jose Alquicira-Hernandez	130	0
Protein language models learn evolutionary statistics of interacting sequence motifs	Protein language models (pLMs) have exhibited remarkable capabilities in protein structure prediction and design. However, the extent to which they comprehend the intrinsic biophysics of protein structures remains uncertain. We present a suite of analyses that dissect how the flagship pLM ESM-2 predicts structure. Motivated by a consistent error of protein isoforms predicted as structured fragments, we developed a completely unsupervised method to uniformly evaluate any pLM, allowing us to compare coevolutionary statistics to linear models. We further identified that ESM-2 does not require full context for predicting inter-residue contacts. Our study highlights the current limitations of pLMs and contributes to a deeper understanding of their underlying mechanisms, paving the way for more reliable protein structure predictions.	statistics protein learn study biophysics analyses prediction evolutionary language mia meeting		2020-05-01											Sergey Ovchinnikov	131	0
Combining protein language and structure models to redesign E. coli proteome with a reduced amino acid alphabet	All known organisms need all 20 canonical amino acids to survive and reproduce, yet use of different amino acids must’ve evolved over time. Unfortunately, even the last universal common ancestor used all 20, so there is no way to observe how life might have looked without all of them. Here, we’re trying to synthesize such an organism by designing a strain of E. coli using only 19 canonical amino acids, starting from redesigning essential genes one at a time with the goal of preserving fitness. Since there are many diverse genes to design, we’re repurposing and extending machine learning-driven protein design methods to accomplish this task. Each of the currently available methods is capturing specific properties of the design landscape due to its approach and training data provided to the models. Protein language models like ESM have access to a vast number of sequences and can learn patterns favored by nature. Methods using AlphaFold as a loss function like AFDesign or MCMC hallucination are aware of the final structure of the protein, but are susceptible to adversarial examples. Finally, models which perform “inverse folding” like ProteinMPNN have both sequence and structure information and can output structure-aware designs. We’re developing optimization methods which combine these models as part of the design process to find sequences which are scored highly by models coming from different approaches, and how this translates to their biological properties. The experimental results show that our methods can generate designs comparable with wild-type versions in fitness with a small number of attempts.	genes amino protein proteinmpnn coli redesign alphabet 20 mia meeting		2020-05-01											Simon Kozlov	132	0
Protein Design with Deep Learning: Progress, Challenges, and Next Steps	The human proteome comprises tens of thousands of proteins, each tailored for a specific function by the selective pressures of evolution. The field of protein design seeks to develop proteins with new or enhanced functions at will, ultimately bypassing the evolutionary clock. In this talk, we discuss general machine-learning methods for accelerating the crucial components of protein design, with a particular focus on the underlying models. We begin with an overview of the protein design field and discuss traditional approaches. We then focus on two important subtasks, fixed-backbone design and protein-protein docking, and critique deep learning approaches with an emphasis on the modeling considerations that attribute to their success. Finally, we highlight some limitations and outstanding challenges in the field and potential next steps.	proteome protein challenges deep design proteins evolution evolutionary learning mia meeting		2020-05-08											Matthew McPartlon	133	0
Unlocking Generative AI for Drug Discovery with Zero-shot Models	Generative AI has the potential to greatly incrase the speed, quality, and controllability of drug design. Traditional discovery requires time and resource intensive screening of large libraries, which also offer little control on the output molecules, which can result in suboptimal candidates. Here, we show how generative deep learning models can produce molecules and representations that could be used for downstream design of new molecules with specified functions.	intensive learning unlocking screening models drug libraries generative discovery mia meeting		2020-05-08											Joshua Meier	134	0
Geometric deep learning and generative models for protein target discovery	Computational therapeutic target discovery requires deciphering the cell types in which proteins act and their interactions. We present PINNACLE, a contextual AI model for single-cell protein biology. Using a multi-organ single-cell atlas, PINNACLE learns from contextualized protein interaction networks, producing 394,760 protein representations from 156 cell types across 24 tissues. PINNACLE’s embedding space reflects cellular and tissue organization, enabling zero-shot retrieval of tissue hierarchy. Pretrained PINNACLE representations can power a range of tasks: enhancing 3D structure-based representations in immuno-oncology, predicting drug effects across cell types and states, and identifying therapeutic targets in a cell-type-specific manner. We used PINNACLE to nominate protein targets for rheumatoid arthritis and inflammatory bowel disease, identifying predictive cell type contexts. Drugs bind to protein pockets, areas where proteins interact with ligand molecules, a challenging task due to biomolecular interactions and sequence-structure dependencies. We developed PocketGen, a sequence-structure generative model that optimizes protein pockets to serve as optimal binders for ligand molecules. PocketGen iteratively refines the sequence and structure of pockets by maximizing binding affinity with the ligand and sequence-structure consistency. Using a graph transformer for all-atom structure modeling and a protein language model for sequence prediction, PocketGen can help optimize protein pockets with high binding affinity, strong structural validity and generation efficiency.	oncology protein learning biology biomolecular proteins geometric generative discovery mia meeting		2020-05-29											Marinka Zitnik	135	0
Multimodal protein language models for deciphering protein function	Understanding the relationship between a protein's amino acid sequence and its structure or function is a long-standing challenge with far-reaching implications for therapeutic development, as the effects of drugs are often directly linked to proteins. Current protein language models (PLMs) capture evolutionary relationships based on sequences but fall short of directly acquiring protein functions from multimodal molecular data, including protein sequences and structures, peptides, and domains. We develop a multimodal protein language model that integrates textual protein descriptions with a sequence-structure PLM to create a more comprehensive and functionally insightful model of proteins. This integration promises to bridge the current gap in PLMs, transitioning from understanding the structural aspects of proteins to gaining a functional view of vast protein space. The model allows scientists to express their queries in natural language and interact with protein models in an open-ended manner. It allows for text-based prediction of protein targets, multimodal protein captioning, and Q&A sessions with scientists with varying levels of expertise, among others. Trained on a new dataset of protein-text instructions, the model can generalize to new phenotypes in a zero-shot manner, making it versatile for diverse tasks even when functional annotations are scarce. We conclude with an outlook for the future with “AI scientists” as generative agents capable of skeptical learning and reasoning to empower biomedical research.	function scientists deciphering protein biomedical multimodal proteins molecular language mia meeting		2020-05-29											Owen Queen, Yepeng Huang, Marinka Zitnik	136	0
Hybrid protein language models for fitness prediction and design	The ability to accurately model the fitness landscape of protein sequences is critical to a wide range of applications, from quantifying the effects of human variants on disease likelihood, to predicting immune-escape mutations in viruses and designing novel biotherapeutic proteins. Deep generative models of protein sequences trained on multiple sequence alignments have been the most successful approaches so far to address these tasks. The performance of these methods is however contingent on the availability of sufficiently deep and diverse alignments for reliable training. Their potential scope is thus limited by the fact many protein families are hard, if not impossible, to align. Large language models trained on massive quantities of non-aligned protein sequences from diverse families seek to address these problems. However, their performance has not yet matched that of their alignment-based counterparts. This talk will introduce hybrid strategies to leverage the strengths from both model classes	biotherapeutic fitness hybrid protein design proteins hard prediction massive mia meeting		2021-02-14											Pascal Notin	137	0
Unsupervised viral antibody escape prediction for future-proof vaccines	Effective pandemic preparedness relies on predicting immune-evasive viral mutations to ensure early detection of variants of concern and to design future-proofed vaccines and therapeutics. However, current experimental strategies for viral evolution prediction are not available early in a pandemic since  they require host polyclonal antibodies.  Furthermore, the existing paradigm for vaccine evaluation relies on retrospective evaluation against past variants, instead of proactive evaluation against future viral evolution. To address these limitations, we developed EVEscape, a model which integrated fitness predictions from evolutionary models, structure-based features that assess antibody binding potential, and biochemical distances between mutated and wild-type residues. EVEscape quantifies the viral escape potential of mutations at scale and has the advantage of being applicable before surveillance sequencing, experimental scans, or 3D structures of antibody complexes are available. Using only information available pre-pandemic, EVEscape is as accurate as high-throughput experimental scans at anticipating pandemic variation for SARS-CoV-2 and is generalizable to other viruses. Using EVEscape we forecast future SARS-CoV-2 evolution and present a novel and proactive approach for evaluating  and designing vaccines.	antibodies viruses future vaccine prediction antibody vaccines viral mia meeting		2021-02-14											Noor Youssef, Sarah Faye Gurev	138	0
Accurate proteome-wide missense variant effect prediction with Alpha Missens	The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present Alpha Missense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89% of missense variants as either likely benign or likely pathogenic.	proteome genes genome alpha missense accurate genetic prediction pathogenicity pathogenic mia meeting		2021-03-13											Žiga Avsec	139	0
Alpha Missens	The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present Alpha Missense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89% of missense variants as either likely benign or likely pathogenic.	genes genome alpha missens genetic pathogenicity pathogenic mia meeting		2021-03-13											Jun Cheng	140	0
Testing data-driven hypotheses post-clustering	This primer talk is motivated by the practice of testing data-driven hypotheses. In the biomedical sciences, it has become increasingly common to collect massive datasets without a pre-specified research question. In this setting, a data analyst might use the data both to generate a research question, and to test the associated null hypothesis. For example, in single-cell RNA-sequencing analyses, researchers often first cluster the cells, and then test for differences in the expected gene expression levels between the clusters to quantify up- or down-regulation of genes, annotate known cell types, and identify new cell types. However, this popular practice is invalid from a statistical perspective: once we have used the data to generate hypotheses, standard statistical inference tools are no longer valid. To tackle this problem, I developed a conditional selective approach to test for a difference in means between pairs of clusters obtained via hierarchical and k-means clustering. The proposed approach has appropriate statistical guarantees (e.g., selective Type 1 error control), and we demonstrate its use on single-cell RNA-sequencing data.	genes data research post biomedical researchers clustering rna testing hypotheses mia meeting		2021-03-20											Yiqun Chen	141	0
Data thinning to avoid double dipping	"""Double dipping"" is the practice of using the same data to fit and validate a model. Problems typically arise when standard statistical procedures are applied in settings involving double dipping. To avoid the challenges surrounding double dipping, a natural approach is to fit a model on one dataset, and then validate the model on another independent dataset. When we only have access to one dataset, we typically accomplish this via sample splitting. Unfortunately, in some problems, sample splitting is unattractive or impossible. In this talk, we are motivated by unsupervised problems that arise in the analysis of single cell RNA sequencing data, where sample splitting does not allow us to avoid double dipping. We first propose Poisson thinning, which splits a single observation drawn from a Poisson distribution into two independent pseudo-observations. We show that Poisson count splitting allows us to avoid double dipping in unsupervised settings. We next generalize the Poisson thinning framework to a variety of distributions, and refer to this general framework as ""data thinning"". Data thinning is applicable far beyond the context of single-cell RNA sequencing data, and is particularly useful for problems where sample splitting is unattractive or impossible."	statistical data avoid sequencing sample double thinning dipping mia meeting		2021-03-20											Lucy Gao	142	0
SPLASH unifies genomic analysis and discovery through a paradigm shift to statistics-first	Myriad mechanisms diversify the sequence content of DNA and of RNA transcripts. Currently, these events are detected using tools that first require alignment to a necessarily incomplete reference genome alignment in the first step; this incompleteness is especially prominent in human genetic diseases such as cancer, in the microbial world, and in non—model organisms where it severely limits the speed and scope of discovery. Second, today the next step in analysis requires as a custom choice of bioinformatic procedure to follow it: for example, to detect splicing, RNA editing, or V(D)J recombination among many others.  I will present the theory for why SPLASH, a new statistics-first analytic approach captures myriad forms of genome regulation, without a reference or sample metadata, by performing statistical inference directly on raw sequencing reads. By design, SPLASH as an algorithm is highly efficient. Thanks to joint work with Professor Sebastian Deorowicz’s group, SPLASH is now implemented so that it is efficient and simple to run. A snapshot of its findings include new insights into RNA splicing, cancer transcriptomes, single cell RNA-editing, mobile genetic elements and discovers new genes non-model organisms.	genome cancer statistics bioinformatic splash genomic genetic paradigm discovery dna mia meeting		2021-04-03											Julia Salzman	143	0
Statistical and algorithmic challenges in reference-free analysis	Today’s genomics workflows typically begin by aligning sequencing data to a reference. In addition to being slow, this has many statistical drawbacks. Even in the intensely studied human genome, it was found that understudied populations have large amounts of sequence missing from the current reference; such blind spots may exacerbate health disparities. Reference-based methods are additionally limited in their detection of novel biology: reads from unannotated isoforms may be mismapped or discarded completely. In recent work we introduce a unifying paradigm, SPLASH, which directly analyzes raw sequencing data, using a statistical test to detect a signature of regulation: sample-specific sequence variation. SPLASH detects many types of variation and can be efficiently run at scale, providing a unifying statistical approach to genomic analysis that enables expansive discovery without metadata or references. In this primer I’ll discuss some of the challenges of reference-free analysis, and provide the algorithmic and statistical background for our proposed solution, SPLASH.	statistical drawbacks genomics reference exacerbate algorithmic challenges biology genomic analysis mia meeting		2021-04-03											Tavor Baharav	144	0
Single-cell models for state-dependent eQTL analysis	As single-cell RNA-seq datasets grow larger and more complex, they enable richer analyses of how gene expression varies between cells and people. However, methods designed for bulk data fail to account for the unique structure of single-cell gene expression. Researchers are now developing statistical models tailored to single-cell-resolution data for a variety of applications. In this primer, I will focus on single-cell models for the task of mapping expression quantitative trait loci (eQTLs) to find genetic variants associated with a gene's expression. Single-cell eQTL models have the potential to capture disease-relevant, state-dependent regulatory effects with the right statistical models and representations of cell state. This primer will discuss the evolution of statistical models for eQTL mapping from pseudobulk to single-cell resolution, representations of single-cell states for state-dependent analyses, and outstanding computational challenges.	analysis state researchers disease computational genetic eqtl rna single cell mia meeting		2021-04-10											Aparna Nathan	145	0
Scalable single-cell models for robust cell-state-dependent eQTL mapping	Modelling cell state-dependent genetic associations with single-cell gene expression exhibits statistical and computational challenges. First, parametrization of single-cell gene expression profiles is not a straightforward task because individual genes exhibit distinct distributions. Second, current single-cell datasets consist of hundreds of thousands to millions of cells, which constrains the ability to test associations in a scalable manner. In this talk, I will introduce a new generalizable approach to robustly identify cell state-dependent eQTLs in single-cell data. To overcome the challenge of gene expression parametrization, we implemented a non-parametric bootstrap procedure to compute empirically calibrated p-values for variant-gene expression associations. To speed up the computation, we used the Julia programming language and pre-computed covariate-adjusted gene expression profiles with a linear mixed model before testing cell state-dependent eQTL interactions. Finally, I will demonstrate an application of this approach to identify autoimmune disease risk loci with context-specific effects in memory T cells.	genes autoimmune scalable computation mapping computational genetic eqtl robust cell mia meeting		2021-04-10											Jose Alquicira-Hernandez	146	0
Protein language models learn evolutionary statistics of interacting sequence motifs	Protein language models (pLMs) have exhibited remarkable capabilities in protein structure prediction and design. However, the extent to which they comprehend the intrinsic biophysics of protein structures remains uncertain. We present a suite of analyses that dissect how the flagship pLM ESM-2 predicts structure. Motivated by a consistent error of protein isoforms predicted as structured fragments, we developed a completely unsupervised method to uniformly evaluate any pLM, allowing us to compare coevolutionary statistics to linear models. We further identified that ESM-2 does not require full context for predicting inter-residue contacts. Our study highlights the current limitations of pLMs and contributes to a deeper understanding of their underlying mechanisms, paving the way for more reliable protein structure predictions.	statistics protein learn study biophysics analyses prediction evolutionary language mia meeting		2021-05-01											Sergey Ovchinnikov	147	0
Combining protein language and structure models to redesign E. coli proteome with a reduced amino acid alphabet	All known organisms need all 20 canonical amino acids to survive and reproduce, yet use of different amino acids must’ve evolved over time. Unfortunately, even the last universal common ancestor used all 20, so there is no way to observe how life might have looked without all of them. Here, we’re trying to synthesize such an organism by designing a strain of E. coli using only 19 canonical amino acids, starting from redesigning essential genes one at a time with the goal of preserving fitness. Since there are many diverse genes to design, we’re repurposing and extending machine learning-driven protein design methods to accomplish this task. Each of the currently available methods is capturing specific properties of the design landscape due to its approach and training data provided to the models. Protein language models like ESM have access to a vast number of sequences and can learn patterns favored by nature. Methods using AlphaFold as a loss function like AFDesign or MCMC hallucination are aware of the final structure of the protein, but are susceptible to adversarial examples. Finally, models which perform “inverse folding” like ProteinMPNN have both sequence and structure information and can output structure-aware designs. We’re developing optimization methods which combine these models as part of the design process to find sequences which are scored highly by models coming from different approaches, and how this translates to their biological properties. The experimental results show that our methods can generate designs comparable with wild-type versions in fitness with a small number of attempts.	genes amino protein proteinmpnn coli redesign alphabet 20 mia meeting		2021-05-01											Simon Kozlov	148	0
Protein Design with Deep Learning: Progress, Challenges, and Next Steps	The human proteome comprises tens of thousands of proteins, each tailored for a specific function by the selective pressures of evolution. The field of protein design seeks to develop proteins with new or enhanced functions at will, ultimately bypassing the evolutionary clock. In this talk, we discuss general machine-learning methods for accelerating the crucial components of protein design, with a particular focus on the underlying models. We begin with an overview of the protein design field and discuss traditional approaches. We then focus on two important subtasks, fixed-backbone design and protein-protein docking, and critique deep learning approaches with an emphasis on the modeling considerations that attribute to their success. Finally, we highlight some limitations and outstanding challenges in the field and potential next steps.	proteome protein challenges deep design proteins evolution evolutionary learning mia meeting		2021-05-08											Matthew McPartlon	149	0
Unlocking Generative AI for Drug Discovery with Zero-shot Models	Generative AI has the potential to greatly incrase the speed, quality, and controllability of drug design. Traditional discovery requires time and resource intensive screening of large libraries, which also offer little control on the output molecules, which can result in suboptimal candidates. Here, we show how generative deep learning models can produce molecules and representations that could be used for downstream design of new molecules with specified functions.	intensive learning unlocking screening models drug libraries generative discovery mia meeting		2021-05-08											Joshua Meier	150	0
Geometric deep learning and generative models for protein target discovery	Computational therapeutic target discovery requires deciphering the cell types in which proteins act and their interactions. We present PINNACLE, a contextual AI model for single-cell protein biology. Using a multi-organ single-cell atlas, PINNACLE learns from contextualized protein interaction networks, producing 394,760 protein representations from 156 cell types across 24 tissues. PINNACLE’s embedding space reflects cellular and tissue organization, enabling zero-shot retrieval of tissue hierarchy. Pretrained PINNACLE representations can power a range of tasks: enhancing 3D structure-based representations in immuno-oncology, predicting drug effects across cell types and states, and identifying therapeutic targets in a cell-type-specific manner. We used PINNACLE to nominate protein targets for rheumatoid arthritis and inflammatory bowel disease, identifying predictive cell type contexts. Drugs bind to protein pockets, areas where proteins interact with ligand molecules, a challenging task due to biomolecular interactions and sequence-structure dependencies. We developed PocketGen, a sequence-structure generative model that optimizes protein pockets to serve as optimal binders for ligand molecules. PocketGen iteratively refines the sequence and structure of pockets by maximizing binding affinity with the ligand and sequence-structure consistency. Using a graph transformer for all-atom structure modeling and a protein language model for sequence prediction, PocketGen can help optimize protein pockets with high binding affinity, strong structural validity and generation efficiency.	oncology protein learning biology biomolecular proteins geometric generative discovery mia meeting		2021-05-29											Marinka Zitnik	151	0
Multimodal protein language models for deciphering protein function	Understanding the relationship between a protein's amino acid sequence and its structure or function is a long-standing challenge with far-reaching implications for therapeutic development, as the effects of drugs are often directly linked to proteins. Current protein language models (PLMs) capture evolutionary relationships based on sequences but fall short of directly acquiring protein functions from multimodal molecular data, including protein sequences and structures, peptides, and domains. We develop a multimodal protein language model that integrates textual protein descriptions with a sequence-structure PLM to create a more comprehensive and functionally insightful model of proteins. This integration promises to bridge the current gap in PLMs, transitioning from understanding the structural aspects of proteins to gaining a functional view of vast protein space. The model allows scientists to express their queries in natural language and interact with protein models in an open-ended manner. It allows for text-based prediction of protein targets, multimodal protein captioning, and Q&A sessions with scientists with varying levels of expertise, among others. Trained on a new dataset of protein-text instructions, the model can generalize to new phenotypes in a zero-shot manner, making it versatile for diverse tasks even when functional annotations are scarce. We conclude with an outlook for the future with “AI scientists” as generative agents capable of skeptical learning and reasoning to empower biomedical research.	function scientists deciphering protein biomedical multimodal proteins molecular language mia meeting		2021-05-29											Owen Queen, Yepeng Huang, Marinka Zitnik	152	0
Hybrid protein language models for fitness prediction and design	The ability to accurately model the fitness landscape of protein sequences is critical to a wide range of applications, from quantifying the effects of human variants on disease likelihood, to predicting immune-escape mutations in viruses and designing novel biotherapeutic proteins. Deep generative models of protein sequences trained on multiple sequence alignments have been the most successful approaches so far to address these tasks. The performance of these methods is however contingent on the availability of sufficiently deep and diverse alignments for reliable training. Their potential scope is thus limited by the fact many protein families are hard, if not impossible, to align. Large language models trained on massive quantities of non-aligned protein sequences from diverse families seek to address these problems. However, their performance has not yet matched that of their alignment-based counterparts. This talk will introduce hybrid strategies to leverage the strengths from both model classes	biotherapeutic fitness hybrid protein design proteins hard prediction massive mia meeting		2022-02-14											Pascal Notin	153	0
Unsupervised viral antibody escape prediction for future-proof vaccines	Effective pandemic preparedness relies on predicting immune-evasive viral mutations to ensure early detection of variants of concern and to design future-proofed vaccines and therapeutics. However, current experimental strategies for viral evolution prediction are not available early in a pandemic since  they require host polyclonal antibodies.  Furthermore, the existing paradigm for vaccine evaluation relies on retrospective evaluation against past variants, instead of proactive evaluation against future viral evolution. To address these limitations, we developed EVEscape, a model which integrated fitness predictions from evolutionary models, structure-based features that assess antibody binding potential, and biochemical distances between mutated and wild-type residues. EVEscape quantifies the viral escape potential of mutations at scale and has the advantage of being applicable before surveillance sequencing, experimental scans, or 3D structures of antibody complexes are available. Using only information available pre-pandemic, EVEscape is as accurate as high-throughput experimental scans at anticipating pandemic variation for SARS-CoV-2 and is generalizable to other viruses. Using EVEscape we forecast future SARS-CoV-2 evolution and present a novel and proactive approach for evaluating  and designing vaccines.	antibodies viruses future vaccine prediction antibody vaccines viral mia meeting		2022-02-14											Noor Youssef, Sarah Faye Gurev	154	0
Accurate proteome-wide missense variant effect prediction with Alpha Missens	The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present Alpha Missense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89% of missense variants as either likely benign or likely pathogenic.	proteome genes genome alpha missense accurate genetic prediction pathogenicity pathogenic mia meeting		2022-03-13											Žiga Avsec	155	0
Alpha Missens	The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present Alpha Missense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89% of missense variants as either likely benign or likely pathogenic.	genes genome alpha missens genetic pathogenicity pathogenic mia meeting		2022-03-13											Jun Cheng	156	0
Testing data-driven hypotheses post-clustering	This primer talk is motivated by the practice of testing data-driven hypotheses. In the biomedical sciences, it has become increasingly common to collect massive datasets without a pre-specified research question. In this setting, a data analyst might use the data both to generate a research question, and to test the associated null hypothesis. For example, in single-cell RNA-sequencing analyses, researchers often first cluster the cells, and then test for differences in the expected gene expression levels between the clusters to quantify up- or down-regulation of genes, annotate known cell types, and identify new cell types. However, this popular practice is invalid from a statistical perspective: once we have used the data to generate hypotheses, standard statistical inference tools are no longer valid. To tackle this problem, I developed a conditional selective approach to test for a difference in means between pairs of clusters obtained via hierarchical and k-means clustering. The proposed approach has appropriate statistical guarantees (e.g., selective Type 1 error control), and we demonstrate its use on single-cell RNA-sequencing data.	genes data research post biomedical researchers clustering rna testing hypotheses mia meeting		2022-03-20											Yiqun Chen	157	0
Data thinning to avoid double dipping	"""Double dipping"" is the practice of using the same data to fit and validate a model. Problems typically arise when standard statistical procedures are applied in settings involving double dipping. To avoid the challenges surrounding double dipping, a natural approach is to fit a model on one dataset, and then validate the model on another independent dataset. When we only have access to one dataset, we typically accomplish this via sample splitting. Unfortunately, in some problems, sample splitting is unattractive or impossible. In this talk, we are motivated by unsupervised problems that arise in the analysis of single cell RNA sequencing data, where sample splitting does not allow us to avoid double dipping. We first propose Poisson thinning, which splits a single observation drawn from a Poisson distribution into two independent pseudo-observations. We show that Poisson count splitting allows us to avoid double dipping in unsupervised settings. We next generalize the Poisson thinning framework to a variety of distributions, and refer to this general framework as ""data thinning"". Data thinning is applicable far beyond the context of single-cell RNA sequencing data, and is particularly useful for problems where sample splitting is unattractive or impossible."	statistical data avoid sequencing sample double thinning dipping mia meeting		2022-03-20											Lucy Gao	158	0
SPLASH unifies genomic analysis and discovery through a paradigm shift to statistics-first	Myriad mechanisms diversify the sequence content of DNA and of RNA transcripts. Currently, these events are detected using tools that first require alignment to a necessarily incomplete reference genome alignment in the first step; this incompleteness is especially prominent in human genetic diseases such as cancer, in the microbial world, and in non—model organisms where it severely limits the speed and scope of discovery. Second, today the next step in analysis requires as a custom choice of bioinformatic procedure to follow it: for example, to detect splicing, RNA editing, or V(D)J recombination among many others.  I will present the theory for why SPLASH, a new statistics-first analytic approach captures myriad forms of genome regulation, without a reference or sample metadata, by performing statistical inference directly on raw sequencing reads. By design, SPLASH as an algorithm is highly efficient. Thanks to joint work with Professor Sebastian Deorowicz’s group, SPLASH is now implemented so that it is efficient and simple to run. A snapshot of its findings include new insights into RNA splicing, cancer transcriptomes, single cell RNA-editing, mobile genetic elements and discovers new genes non-model organisms.	genome cancer statistics bioinformatic splash genomic genetic paradigm discovery dna mia meeting		2022-04-03											Julia Salzman	159	0
Statistical and algorithmic challenges in reference-free analysis	Today’s genomics workflows typically begin by aligning sequencing data to a reference. In addition to being slow, this has many statistical drawbacks. Even in the intensely studied human genome, it was found that understudied populations have large amounts of sequence missing from the current reference; such blind spots may exacerbate health disparities. Reference-based methods are additionally limited in their detection of novel biology: reads from unannotated isoforms may be mismapped or discarded completely. In recent work we introduce a unifying paradigm, SPLASH, which directly analyzes raw sequencing data, using a statistical test to detect a signature of regulation: sample-specific sequence variation. SPLASH detects many types of variation and can be efficiently run at scale, providing a unifying statistical approach to genomic analysis that enables expansive discovery without metadata or references. In this primer I’ll discuss some of the challenges of reference-free analysis, and provide the algorithmic and statistical background for our proposed solution, SPLASH.	statistical drawbacks genomics reference exacerbate algorithmic challenges biology genomic analysis mia meeting		2022-04-03											Tavor Baharav	160	0
Single-cell models for state-dependent eQTL analysis	As single-cell RNA-seq datasets grow larger and more complex, they enable richer analyses of how gene expression varies between cells and people. However, methods designed for bulk data fail to account for the unique structure of single-cell gene expression. Researchers are now developing statistical models tailored to single-cell-resolution data for a variety of applications. In this primer, I will focus on single-cell models for the task of mapping expression quantitative trait loci (eQTLs) to find genetic variants associated with a gene's expression. Single-cell eQTL models have the potential to capture disease-relevant, state-dependent regulatory effects with the right statistical models and representations of cell state. This primer will discuss the evolution of statistical models for eQTL mapping from pseudobulk to single-cell resolution, representations of single-cell states for state-dependent analyses, and outstanding computational challenges.	analysis state researchers disease computational genetic eqtl rna single cell mia meeting		2022-04-10											Aparna Nathan	161	0
Scalable single-cell models for robust cell-state-dependent eQTL mapping	Modelling cell state-dependent genetic associations with single-cell gene expression exhibits statistical and computational challenges. First, parametrization of single-cell gene expression profiles is not a straightforward task because individual genes exhibit distinct distributions. Second, current single-cell datasets consist of hundreds of thousands to millions of cells, which constrains the ability to test associations in a scalable manner. In this talk, I will introduce a new generalizable approach to robustly identify cell state-dependent eQTLs in single-cell data. To overcome the challenge of gene expression parametrization, we implemented a non-parametric bootstrap procedure to compute empirically calibrated p-values for variant-gene expression associations. To speed up the computation, we used the Julia programming language and pre-computed covariate-adjusted gene expression profiles with a linear mixed model before testing cell state-dependent eQTL interactions. Finally, I will demonstrate an application of this approach to identify autoimmune disease risk loci with context-specific effects in memory T cells.	genes autoimmune scalable computation mapping computational genetic eqtl robust cell mia meeting		2022-04-10											Jose Alquicira-Hernandez	162	0
Protein language models learn evolutionary statistics of interacting sequence motifs	Protein language models (pLMs) have exhibited remarkable capabilities in protein structure prediction and design. However, the extent to which they comprehend the intrinsic biophysics of protein structures remains uncertain. We present a suite of analyses that dissect how the flagship pLM ESM-2 predicts structure. Motivated by a consistent error of protein isoforms predicted as structured fragments, we developed a completely unsupervised method to uniformly evaluate any pLM, allowing us to compare coevolutionary statistics to linear models. We further identified that ESM-2 does not require full context for predicting inter-residue contacts. Our study highlights the current limitations of pLMs and contributes to a deeper understanding of their underlying mechanisms, paving the way for more reliable protein structure predictions.	statistics protein learn study biophysics analyses prediction evolutionary language mia meeting		2022-05-01											Sergey Ovchinnikov	163	0
Combining protein language and structure models to redesign E. coli proteome with a reduced amino acid alphabet	All known organisms need all 20 canonical amino acids to survive and reproduce, yet use of different amino acids must’ve evolved over time. Unfortunately, even the last universal common ancestor used all 20, so there is no way to observe how life might have looked without all of them. Here, we’re trying to synthesize such an organism by designing a strain of E. coli using only 19 canonical amino acids, starting from redesigning essential genes one at a time with the goal of preserving fitness. Since there are many diverse genes to design, we’re repurposing and extending machine learning-driven protein design methods to accomplish this task. Each of the currently available methods is capturing specific properties of the design landscape due to its approach and training data provided to the models. Protein language models like ESM have access to a vast number of sequences and can learn patterns favored by nature. Methods using AlphaFold as a loss function like AFDesign or MCMC hallucination are aware of the final structure of the protein, but are susceptible to adversarial examples. Finally, models which perform “inverse folding” like ProteinMPNN have both sequence and structure information and can output structure-aware designs. We’re developing optimization methods which combine these models as part of the design process to find sequences which are scored highly by models coming from different approaches, and how this translates to their biological properties. The experimental results show that our methods can generate designs comparable with wild-type versions in fitness with a small number of attempts.	genes amino protein proteinmpnn coli redesign alphabet 20 mia meeting		2022-05-01											Simon Kozlov	164	0
Protein Design with Deep Learning: Progress, Challenges, and Next Steps	The human proteome comprises tens of thousands of proteins, each tailored for a specific function by the selective pressures of evolution. The field of protein design seeks to develop proteins with new or enhanced functions at will, ultimately bypassing the evolutionary clock. In this talk, we discuss general machine-learning methods for accelerating the crucial components of protein design, with a particular focus on the underlying models. We begin with an overview of the protein design field and discuss traditional approaches. We then focus on two important subtasks, fixed-backbone design and protein-protein docking, and critique deep learning approaches with an emphasis on the modeling considerations that attribute to their success. Finally, we highlight some limitations and outstanding challenges in the field and potential next steps.	proteome protein challenges deep design proteins evolution evolutionary learning mia meeting		2022-05-08											Matthew McPartlon	165	0
Unlocking Generative AI for Drug Discovery with Zero-shot Models	Generative AI has the potential to greatly incrase the speed, quality, and controllability of drug design. Traditional discovery requires time and resource intensive screening of large libraries, which also offer little control on the output molecules, which can result in suboptimal candidates. Here, we show how generative deep learning models can produce molecules and representations that could be used for downstream design of new molecules with specified functions.	intensive learning unlocking screening models drug libraries generative discovery mia meeting		2022-05-08											Joshua Meier	166	0
Geometric deep learning and generative models for protein target discovery	Computational therapeutic target discovery requires deciphering the cell types in which proteins act and their interactions. We present PINNACLE, a contextual AI model for single-cell protein biology. Using a multi-organ single-cell atlas, PINNACLE learns from contextualized protein interaction networks, producing 394,760 protein representations from 156 cell types across 24 tissues. PINNACLE’s embedding space reflects cellular and tissue organization, enabling zero-shot retrieval of tissue hierarchy. Pretrained PINNACLE representations can power a range of tasks: enhancing 3D structure-based representations in immuno-oncology, predicting drug effects across cell types and states, and identifying therapeutic targets in a cell-type-specific manner. We used PINNACLE to nominate protein targets for rheumatoid arthritis and inflammatory bowel disease, identifying predictive cell type contexts. Drugs bind to protein pockets, areas where proteins interact with ligand molecules, a challenging task due to biomolecular interactions and sequence-structure dependencies. We developed PocketGen, a sequence-structure generative model that optimizes protein pockets to serve as optimal binders for ligand molecules. PocketGen iteratively refines the sequence and structure of pockets by maximizing binding affinity with the ligand and sequence-structure consistency. Using a graph transformer for all-atom structure modeling and a protein language model for sequence prediction, PocketGen can help optimize protein pockets with high binding affinity, strong structural validity and generation efficiency.	oncology protein learning biology biomolecular proteins geometric generative discovery mia meeting		2022-05-29											Marinka Zitnik	167	0
Multimodal protein language models for deciphering protein function	Understanding the relationship between a protein's amino acid sequence and its structure or function is a long-standing challenge with far-reaching implications for therapeutic development, as the effects of drugs are often directly linked to proteins. Current protein language models (PLMs) capture evolutionary relationships based on sequences but fall short of directly acquiring protein functions from multimodal molecular data, including protein sequences and structures, peptides, and domains. We develop a multimodal protein language model that integrates textual protein descriptions with a sequence-structure PLM to create a more comprehensive and functionally insightful model of proteins. This integration promises to bridge the current gap in PLMs, transitioning from understanding the structural aspects of proteins to gaining a functional view of vast protein space. The model allows scientists to express their queries in natural language and interact with protein models in an open-ended manner. It allows for text-based prediction of protein targets, multimodal protein captioning, and Q&A sessions with scientists with varying levels of expertise, among others. Trained on a new dataset of protein-text instructions, the model can generalize to new phenotypes in a zero-shot manner, making it versatile for diverse tasks even when functional annotations are scarce. We conclude with an outlook for the future with “AI scientists” as generative agents capable of skeptical learning and reasoning to empower biomedical research.	function scientists deciphering protein biomedical multimodal proteins molecular language mia meeting		2022-05-29											Owen Queen, Yepeng Huang, Marinka Zitnik	168	0
Hybrid protein language models for fitness prediction and design	The ability to accurately model the fitness landscape of protein sequences is critical to a wide range of applications, from quantifying the effects of human variants on disease likelihood, to predicting immune-escape mutations in viruses and designing novel biotherapeutic proteins. Deep generative models of protein sequences trained on multiple sequence alignments have been the most successful approaches so far to address these tasks. The performance of these methods is however contingent on the availability of sufficiently deep and diverse alignments for reliable training. Their potential scope is thus limited by the fact many protein families are hard, if not impossible, to align. Large language models trained on massive quantities of non-aligned protein sequences from diverse families seek to address these problems. However, their performance has not yet matched that of their alignment-based counterparts. This talk will introduce hybrid strategies to leverage the strengths from both model classes	biotherapeutic fitness hybrid protein design proteins hard prediction massive mia meeting		2023-02-14											Pascal Notin	169	0
Unsupervised viral antibody escape prediction for future-proof vaccines	Effective pandemic preparedness relies on predicting immune-evasive viral mutations to ensure early detection of variants of concern and to design future-proofed vaccines and therapeutics. However, current experimental strategies for viral evolution prediction are not available early in a pandemic since  they require host polyclonal antibodies.  Furthermore, the existing paradigm for vaccine evaluation relies on retrospective evaluation against past variants, instead of proactive evaluation against future viral evolution. To address these limitations, we developed EVEscape, a model which integrated fitness predictions from evolutionary models, structure-based features that assess antibody binding potential, and biochemical distances between mutated and wild-type residues. EVEscape quantifies the viral escape potential of mutations at scale and has the advantage of being applicable before surveillance sequencing, experimental scans, or 3D structures of antibody complexes are available. Using only information available pre-pandemic, EVEscape is as accurate as high-throughput experimental scans at anticipating pandemic variation for SARS-CoV-2 and is generalizable to other viruses. Using EVEscape we forecast future SARS-CoV-2 evolution and present a novel and proactive approach for evaluating  and designing vaccines.	antibodies viruses future vaccine prediction antibody vaccines viral mia meeting		2023-02-14											Noor Youssef, Sarah Faye Gurev	170	0
Accurate proteome-wide missense variant effect prediction with Alpha Missens	The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present Alpha Missense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89% of missense variants as either likely benign or likely pathogenic.	proteome genes genome alpha missense accurate genetic prediction pathogenicity pathogenic mia meeting		2023-03-13											Žiga Avsec	171	0
Alpha Missens	The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present Alpha Missense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89% of missense variants as either likely benign or likely pathogenic.	genes genome alpha missens genetic pathogenicity pathogenic mia meeting		2023-03-13											Jun Cheng	172	0
Testing data-driven hypotheses post-clustering	This primer talk is motivated by the practice of testing data-driven hypotheses. In the biomedical sciences, it has become increasingly common to collect massive datasets without a pre-specified research question. In this setting, a data analyst might use the data both to generate a research question, and to test the associated null hypothesis. For example, in single-cell RNA-sequencing analyses, researchers often first cluster the cells, and then test for differences in the expected gene expression levels between the clusters to quantify up- or down-regulation of genes, annotate known cell types, and identify new cell types. However, this popular practice is invalid from a statistical perspective: once we have used the data to generate hypotheses, standard statistical inference tools are no longer valid. To tackle this problem, I developed a conditional selective approach to test for a difference in means between pairs of clusters obtained via hierarchical and k-means clustering. The proposed approach has appropriate statistical guarantees (e.g., selective Type 1 error control), and we demonstrate its use on single-cell RNA-sequencing data.	genes data research post biomedical researchers clustering rna testing hypotheses mia meeting		2023-03-20											Yiqun Chen	173	0
Data thinning to avoid double dipping	"""Double dipping"" is the practice of using the same data to fit and validate a model. Problems typically arise when standard statistical procedures are applied in settings involving double dipping. To avoid the challenges surrounding double dipping, a natural approach is to fit a model on one dataset, and then validate the model on another independent dataset. When we only have access to one dataset, we typically accomplish this via sample splitting. Unfortunately, in some problems, sample splitting is unattractive or impossible. In this talk, we are motivated by unsupervised problems that arise in the analysis of single cell RNA sequencing data, where sample splitting does not allow us to avoid double dipping. We first propose Poisson thinning, which splits a single observation drawn from a Poisson distribution into two independent pseudo-observations. We show that Poisson count splitting allows us to avoid double dipping in unsupervised settings. We next generalize the Poisson thinning framework to a variety of distributions, and refer to this general framework as ""data thinning"". Data thinning is applicable far beyond the context of single-cell RNA sequencing data, and is particularly useful for problems where sample splitting is unattractive or impossible."	statistical data avoid sequencing sample double thinning dipping mia meeting		2023-03-20											Lucy Gao	174	0
SPLASH unifies genomic analysis and discovery through a paradigm shift to statistics-first	Myriad mechanisms diversify the sequence content of DNA and of RNA transcripts. Currently, these events are detected using tools that first require alignment to a necessarily incomplete reference genome alignment in the first step; this incompleteness is especially prominent in human genetic diseases such as cancer, in the microbial world, and in non—model organisms where it severely limits the speed and scope of discovery. Second, today the next step in analysis requires as a custom choice of bioinformatic procedure to follow it: for example, to detect splicing, RNA editing, or V(D)J recombination among many others.  I will present the theory for why SPLASH, a new statistics-first analytic approach captures myriad forms of genome regulation, without a reference or sample metadata, by performing statistical inference directly on raw sequencing reads. By design, SPLASH as an algorithm is highly efficient. Thanks to joint work with Professor Sebastian Deorowicz’s group, SPLASH is now implemented so that it is efficient and simple to run. A snapshot of its findings include new insights into RNA splicing, cancer transcriptomes, single cell RNA-editing, mobile genetic elements and discovers new genes non-model organisms.	genome cancer statistics bioinformatic splash genomic genetic paradigm discovery dna mia meeting		2023-04-03											Julia Salzman	175	0
Statistical and algorithmic challenges in reference-free analysis	Today’s genomics workflows typically begin by aligning sequencing data to a reference. In addition to being slow, this has many statistical drawbacks. Even in the intensely studied human genome, it was found that understudied populations have large amounts of sequence missing from the current reference; such blind spots may exacerbate health disparities. Reference-based methods are additionally limited in their detection of novel biology: reads from unannotated isoforms may be mismapped or discarded completely. In recent work we introduce a unifying paradigm, SPLASH, which directly analyzes raw sequencing data, using a statistical test to detect a signature of regulation: sample-specific sequence variation. SPLASH detects many types of variation and can be efficiently run at scale, providing a unifying statistical approach to genomic analysis that enables expansive discovery without metadata or references. In this primer I’ll discuss some of the challenges of reference-free analysis, and provide the algorithmic and statistical background for our proposed solution, SPLASH.	statistical drawbacks genomics reference exacerbate algorithmic challenges biology genomic analysis mia meeting		2023-04-03											Tavor Baharav	176	0
Single-cell models for state-dependent eQTL analysis	As single-cell RNA-seq datasets grow larger and more complex, they enable richer analyses of how gene expression varies between cells and people. However, methods designed for bulk data fail to account for the unique structure of single-cell gene expression. Researchers are now developing statistical models tailored to single-cell-resolution data for a variety of applications. In this primer, I will focus on single-cell models for the task of mapping expression quantitative trait loci (eQTLs) to find genetic variants associated with a gene's expression. Single-cell eQTL models have the potential to capture disease-relevant, state-dependent regulatory effects with the right statistical models and representations of cell state. This primer will discuss the evolution of statistical models for eQTL mapping from pseudobulk to single-cell resolution, representations of single-cell states for state-dependent analyses, and outstanding computational challenges.	analysis state researchers disease computational genetic eqtl rna single cell mia meeting		2023-04-10											Aparna Nathan	177	0
Scalable single-cell models for robust cell-state-dependent eQTL mapping	Modelling cell state-dependent genetic associations with single-cell gene expression exhibits statistical and computational challenges. First, parametrization of single-cell gene expression profiles is not a straightforward task because individual genes exhibit distinct distributions. Second, current single-cell datasets consist of hundreds of thousands to millions of cells, which constrains the ability to test associations in a scalable manner. In this talk, I will introduce a new generalizable approach to robustly identify cell state-dependent eQTLs in single-cell data. To overcome the challenge of gene expression parametrization, we implemented a non-parametric bootstrap procedure to compute empirically calibrated p-values for variant-gene expression associations. To speed up the computation, we used the Julia programming language and pre-computed covariate-adjusted gene expression profiles with a linear mixed model before testing cell state-dependent eQTL interactions. Finally, I will demonstrate an application of this approach to identify autoimmune disease risk loci with context-specific effects in memory T cells.	genes autoimmune scalable computation mapping computational genetic eqtl robust cell mia meeting		2023-04-10											Jose Alquicira-Hernandez	178	0
Protein language models learn evolutionary statistics of interacting sequence motifs	Protein language models (pLMs) have exhibited remarkable capabilities in protein structure prediction and design. However, the extent to which they comprehend the intrinsic biophysics of protein structures remains uncertain. We present a suite of analyses that dissect how the flagship pLM ESM-2 predicts structure. Motivated by a consistent error of protein isoforms predicted as structured fragments, we developed a completely unsupervised method to uniformly evaluate any pLM, allowing us to compare coevolutionary statistics to linear models. We further identified that ESM-2 does not require full context for predicting inter-residue contacts. Our study highlights the current limitations of pLMs and contributes to a deeper understanding of their underlying mechanisms, paving the way for more reliable protein structure predictions.	statistics protein learn study biophysics analyses prediction evolutionary language mia meeting		2023-05-01											Sergey Ovchinnikov	179	0
Combining protein language and structure models to redesign E. coli proteome with a reduced amino acid alphabet	All known organisms need all 20 canonical amino acids to survive and reproduce, yet use of different amino acids must’ve evolved over time. Unfortunately, even the last universal common ancestor used all 20, so there is no way to observe how life might have looked without all of them. Here, we’re trying to synthesize such an organism by designing a strain of E. coli using only 19 canonical amino acids, starting from redesigning essential genes one at a time with the goal of preserving fitness. Since there are many diverse genes to design, we’re repurposing and extending machine learning-driven protein design methods to accomplish this task. Each of the currently available methods is capturing specific properties of the design landscape due to its approach and training data provided to the models. Protein language models like ESM have access to a vast number of sequences and can learn patterns favored by nature. Methods using AlphaFold as a loss function like AFDesign or MCMC hallucination are aware of the final structure of the protein, but are susceptible to adversarial examples. Finally, models which perform “inverse folding” like ProteinMPNN have both sequence and structure information and can output structure-aware designs. We’re developing optimization methods which combine these models as part of the design process to find sequences which are scored highly by models coming from different approaches, and how this translates to their biological properties. The experimental results show that our methods can generate designs comparable with wild-type versions in fitness with a small number of attempts.	genes amino protein proteinmpnn coli redesign alphabet 20 mia meeting		2023-05-01											Simon Kozlov	180	0
Protein Design with Deep Learning: Progress, Challenges, and Next Steps	The human proteome comprises tens of thousands of proteins, each tailored for a specific function by the selective pressures of evolution. The field of protein design seeks to develop proteins with new or enhanced functions at will, ultimately bypassing the evolutionary clock. In this talk, we discuss general machine-learning methods for accelerating the crucial components of protein design, with a particular focus on the underlying models. We begin with an overview of the protein design field and discuss traditional approaches. We then focus on two important subtasks, fixed-backbone design and protein-protein docking, and critique deep learning approaches with an emphasis on the modeling considerations that attribute to their success. Finally, we highlight some limitations and outstanding challenges in the field and potential next steps.	proteome protein challenges deep design proteins evolution evolutionary learning mia meeting		2023-05-08											Matthew McPartlon	181	0
Unlocking Generative AI for Drug Discovery with Zero-shot Models	Generative AI has the potential to greatly incrase the speed, quality, and controllability of drug design. Traditional discovery requires time and resource intensive screening of large libraries, which also offer little control on the output molecules, which can result in suboptimal candidates. Here, we show how generative deep learning models can produce molecules and representations that could be used for downstream design of new molecules with specified functions.	intensive learning unlocking screening models drug libraries generative discovery mia meeting		2023-05-08											Joshua Meier	182	0
Geometric deep learning and generative models for protein target discovery	Computational therapeutic target discovery requires deciphering the cell types in which proteins act and their interactions. We present PINNACLE, a contextual AI model for single-cell protein biology. Using a multi-organ single-cell atlas, PINNACLE learns from contextualized protein interaction networks, producing 394,760 protein representations from 156 cell types across 24 tissues. PINNACLE’s embedding space reflects cellular and tissue organization, enabling zero-shot retrieval of tissue hierarchy. Pretrained PINNACLE representations can power a range of tasks: enhancing 3D structure-based representations in immuno-oncology, predicting drug effects across cell types and states, and identifying therapeutic targets in a cell-type-specific manner. We used PINNACLE to nominate protein targets for rheumatoid arthritis and inflammatory bowel disease, identifying predictive cell type contexts. Drugs bind to protein pockets, areas where proteins interact with ligand molecules, a challenging task due to biomolecular interactions and sequence-structure dependencies. We developed PocketGen, a sequence-structure generative model that optimizes protein pockets to serve as optimal binders for ligand molecules. PocketGen iteratively refines the sequence and structure of pockets by maximizing binding affinity with the ligand and sequence-structure consistency. Using a graph transformer for all-atom structure modeling and a protein language model for sequence prediction, PocketGen can help optimize protein pockets with high binding affinity, strong structural validity and generation efficiency.	oncology protein learning biology biomolecular proteins geometric generative discovery mia meeting		2023-05-29											Marinka Zitnik	183	0
Multimodal protein language models for deciphering protein function	Understanding the relationship between a protein's amino acid sequence and its structure or function is a long-standing challenge with far-reaching implications for therapeutic development, as the effects of drugs are often directly linked to proteins. Current protein language models (PLMs) capture evolutionary relationships based on sequences but fall short of directly acquiring protein functions from multimodal molecular data, including protein sequences and structures, peptides, and domains. We develop a multimodal protein language model that integrates textual protein descriptions with a sequence-structure PLM to create a more comprehensive and functionally insightful model of proteins. This integration promises to bridge the current gap in PLMs, transitioning from understanding the structural aspects of proteins to gaining a functional view of vast protein space. The model allows scientists to express their queries in natural language and interact with protein models in an open-ended manner. It allows for text-based prediction of protein targets, multimodal protein captioning, and Q&A sessions with scientists with varying levels of expertise, among others. Trained on a new dataset of protein-text instructions, the model can generalize to new phenotypes in a zero-shot manner, making it versatile for diverse tasks even when functional annotations are scarce. We conclude with an outlook for the future with “AI scientists” as generative agents capable of skeptical learning and reasoning to empower biomedical research.	function scientists deciphering protein biomedical multimodal proteins molecular language mia meeting		2023-05-29											Owen Queen, Yepeng Huang, Marinka Zitnik	184	0
Hybrid protein language models for fitness prediction and design	The ability to accurately model the fitness landscape of protein sequences is critical to a wide range of applications, from quantifying the effects of human variants on disease likelihood, to predicting immune-escape mutations in viruses and designing novel biotherapeutic proteins. Deep generative models of protein sequences trained on multiple sequence alignments have been the most successful approaches so far to address these tasks. The performance of these methods is however contingent on the availability of sufficiently deep and diverse alignments for reliable training. Their potential scope is thus limited by the fact many protein families are hard, if not impossible, to align. Large language models trained on massive quantities of non-aligned protein sequences from diverse families seek to address these problems. However, their performance has not yet matched that of their alignment-based counterparts. This talk will introduce hybrid strategies to leverage the strengths from both model classes	biotherapeutic fitness hybrid protein design proteins hard prediction massive mia meeting		2020-02-14											Pascal Notin	185	0
Unsupervised viral antibody escape prediction for future-proof vaccines	Effective pandemic preparedness relies on predicting immune-evasive viral mutations to ensure early detection of variants of concern and to design future-proofed vaccines and therapeutics. However, current experimental strategies for viral evolution prediction are not available early in a pandemic since  they require host polyclonal antibodies.  Furthermore, the existing paradigm for vaccine evaluation relies on retrospective evaluation against past variants, instead of proactive evaluation against future viral evolution. To address these limitations, we developed EVEscape, a model which integrated fitness predictions from evolutionary models, structure-based features that assess antibody binding potential, and biochemical distances between mutated and wild-type residues. EVEscape quantifies the viral escape potential of mutations at scale and has the advantage of being applicable before surveillance sequencing, experimental scans, or 3D structures of antibody complexes are available. Using only information available pre-pandemic, EVEscape is as accurate as high-throughput experimental scans at anticipating pandemic variation for SARS-CoV-2 and is generalizable to other viruses. Using EVEscape we forecast future SARS-CoV-2 evolution and present a novel and proactive approach for evaluating  and designing vaccines.	antibodies viruses future vaccine prediction antibody vaccines viral mia meeting		2020-02-14											Noor Youssef, Sarah Faye Gurev	186	0
Accurate proteome-wide missense variant effect prediction with Alpha Missens	The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present Alpha Missense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89% of missense variants as either likely benign or likely pathogenic.	proteome genes genome alpha missense accurate genetic prediction pathogenicity pathogenic mia meeting		2020-03-13											Žiga Avsec	187	0
Alpha Missens	The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present Alpha Missense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89% of missense variants as either likely benign or likely pathogenic.	genes genome alpha missens genetic pathogenicity pathogenic mia meeting		2020-03-13											Jun Cheng	188	0
Testing data-driven hypotheses post-clustering	This primer talk is motivated by the practice of testing data-driven hypotheses. In the biomedical sciences, it has become increasingly common to collect massive datasets without a pre-specified research question. In this setting, a data analyst might use the data both to generate a research question, and to test the associated null hypothesis. For example, in single-cell RNA-sequencing analyses, researchers often first cluster the cells, and then test for differences in the expected gene expression levels between the clusters to quantify up- or down-regulation of genes, annotate known cell types, and identify new cell types. However, this popular practice is invalid from a statistical perspective: once we have used the data to generate hypotheses, standard statistical inference tools are no longer valid. To tackle this problem, I developed a conditional selective approach to test for a difference in means between pairs of clusters obtained via hierarchical and k-means clustering. The proposed approach has appropriate statistical guarantees (e.g., selective Type 1 error control), and we demonstrate its use on single-cell RNA-sequencing data.	genes data research post biomedical researchers clustering rna testing hypotheses mia meeting		2020-03-20											Yiqun Chen	189	0
Data thinning to avoid double dipping	"""Double dipping"" is the practice of using the same data to fit and validate a model. Problems typically arise when standard statistical procedures are applied in settings involving double dipping. To avoid the challenges surrounding double dipping, a natural approach is to fit a model on one dataset, and then validate the model on another independent dataset. When we only have access to one dataset, we typically accomplish this via sample splitting. Unfortunately, in some problems, sample splitting is unattractive or impossible. In this talk, we are motivated by unsupervised problems that arise in the analysis of single cell RNA sequencing data, where sample splitting does not allow us to avoid double dipping. We first propose Poisson thinning, which splits a single observation drawn from a Poisson distribution into two independent pseudo-observations. We show that Poisson count splitting allows us to avoid double dipping in unsupervised settings. We next generalize the Poisson thinning framework to a variety of distributions, and refer to this general framework as ""data thinning"". Data thinning is applicable far beyond the context of single-cell RNA sequencing data, and is particularly useful for problems where sample splitting is unattractive or impossible."	statistical data avoid sequencing sample double thinning dipping mia meeting		2020-03-20											Lucy Gao	190	0
SPLASH unifies genomic analysis and discovery through a paradigm shift to statistics-first	Myriad mechanisms diversify the sequence content of DNA and of RNA transcripts. Currently, these events are detected using tools that first require alignment to a necessarily incomplete reference genome alignment in the first step; this incompleteness is especially prominent in human genetic diseases such as cancer, in the microbial world, and in non—model organisms where it severely limits the speed and scope of discovery. Second, today the next step in analysis requires as a custom choice of bioinformatic procedure to follow it: for example, to detect splicing, RNA editing, or V(D)J recombination among many others.  I will present the theory for why SPLASH, a new statistics-first analytic approach captures myriad forms of genome regulation, without a reference or sample metadata, by performing statistical inference directly on raw sequencing reads. By design, SPLASH as an algorithm is highly efficient. Thanks to joint work with Professor Sebastian Deorowicz’s group, SPLASH is now implemented so that it is efficient and simple to run. A snapshot of its findings include new insights into RNA splicing, cancer transcriptomes, single cell RNA-editing, mobile genetic elements and discovers new genes non-model organisms.	genome cancer statistics bioinformatic splash genomic genetic paradigm discovery dna mia meeting		2020-04-03											Julia Salzman	191	0
Statistical and algorithmic challenges in reference-free analysis	Today’s genomics workflows typically begin by aligning sequencing data to a reference. In addition to being slow, this has many statistical drawbacks. Even in the intensely studied human genome, it was found that understudied populations have large amounts of sequence missing from the current reference; such blind spots may exacerbate health disparities. Reference-based methods are additionally limited in their detection of novel biology: reads from unannotated isoforms may be mismapped or discarded completely. In recent work we introduce a unifying paradigm, SPLASH, which directly analyzes raw sequencing data, using a statistical test to detect a signature of regulation: sample-specific sequence variation. SPLASH detects many types of variation and can be efficiently run at scale, providing a unifying statistical approach to genomic analysis that enables expansive discovery without metadata or references. In this primer I’ll discuss some of the challenges of reference-free analysis, and provide the algorithmic and statistical background for our proposed solution, SPLASH.	statistical drawbacks genomics reference exacerbate algorithmic challenges biology genomic analysis mia meeting		2020-04-03											Tavor Baharav	192	0
Single-cell models for state-dependent eQTL analysis	As single-cell RNA-seq datasets grow larger and more complex, they enable richer analyses of how gene expression varies between cells and people. However, methods designed for bulk data fail to account for the unique structure of single-cell gene expression. Researchers are now developing statistical models tailored to single-cell-resolution data for a variety of applications. In this primer, I will focus on single-cell models for the task of mapping expression quantitative trait loci (eQTLs) to find genetic variants associated with a gene's expression. Single-cell eQTL models have the potential to capture disease-relevant, state-dependent regulatory effects with the right statistical models and representations of cell state. This primer will discuss the evolution of statistical models for eQTL mapping from pseudobulk to single-cell resolution, representations of single-cell states for state-dependent analyses, and outstanding computational challenges.	analysis state researchers disease computational genetic eqtl rna single cell mia meeting		2020-04-10											Aparna Nathan	193	0
Scalable single-cell models for robust cell-state-dependent eQTL mapping	Modelling cell state-dependent genetic associations with single-cell gene expression exhibits statistical and computational challenges. First, parametrization of single-cell gene expression profiles is not a straightforward task because individual genes exhibit distinct distributions. Second, current single-cell datasets consist of hundreds of thousands to millions of cells, which constrains the ability to test associations in a scalable manner. In this talk, I will introduce a new generalizable approach to robustly identify cell state-dependent eQTLs in single-cell data. To overcome the challenge of gene expression parametrization, we implemented a non-parametric bootstrap procedure to compute empirically calibrated p-values for variant-gene expression associations. To speed up the computation, we used the Julia programming language and pre-computed covariate-adjusted gene expression profiles with a linear mixed model before testing cell state-dependent eQTL interactions. Finally, I will demonstrate an application of this approach to identify autoimmune disease risk loci with context-specific effects in memory T cells.	genes autoimmune scalable computation mapping computational genetic eqtl robust cell mia meeting		2020-04-10											Jose Alquicira-Hernandez	194	0
Protein language models learn evolutionary statistics of interacting sequence motifs	Protein language models (pLMs) have exhibited remarkable capabilities in protein structure prediction and design. However, the extent to which they comprehend the intrinsic biophysics of protein structures remains uncertain. We present a suite of analyses that dissect how the flagship pLM ESM-2 predicts structure. Motivated by a consistent error of protein isoforms predicted as structured fragments, we developed a completely unsupervised method to uniformly evaluate any pLM, allowing us to compare coevolutionary statistics to linear models. We further identified that ESM-2 does not require full context for predicting inter-residue contacts. Our study highlights the current limitations of pLMs and contributes to a deeper understanding of their underlying mechanisms, paving the way for more reliable protein structure predictions.	statistics protein learn study biophysics analyses prediction evolutionary language mia meeting		2020-05-01											Sergey Ovchinnikov	195	0
Combining protein language and structure models to redesign E. coli proteome with a reduced amino acid alphabet	All known organisms need all 20 canonical amino acids to survive and reproduce, yet use of different amino acids must’ve evolved over time. Unfortunately, even the last universal common ancestor used all 20, so there is no way to observe how life might have looked without all of them. Here, we’re trying to synthesize such an organism by designing a strain of E. coli using only 19 canonical amino acids, starting from redesigning essential genes one at a time with the goal of preserving fitness. Since there are many diverse genes to design, we’re repurposing and extending machine learning-driven protein design methods to accomplish this task. Each of the currently available methods is capturing specific properties of the design landscape due to its approach and training data provided to the models. Protein language models like ESM have access to a vast number of sequences and can learn patterns favored by nature. Methods using AlphaFold as a loss function like AFDesign or MCMC hallucination are aware of the final structure of the protein, but are susceptible to adversarial examples. Finally, models which perform “inverse folding” like ProteinMPNN have both sequence and structure information and can output structure-aware designs. We’re developing optimization methods which combine these models as part of the design process to find sequences which are scored highly by models coming from different approaches, and how this translates to their biological properties. The experimental results show that our methods can generate designs comparable with wild-type versions in fitness with a small number of attempts.	genes amino protein proteinmpnn coli redesign alphabet 20 mia meeting		2020-05-01											Simon Kozlov	196	0
Protein Design with Deep Learning: Progress, Challenges, and Next Steps	The human proteome comprises tens of thousands of proteins, each tailored for a specific function by the selective pressures of evolution. The field of protein design seeks to develop proteins with new or enhanced functions at will, ultimately bypassing the evolutionary clock. In this talk, we discuss general machine-learning methods for accelerating the crucial components of protein design, with a particular focus on the underlying models. We begin with an overview of the protein design field and discuss traditional approaches. We then focus on two important subtasks, fixed-backbone design and protein-protein docking, and critique deep learning approaches with an emphasis on the modeling considerations that attribute to their success. Finally, we highlight some limitations and outstanding challenges in the field and potential next steps.	proteome protein challenges deep design proteins evolution evolutionary learning mia meeting		2020-05-08											Matthew McPartlon	197	0
Unlocking Generative AI for Drug Discovery with Zero-shot Models	Generative AI has the potential to greatly incrase the speed, quality, and controllability of drug design. Traditional discovery requires time and resource intensive screening of large libraries, which also offer little control on the output molecules, which can result in suboptimal candidates. Here, we show how generative deep learning models can produce molecules and representations that could be used for downstream design of new molecules with specified functions.	intensive learning unlocking screening models drug libraries generative discovery mia meeting		2020-05-08											Joshua Meier	198	0
Geometric deep learning and generative models for protein target discovery	Computational therapeutic target discovery requires deciphering the cell types in which proteins act and their interactions. We present PINNACLE, a contextual AI model for single-cell protein biology. Using a multi-organ single-cell atlas, PINNACLE learns from contextualized protein interaction networks, producing 394,760 protein representations from 156 cell types across 24 tissues. PINNACLE’s embedding space reflects cellular and tissue organization, enabling zero-shot retrieval of tissue hierarchy. Pretrained PINNACLE representations can power a range of tasks: enhancing 3D structure-based representations in immuno-oncology, predicting drug effects across cell types and states, and identifying therapeutic targets in a cell-type-specific manner. We used PINNACLE to nominate protein targets for rheumatoid arthritis and inflammatory bowel disease, identifying predictive cell type contexts. Drugs bind to protein pockets, areas where proteins interact with ligand molecules, a challenging task due to biomolecular interactions and sequence-structure dependencies. We developed PocketGen, a sequence-structure generative model that optimizes protein pockets to serve as optimal binders for ligand molecules. PocketGen iteratively refines the sequence and structure of pockets by maximizing binding affinity with the ligand and sequence-structure consistency. Using a graph transformer for all-atom structure modeling and a protein language model for sequence prediction, PocketGen can help optimize protein pockets with high binding affinity, strong structural validity and generation efficiency.	oncology protein learning biology biomolecular proteins geometric generative discovery mia meeting		2020-05-29											Marinka Zitnik	199	0
Multimodal protein language models for deciphering protein function	Understanding the relationship between a protein's amino acid sequence and its structure or function is a long-standing challenge with far-reaching implications for therapeutic development, as the effects of drugs are often directly linked to proteins. Current protein language models (PLMs) capture evolutionary relationships based on sequences but fall short of directly acquiring protein functions from multimodal molecular data, including protein sequences and structures, peptides, and domains. We develop a multimodal protein language model that integrates textual protein descriptions with a sequence-structure PLM to create a more comprehensive and functionally insightful model of proteins. This integration promises to bridge the current gap in PLMs, transitioning from understanding the structural aspects of proteins to gaining a functional view of vast protein space. The model allows scientists to express their queries in natural language and interact with protein models in an open-ended manner. It allows for text-based prediction of protein targets, multimodal protein captioning, and Q&A sessions with scientists with varying levels of expertise, among others. Trained on a new dataset of protein-text instructions, the model can generalize to new phenotypes in a zero-shot manner, making it versatile for diverse tasks even when functional annotations are scarce. We conclude with an outlook for the future with “AI scientists” as generative agents capable of skeptical learning and reasoning to empower biomedical research.	function scientists deciphering protein biomedical multimodal proteins molecular language mia meeting		2020-05-29											Owen Queen, Yepeng Huang, Marinka Zitnik	200	0
Hybrid protein language models for fitness prediction and design	The ability to accurately model the fitness landscape of protein sequences is critical to a wide range of applications, from quantifying the effects of human variants on disease likelihood, to predicting immune-escape mutations in viruses and designing novel biotherapeutic proteins. Deep generative models of protein sequences trained on multiple sequence alignments have been the most successful approaches so far to address these tasks. The performance of these methods is however contingent on the availability of sufficiently deep and diverse alignments for reliable training. Their potential scope is thus limited by the fact many protein families are hard, if not impossible, to align. Large language models trained on massive quantities of non-aligned protein sequences from diverse families seek to address these problems. However, their performance has not yet matched that of their alignment-based counterparts. This talk will introduce hybrid strategies to leverage the strengths from both model classes	biotherapeutic fitness hybrid protein design proteins hard prediction massive mia meeting		2021-02-14											Pascal Notin	201	0
Unsupervised viral antibody escape prediction for future-proof vaccines	Effective pandemic preparedness relies on predicting immune-evasive viral mutations to ensure early detection of variants of concern and to design future-proofed vaccines and therapeutics. However, current experimental strategies for viral evolution prediction are not available early in a pandemic since  they require host polyclonal antibodies.  Furthermore, the existing paradigm for vaccine evaluation relies on retrospective evaluation against past variants, instead of proactive evaluation against future viral evolution. To address these limitations, we developed EVEscape, a model which integrated fitness predictions from evolutionary models, structure-based features that assess antibody binding potential, and biochemical distances between mutated and wild-type residues. EVEscape quantifies the viral escape potential of mutations at scale and has the advantage of being applicable before surveillance sequencing, experimental scans, or 3D structures of antibody complexes are available. Using only information available pre-pandemic, EVEscape is as accurate as high-throughput experimental scans at anticipating pandemic variation for SARS-CoV-2 and is generalizable to other viruses. Using EVEscape we forecast future SARS-CoV-2 evolution and present a novel and proactive approach for evaluating  and designing vaccines.	antibodies viruses future vaccine prediction antibody vaccines viral mia meeting		2021-02-14											Noor Youssef, Sarah Faye Gurev	202	0
Accurate proteome-wide missense variant effect prediction with Alpha Missens	The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present Alpha Missense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89% of missense variants as either likely benign or likely pathogenic.	proteome genes genome alpha missense accurate genetic prediction pathogenicity pathogenic mia meeting		2021-03-13											Žiga Avsec	203	0
Alpha Missens	The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present Alpha Missense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89% of missense variants as either likely benign or likely pathogenic.	genes genome alpha missens genetic pathogenicity pathogenic mia meeting		2021-03-13											Jun Cheng	204	0
Testing data-driven hypotheses post-clustering	This primer talk is motivated by the practice of testing data-driven hypotheses. In the biomedical sciences, it has become increasingly common to collect massive datasets without a pre-specified research question. In this setting, a data analyst might use the data both to generate a research question, and to test the associated null hypothesis. For example, in single-cell RNA-sequencing analyses, researchers often first cluster the cells, and then test for differences in the expected gene expression levels between the clusters to quantify up- or down-regulation of genes, annotate known cell types, and identify new cell types. However, this popular practice is invalid from a statistical perspective: once we have used the data to generate hypotheses, standard statistical inference tools are no longer valid. To tackle this problem, I developed a conditional selective approach to test for a difference in means between pairs of clusters obtained via hierarchical and k-means clustering. The proposed approach has appropriate statistical guarantees (e.g., selective Type 1 error control), and we demonstrate its use on single-cell RNA-sequencing data.	genes data research post biomedical researchers clustering rna testing hypotheses mia meeting		2021-03-20											Yiqun Chen	205	0
Data thinning to avoid double dipping	"""Double dipping"" is the practice of using the same data to fit and validate a model. Problems typically arise when standard statistical procedures are applied in settings involving double dipping. To avoid the challenges surrounding double dipping, a natural approach is to fit a model on one dataset, and then validate the model on another independent dataset. When we only have access to one dataset, we typically accomplish this via sample splitting. Unfortunately, in some problems, sample splitting is unattractive or impossible. In this talk, we are motivated by unsupervised problems that arise in the analysis of single cell RNA sequencing data, where sample splitting does not allow us to avoid double dipping. We first propose Poisson thinning, which splits a single observation drawn from a Poisson distribution into two independent pseudo-observations. We show that Poisson count splitting allows us to avoid double dipping in unsupervised settings. We next generalize the Poisson thinning framework to a variety of distributions, and refer to this general framework as ""data thinning"". Data thinning is applicable far beyond the context of single-cell RNA sequencing data, and is particularly useful for problems where sample splitting is unattractive or impossible."	statistical data avoid sequencing sample double thinning dipping mia meeting		2021-03-20											Lucy Gao	206	0
SPLASH unifies genomic analysis and discovery through a paradigm shift to statistics-first	Myriad mechanisms diversify the sequence content of DNA and of RNA transcripts. Currently, these events are detected using tools that first require alignment to a necessarily incomplete reference genome alignment in the first step; this incompleteness is especially prominent in human genetic diseases such as cancer, in the microbial world, and in non—model organisms where it severely limits the speed and scope of discovery. Second, today the next step in analysis requires as a custom choice of bioinformatic procedure to follow it: for example, to detect splicing, RNA editing, or V(D)J recombination among many others.  I will present the theory for why SPLASH, a new statistics-first analytic approach captures myriad forms of genome regulation, without a reference or sample metadata, by performing statistical inference directly on raw sequencing reads. By design, SPLASH as an algorithm is highly efficient. Thanks to joint work with Professor Sebastian Deorowicz’s group, SPLASH is now implemented so that it is efficient and simple to run. A snapshot of its findings include new insights into RNA splicing, cancer transcriptomes, single cell RNA-editing, mobile genetic elements and discovers new genes non-model organisms.	genome cancer statistics bioinformatic splash genomic genetic paradigm discovery dna mia meeting		2021-04-03											Julia Salzman	207	0
Statistical and algorithmic challenges in reference-free analysis	Today’s genomics workflows typically begin by aligning sequencing data to a reference. In addition to being slow, this has many statistical drawbacks. Even in the intensely studied human genome, it was found that understudied populations have large amounts of sequence missing from the current reference; such blind spots may exacerbate health disparities. Reference-based methods are additionally limited in their detection of novel biology: reads from unannotated isoforms may be mismapped or discarded completely. In recent work we introduce a unifying paradigm, SPLASH, which directly analyzes raw sequencing data, using a statistical test to detect a signature of regulation: sample-specific sequence variation. SPLASH detects many types of variation and can be efficiently run at scale, providing a unifying statistical approach to genomic analysis that enables expansive discovery without metadata or references. In this primer I’ll discuss some of the challenges of reference-free analysis, and provide the algorithmic and statistical background for our proposed solution, SPLASH.	statistical drawbacks genomics reference exacerbate algorithmic challenges biology genomic analysis mia meeting		2021-04-03											Tavor Baharav	208	0
Single-cell models for state-dependent eQTL analysis	As single-cell RNA-seq datasets grow larger and more complex, they enable richer analyses of how gene expression varies between cells and people. However, methods designed for bulk data fail to account for the unique structure of single-cell gene expression. Researchers are now developing statistical models tailored to single-cell-resolution data for a variety of applications. In this primer, I will focus on single-cell models for the task of mapping expression quantitative trait loci (eQTLs) to find genetic variants associated with a gene's expression. Single-cell eQTL models have the potential to capture disease-relevant, state-dependent regulatory effects with the right statistical models and representations of cell state. This primer will discuss the evolution of statistical models for eQTL mapping from pseudobulk to single-cell resolution, representations of single-cell states for state-dependent analyses, and outstanding computational challenges.	analysis state researchers disease computational genetic eqtl rna single cell mia meeting		2021-04-10											Aparna Nathan	209	0
Scalable single-cell models for robust cell-state-dependent eQTL mapping	Modelling cell state-dependent genetic associations with single-cell gene expression exhibits statistical and computational challenges. First, parametrization of single-cell gene expression profiles is not a straightforward task because individual genes exhibit distinct distributions. Second, current single-cell datasets consist of hundreds of thousands to millions of cells, which constrains the ability to test associations in a scalable manner. In this talk, I will introduce a new generalizable approach to robustly identify cell state-dependent eQTLs in single-cell data. To overcome the challenge of gene expression parametrization, we implemented a non-parametric bootstrap procedure to compute empirically calibrated p-values for variant-gene expression associations. To speed up the computation, we used the Julia programming language and pre-computed covariate-adjusted gene expression profiles with a linear mixed model before testing cell state-dependent eQTL interactions. Finally, I will demonstrate an application of this approach to identify autoimmune disease risk loci with context-specific effects in memory T cells.	genes autoimmune scalable computation mapping computational genetic eqtl robust cell mia meeting		2021-04-10											Jose Alquicira-Hernandez	210	0
Protein language models learn evolutionary statistics of interacting sequence motifs	Protein language models (pLMs) have exhibited remarkable capabilities in protein structure prediction and design. However, the extent to which they comprehend the intrinsic biophysics of protein structures remains uncertain. We present a suite of analyses that dissect how the flagship pLM ESM-2 predicts structure. Motivated by a consistent error of protein isoforms predicted as structured fragments, we developed a completely unsupervised method to uniformly evaluate any pLM, allowing us to compare coevolutionary statistics to linear models. We further identified that ESM-2 does not require full context for predicting inter-residue contacts. Our study highlights the current limitations of pLMs and contributes to a deeper understanding of their underlying mechanisms, paving the way for more reliable protein structure predictions.	statistics protein learn study biophysics analyses prediction evolutionary language mia meeting		2021-05-01											Sergey Ovchinnikov	211	0
Combining protein language and structure models to redesign E. coli proteome with a reduced amino acid alphabet	All known organisms need all 20 canonical amino acids to survive and reproduce, yet use of different amino acids must’ve evolved over time. Unfortunately, even the last universal common ancestor used all 20, so there is no way to observe how life might have looked without all of them. Here, we’re trying to synthesize such an organism by designing a strain of E. coli using only 19 canonical amino acids, starting from redesigning essential genes one at a time with the goal of preserving fitness. Since there are many diverse genes to design, we’re repurposing and extending machine learning-driven protein design methods to accomplish this task. Each of the currently available methods is capturing specific properties of the design landscape due to its approach and training data provided to the models. Protein language models like ESM have access to a vast number of sequences and can learn patterns favored by nature. Methods using AlphaFold as a loss function like AFDesign or MCMC hallucination are aware of the final structure of the protein, but are susceptible to adversarial examples. Finally, models which perform “inverse folding” like ProteinMPNN have both sequence and structure information and can output structure-aware designs. We’re developing optimization methods which combine these models as part of the design process to find sequences which are scored highly by models coming from different approaches, and how this translates to their biological properties. The experimental results show that our methods can generate designs comparable with wild-type versions in fitness with a small number of attempts.	genes amino protein proteinmpnn coli redesign alphabet 20 mia meeting		2021-05-01											Simon Kozlov	212	0
Protein Design with Deep Learning: Progress, Challenges, and Next Steps	The human proteome comprises tens of thousands of proteins, each tailored for a specific function by the selective pressures of evolution. The field of protein design seeks to develop proteins with new or enhanced functions at will, ultimately bypassing the evolutionary clock. In this talk, we discuss general machine-learning methods for accelerating the crucial components of protein design, with a particular focus on the underlying models. We begin with an overview of the protein design field and discuss traditional approaches. We then focus on two important subtasks, fixed-backbone design and protein-protein docking, and critique deep learning approaches with an emphasis on the modeling considerations that attribute to their success. Finally, we highlight some limitations and outstanding challenges in the field and potential next steps.	proteome protein challenges deep design proteins evolution evolutionary learning mia meeting		2021-05-08											Matthew McPartlon	213	0
Unlocking Generative AI for Drug Discovery with Zero-shot Models	Generative AI has the potential to greatly incrase the speed, quality, and controllability of drug design. Traditional discovery requires time and resource intensive screening of large libraries, which also offer little control on the output molecules, which can result in suboptimal candidates. Here, we show how generative deep learning models can produce molecules and representations that could be used for downstream design of new molecules with specified functions.	intensive learning unlocking screening models drug libraries generative discovery mia meeting		2021-05-08											Joshua Meier	214	0
Geometric deep learning and generative models for protein target discovery	Computational therapeutic target discovery requires deciphering the cell types in which proteins act and their interactions. We present PINNACLE, a contextual AI model for single-cell protein biology. Using a multi-organ single-cell atlas, PINNACLE learns from contextualized protein interaction networks, producing 394,760 protein representations from 156 cell types across 24 tissues. PINNACLE’s embedding space reflects cellular and tissue organization, enabling zero-shot retrieval of tissue hierarchy. Pretrained PINNACLE representations can power a range of tasks: enhancing 3D structure-based representations in immuno-oncology, predicting drug effects across cell types and states, and identifying therapeutic targets in a cell-type-specific manner. We used PINNACLE to nominate protein targets for rheumatoid arthritis and inflammatory bowel disease, identifying predictive cell type contexts. Drugs bind to protein pockets, areas where proteins interact with ligand molecules, a challenging task due to biomolecular interactions and sequence-structure dependencies. We developed PocketGen, a sequence-structure generative model that optimizes protein pockets to serve as optimal binders for ligand molecules. PocketGen iteratively refines the sequence and structure of pockets by maximizing binding affinity with the ligand and sequence-structure consistency. Using a graph transformer for all-atom structure modeling and a protein language model for sequence prediction, PocketGen can help optimize protein pockets with high binding affinity, strong structural validity and generation efficiency.	oncology protein learning biology biomolecular proteins geometric generative discovery mia meeting		2021-05-29											Marinka Zitnik	215	0
Multimodal protein language models for deciphering protein function	Understanding the relationship between a protein's amino acid sequence and its structure or function is a long-standing challenge with far-reaching implications for therapeutic development, as the effects of drugs are often directly linked to proteins. Current protein language models (PLMs) capture evolutionary relationships based on sequences but fall short of directly acquiring protein functions from multimodal molecular data, including protein sequences and structures, peptides, and domains. We develop a multimodal protein language model that integrates textual protein descriptions with a sequence-structure PLM to create a more comprehensive and functionally insightful model of proteins. This integration promises to bridge the current gap in PLMs, transitioning from understanding the structural aspects of proteins to gaining a functional view of vast protein space. The model allows scientists to express their queries in natural language and interact with protein models in an open-ended manner. It allows for text-based prediction of protein targets, multimodal protein captioning, and Q&A sessions with scientists with varying levels of expertise, among others. Trained on a new dataset of protein-text instructions, the model can generalize to new phenotypes in a zero-shot manner, making it versatile for diverse tasks even when functional annotations are scarce. We conclude with an outlook for the future with “AI scientists” as generative agents capable of skeptical learning and reasoning to empower biomedical research.	function scientists deciphering protein biomedical multimodal proteins molecular language mia meeting		2021-05-29											Owen Queen, Yepeng Huang, Marinka Zitnik	216	0
Hybrid protein language models for fitness prediction and design	The ability to accurately model the fitness landscape of protein sequences is critical to a wide range of applications, from quantifying the effects of human variants on disease likelihood, to predicting immune-escape mutations in viruses and designing novel biotherapeutic proteins. Deep generative models of protein sequences trained on multiple sequence alignments have been the most successful approaches so far to address these tasks. The performance of these methods is however contingent on the availability of sufficiently deep and diverse alignments for reliable training. Their potential scope is thus limited by the fact many protein families are hard, if not impossible, to align. Large language models trained on massive quantities of non-aligned protein sequences from diverse families seek to address these problems. However, their performance has not yet matched that of their alignment-based counterparts. This talk will introduce hybrid strategies to leverage the strengths from both model classes	biotherapeutic fitness hybrid protein design proteins hard prediction massive mia meeting		2022-02-14											Pascal Notin	217	0
Unsupervised viral antibody escape prediction for future-proof vaccines	Effective pandemic preparedness relies on predicting immune-evasive viral mutations to ensure early detection of variants of concern and to design future-proofed vaccines and therapeutics. However, current experimental strategies for viral evolution prediction are not available early in a pandemic since  they require host polyclonal antibodies.  Furthermore, the existing paradigm for vaccine evaluation relies on retrospective evaluation against past variants, instead of proactive evaluation against future viral evolution. To address these limitations, we developed EVEscape, a model which integrated fitness predictions from evolutionary models, structure-based features that assess antibody binding potential, and biochemical distances between mutated and wild-type residues. EVEscape quantifies the viral escape potential of mutations at scale and has the advantage of being applicable before surveillance sequencing, experimental scans, or 3D structures of antibody complexes are available. Using only information available pre-pandemic, EVEscape is as accurate as high-throughput experimental scans at anticipating pandemic variation for SARS-CoV-2 and is generalizable to other viruses. Using EVEscape we forecast future SARS-CoV-2 evolution and present a novel and proactive approach for evaluating  and designing vaccines.	antibodies viruses future vaccine prediction antibody vaccines viral mia meeting		2022-02-14											Noor Youssef, Sarah Faye Gurev	218	0
Accurate proteome-wide missense variant effect prediction with Alpha Missens	The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present Alpha Missense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89% of missense variants as either likely benign or likely pathogenic.	proteome genes genome alpha missense accurate genetic prediction pathogenicity pathogenic mia meeting		2022-03-13											Žiga Avsec	219	0
Alpha Missens	The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present Alpha Missense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89% of missense variants as either likely benign or likely pathogenic.	genes genome alpha missens genetic pathogenicity pathogenic mia meeting		2022-03-13											Jun Cheng	220	0
Testing data-driven hypotheses post-clustering	This primer talk is motivated by the practice of testing data-driven hypotheses. In the biomedical sciences, it has become increasingly common to collect massive datasets without a pre-specified research question. In this setting, a data analyst might use the data both to generate a research question, and to test the associated null hypothesis. For example, in single-cell RNA-sequencing analyses, researchers often first cluster the cells, and then test for differences in the expected gene expression levels between the clusters to quantify up- or down-regulation of genes, annotate known cell types, and identify new cell types. However, this popular practice is invalid from a statistical perspective: once we have used the data to generate hypotheses, standard statistical inference tools are no longer valid. To tackle this problem, I developed a conditional selective approach to test for a difference in means between pairs of clusters obtained via hierarchical and k-means clustering. The proposed approach has appropriate statistical guarantees (e.g., selective Type 1 error control), and we demonstrate its use on single-cell RNA-sequencing data.	genes data research post biomedical researchers clustering rna testing hypotheses mia meeting		2022-03-20											Yiqun Chen	221	0
Data thinning to avoid double dipping	"""Double dipping"" is the practice of using the same data to fit and validate a model. Problems typically arise when standard statistical procedures are applied in settings involving double dipping. To avoid the challenges surrounding double dipping, a natural approach is to fit a model on one dataset, and then validate the model on another independent dataset. When we only have access to one dataset, we typically accomplish this via sample splitting. Unfortunately, in some problems, sample splitting is unattractive or impossible. In this talk, we are motivated by unsupervised problems that arise in the analysis of single cell RNA sequencing data, where sample splitting does not allow us to avoid double dipping. We first propose Poisson thinning, which splits a single observation drawn from a Poisson distribution into two independent pseudo-observations. We show that Poisson count splitting allows us to avoid double dipping in unsupervised settings. We next generalize the Poisson thinning framework to a variety of distributions, and refer to this general framework as ""data thinning"". Data thinning is applicable far beyond the context of single-cell RNA sequencing data, and is particularly useful for problems where sample splitting is unattractive or impossible."	statistical data avoid sequencing sample double thinning dipping mia meeting		2022-03-20											Lucy Gao	222	0
SPLASH unifies genomic analysis and discovery through a paradigm shift to statistics-first	Myriad mechanisms diversify the sequence content of DNA and of RNA transcripts. Currently, these events are detected using tools that first require alignment to a necessarily incomplete reference genome alignment in the first step; this incompleteness is especially prominent in human genetic diseases such as cancer, in the microbial world, and in non—model organisms where it severely limits the speed and scope of discovery. Second, today the next step in analysis requires as a custom choice of bioinformatic procedure to follow it: for example, to detect splicing, RNA editing, or V(D)J recombination among many others.  I will present the theory for why SPLASH, a new statistics-first analytic approach captures myriad forms of genome regulation, without a reference or sample metadata, by performing statistical inference directly on raw sequencing reads. By design, SPLASH as an algorithm is highly efficient. Thanks to joint work with Professor Sebastian Deorowicz’s group, SPLASH is now implemented so that it is efficient and simple to run. A snapshot of its findings include new insights into RNA splicing, cancer transcriptomes, single cell RNA-editing, mobile genetic elements and discovers new genes non-model organisms.	genome cancer statistics bioinformatic splash genomic genetic paradigm discovery dna mia meeting		2022-04-03											Julia Salzman	223	0
Statistical and algorithmic challenges in reference-free analysis	Today’s genomics workflows typically begin by aligning sequencing data to a reference. In addition to being slow, this has many statistical drawbacks. Even in the intensely studied human genome, it was found that understudied populations have large amounts of sequence missing from the current reference; such blind spots may exacerbate health disparities. Reference-based methods are additionally limited in their detection of novel biology: reads from unannotated isoforms may be mismapped or discarded completely. In recent work we introduce a unifying paradigm, SPLASH, which directly analyzes raw sequencing data, using a statistical test to detect a signature of regulation: sample-specific sequence variation. SPLASH detects many types of variation and can be efficiently run at scale, providing a unifying statistical approach to genomic analysis that enables expansive discovery without metadata or references. In this primer I’ll discuss some of the challenges of reference-free analysis, and provide the algorithmic and statistical background for our proposed solution, SPLASH.	statistical drawbacks genomics reference exacerbate algorithmic challenges biology genomic analysis mia meeting		2022-04-03											Tavor Baharav	224	0
Single-cell models for state-dependent eQTL analysis	As single-cell RNA-seq datasets grow larger and more complex, they enable richer analyses of how gene expression varies between cells and people. However, methods designed for bulk data fail to account for the unique structure of single-cell gene expression. Researchers are now developing statistical models tailored to single-cell-resolution data for a variety of applications. In this primer, I will focus on single-cell models for the task of mapping expression quantitative trait loci (eQTLs) to find genetic variants associated with a gene's expression. Single-cell eQTL models have the potential to capture disease-relevant, state-dependent regulatory effects with the right statistical models and representations of cell state. This primer will discuss the evolution of statistical models for eQTL mapping from pseudobulk to single-cell resolution, representations of single-cell states for state-dependent analyses, and outstanding computational challenges.	analysis state researchers disease computational genetic eqtl rna single cell mia meeting		2022-04-10											Aparna Nathan	225	0
Scalable single-cell models for robust cell-state-dependent eQTL mapping	Modelling cell state-dependent genetic associations with single-cell gene expression exhibits statistical and computational challenges. First, parametrization of single-cell gene expression profiles is not a straightforward task because individual genes exhibit distinct distributions. Second, current single-cell datasets consist of hundreds of thousands to millions of cells, which constrains the ability to test associations in a scalable manner. In this talk, I will introduce a new generalizable approach to robustly identify cell state-dependent eQTLs in single-cell data. To overcome the challenge of gene expression parametrization, we implemented a non-parametric bootstrap procedure to compute empirically calibrated p-values for variant-gene expression associations. To speed up the computation, we used the Julia programming language and pre-computed covariate-adjusted gene expression profiles with a linear mixed model before testing cell state-dependent eQTL interactions. Finally, I will demonstrate an application of this approach to identify autoimmune disease risk loci with context-specific effects in memory T cells.	genes autoimmune scalable computation mapping computational genetic eqtl robust cell mia meeting		2022-04-10											Jose Alquicira-Hernandez	226	0
Protein language models learn evolutionary statistics of interacting sequence motifs	Protein language models (pLMs) have exhibited remarkable capabilities in protein structure prediction and design. However, the extent to which they comprehend the intrinsic biophysics of protein structures remains uncertain. We present a suite of analyses that dissect how the flagship pLM ESM-2 predicts structure. Motivated by a consistent error of protein isoforms predicted as structured fragments, we developed a completely unsupervised method to uniformly evaluate any pLM, allowing us to compare coevolutionary statistics to linear models. We further identified that ESM-2 does not require full context for predicting inter-residue contacts. Our study highlights the current limitations of pLMs and contributes to a deeper understanding of their underlying mechanisms, paving the way for more reliable protein structure predictions.	statistics protein learn study biophysics analyses prediction evolutionary language mia meeting		2022-05-01											Sergey Ovchinnikov	227	0
Combining protein language and structure models to redesign E. coli proteome with a reduced amino acid alphabet	All known organisms need all 20 canonical amino acids to survive and reproduce, yet use of different amino acids must’ve evolved over time. Unfortunately, even the last universal common ancestor used all 20, so there is no way to observe how life might have looked without all of them. Here, we’re trying to synthesize such an organism by designing a strain of E. coli using only 19 canonical amino acids, starting from redesigning essential genes one at a time with the goal of preserving fitness. Since there are many diverse genes to design, we’re repurposing and extending machine learning-driven protein design methods to accomplish this task. Each of the currently available methods is capturing specific properties of the design landscape due to its approach and training data provided to the models. Protein language models like ESM have access to a vast number of sequences and can learn patterns favored by nature. Methods using AlphaFold as a loss function like AFDesign or MCMC hallucination are aware of the final structure of the protein, but are susceptible to adversarial examples. Finally, models which perform “inverse folding” like ProteinMPNN have both sequence and structure information and can output structure-aware designs. We’re developing optimization methods which combine these models as part of the design process to find sequences which are scored highly by models coming from different approaches, and how this translates to their biological properties. The experimental results show that our methods can generate designs comparable with wild-type versions in fitness with a small number of attempts.	genes amino protein proteinmpnn coli redesign alphabet 20 mia meeting		2022-05-01											Simon Kozlov	228	0
Protein Design with Deep Learning: Progress, Challenges, and Next Steps	The human proteome comprises tens of thousands of proteins, each tailored for a specific function by the selective pressures of evolution. The field of protein design seeks to develop proteins with new or enhanced functions at will, ultimately bypassing the evolutionary clock. In this talk, we discuss general machine-learning methods for accelerating the crucial components of protein design, with a particular focus on the underlying models. We begin with an overview of the protein design field and discuss traditional approaches. We then focus on two important subtasks, fixed-backbone design and protein-protein docking, and critique deep learning approaches with an emphasis on the modeling considerations that attribute to their success. Finally, we highlight some limitations and outstanding challenges in the field and potential next steps.	proteome protein challenges deep design proteins evolution evolutionary learning mia meeting		2022-05-08											Matthew McPartlon	229	0
Unlocking Generative AI for Drug Discovery with Zero-shot Models	Generative AI has the potential to greatly incrase the speed, quality, and controllability of drug design. Traditional discovery requires time and resource intensive screening of large libraries, which also offer little control on the output molecules, which can result in suboptimal candidates. Here, we show how generative deep learning models can produce molecules and representations that could be used for downstream design of new molecules with specified functions.	intensive learning unlocking screening models drug libraries generative discovery mia meeting		2022-05-08											Joshua Meier	230	0
Geometric deep learning and generative models for protein target discovery	Computational therapeutic target discovery requires deciphering the cell types in which proteins act and their interactions. We present PINNACLE, a contextual AI model for single-cell protein biology. Using a multi-organ single-cell atlas, PINNACLE learns from contextualized protein interaction networks, producing 394,760 protein representations from 156 cell types across 24 tissues. PINNACLE’s embedding space reflects cellular and tissue organization, enabling zero-shot retrieval of tissue hierarchy. Pretrained PINNACLE representations can power a range of tasks: enhancing 3D structure-based representations in immuno-oncology, predicting drug effects across cell types and states, and identifying therapeutic targets in a cell-type-specific manner. We used PINNACLE to nominate protein targets for rheumatoid arthritis and inflammatory bowel disease, identifying predictive cell type contexts. Drugs bind to protein pockets, areas where proteins interact with ligand molecules, a challenging task due to biomolecular interactions and sequence-structure dependencies. We developed PocketGen, a sequence-structure generative model that optimizes protein pockets to serve as optimal binders for ligand molecules. PocketGen iteratively refines the sequence and structure of pockets by maximizing binding affinity with the ligand and sequence-structure consistency. Using a graph transformer for all-atom structure modeling and a protein language model for sequence prediction, PocketGen can help optimize protein pockets with high binding affinity, strong structural validity and generation efficiency.	oncology protein learning biology biomolecular proteins geometric generative discovery mia meeting		2022-05-29											Marinka Zitnik	231	0
Multimodal protein language models for deciphering protein function	Understanding the relationship between a protein's amino acid sequence and its structure or function is a long-standing challenge with far-reaching implications for therapeutic development, as the effects of drugs are often directly linked to proteins. Current protein language models (PLMs) capture evolutionary relationships based on sequences but fall short of directly acquiring protein functions from multimodal molecular data, including protein sequences and structures, peptides, and domains. We develop a multimodal protein language model that integrates textual protein descriptions with a sequence-structure PLM to create a more comprehensive and functionally insightful model of proteins. This integration promises to bridge the current gap in PLMs, transitioning from understanding the structural aspects of proteins to gaining a functional view of vast protein space. The model allows scientists to express their queries in natural language and interact with protein models in an open-ended manner. It allows for text-based prediction of protein targets, multimodal protein captioning, and Q&A sessions with scientists with varying levels of expertise, among others. Trained on a new dataset of protein-text instructions, the model can generalize to new phenotypes in a zero-shot manner, making it versatile for diverse tasks even when functional annotations are scarce. We conclude with an outlook for the future with “AI scientists” as generative agents capable of skeptical learning and reasoning to empower biomedical research.	function scientists deciphering protein biomedical multimodal proteins molecular language mia meeting		2022-05-29											Owen Queen, Yepeng Huang, Marinka Zitnik	232	0
Hybrid protein language models for fitness prediction and design	The ability to accurately model the fitness landscape of protein sequences is critical to a wide range of applications, from quantifying the effects of human variants on disease likelihood, to predicting immune-escape mutations in viruses and designing novel biotherapeutic proteins. Deep generative models of protein sequences trained on multiple sequence alignments have been the most successful approaches so far to address these tasks. The performance of these methods is however contingent on the availability of sufficiently deep and diverse alignments for reliable training. Their potential scope is thus limited by the fact many protein families are hard, if not impossible, to align. Large language models trained on massive quantities of non-aligned protein sequences from diverse families seek to address these problems. However, their performance has not yet matched that of their alignment-based counterparts. This talk will introduce hybrid strategies to leverage the strengths from both model classes	biotherapeutic fitness hybrid protein design proteins hard prediction massive mia meeting		2023-02-14											Pascal Notin	233	0
Unsupervised viral antibody escape prediction for future-proof vaccines	Effective pandemic preparedness relies on predicting immune-evasive viral mutations to ensure early detection of variants of concern and to design future-proofed vaccines and therapeutics. However, current experimental strategies for viral evolution prediction are not available early in a pandemic since  they require host polyclonal antibodies.  Furthermore, the existing paradigm for vaccine evaluation relies on retrospective evaluation against past variants, instead of proactive evaluation against future viral evolution. To address these limitations, we developed EVEscape, a model which integrated fitness predictions from evolutionary models, structure-based features that assess antibody binding potential, and biochemical distances between mutated and wild-type residues. EVEscape quantifies the viral escape potential of mutations at scale and has the advantage of being applicable before surveillance sequencing, experimental scans, or 3D structures of antibody complexes are available. Using only information available pre-pandemic, EVEscape is as accurate as high-throughput experimental scans at anticipating pandemic variation for SARS-CoV-2 and is generalizable to other viruses. Using EVEscape we forecast future SARS-CoV-2 evolution and present a novel and proactive approach for evaluating  and designing vaccines.	antibodies viruses future vaccine prediction antibody vaccines viral mia meeting		2023-02-14											Noor Youssef, Sarah Faye Gurev	234	0
Accurate proteome-wide missense variant effect prediction with Alpha Missens	The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present Alpha Missense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89% of missense variants as either likely benign or likely pathogenic.	proteome genes genome alpha missense accurate genetic prediction pathogenicity pathogenic mia meeting		2023-03-13											Žiga Avsec	235	0
Alpha Missens	The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present Alpha Missense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89% of missense variants as either likely benign or likely pathogenic.	genes genome alpha missens genetic pathogenicity pathogenic mia meeting		2023-03-13											Jun Cheng	236	0
Testing data-driven hypotheses post-clustering	This primer talk is motivated by the practice of testing data-driven hypotheses. In the biomedical sciences, it has become increasingly common to collect massive datasets without a pre-specified research question. In this setting, a data analyst might use the data both to generate a research question, and to test the associated null hypothesis. For example, in single-cell RNA-sequencing analyses, researchers often first cluster the cells, and then test for differences in the expected gene expression levels between the clusters to quantify up- or down-regulation of genes, annotate known cell types, and identify new cell types. However, this popular practice is invalid from a statistical perspective: once we have used the data to generate hypotheses, standard statistical inference tools are no longer valid. To tackle this problem, I developed a conditional selective approach to test for a difference in means between pairs of clusters obtained via hierarchical and k-means clustering. The proposed approach has appropriate statistical guarantees (e.g., selective Type 1 error control), and we demonstrate its use on single-cell RNA-sequencing data.	genes data research post biomedical researchers clustering rna testing hypotheses mia meeting		2023-03-20											Yiqun Chen	237	0
Data thinning to avoid double dipping	"""Double dipping"" is the practice of using the same data to fit and validate a model. Problems typically arise when standard statistical procedures are applied in settings involving double dipping. To avoid the challenges surrounding double dipping, a natural approach is to fit a model on one dataset, and then validate the model on another independent dataset. When we only have access to one dataset, we typically accomplish this via sample splitting. Unfortunately, in some problems, sample splitting is unattractive or impossible. In this talk, we are motivated by unsupervised problems that arise in the analysis of single cell RNA sequencing data, where sample splitting does not allow us to avoid double dipping. We first propose Poisson thinning, which splits a single observation drawn from a Poisson distribution into two independent pseudo-observations. We show that Poisson count splitting allows us to avoid double dipping in unsupervised settings. We next generalize the Poisson thinning framework to a variety of distributions, and refer to this general framework as ""data thinning"". Data thinning is applicable far beyond the context of single-cell RNA sequencing data, and is particularly useful for problems where sample splitting is unattractive or impossible."	statistical data avoid sequencing sample double thinning dipping mia meeting		2023-03-20											Lucy Gao	238	0
SPLASH unifies genomic analysis and discovery through a paradigm shift to statistics-first	Myriad mechanisms diversify the sequence content of DNA and of RNA transcripts. Currently, these events are detected using tools that first require alignment to a necessarily incomplete reference genome alignment in the first step; this incompleteness is especially prominent in human genetic diseases such as cancer, in the microbial world, and in non—model organisms where it severely limits the speed and scope of discovery. Second, today the next step in analysis requires as a custom choice of bioinformatic procedure to follow it: for example, to detect splicing, RNA editing, or V(D)J recombination among many others.  I will present the theory for why SPLASH, a new statistics-first analytic approach captures myriad forms of genome regulation, without a reference or sample metadata, by performing statistical inference directly on raw sequencing reads. By design, SPLASH as an algorithm is highly efficient. Thanks to joint work with Professor Sebastian Deorowicz’s group, SPLASH is now implemented so that it is efficient and simple to run. A snapshot of its findings include new insights into RNA splicing, cancer transcriptomes, single cell RNA-editing, mobile genetic elements and discovers new genes non-model organisms.	genome cancer statistics bioinformatic splash genomic genetic paradigm discovery dna mia meeting		2023-04-03											Julia Salzman	239	0
Statistical and algorithmic challenges in reference-free analysis	Today’s genomics workflows typically begin by aligning sequencing data to a reference. In addition to being slow, this has many statistical drawbacks. Even in the intensely studied human genome, it was found that understudied populations have large amounts of sequence missing from the current reference; such blind spots may exacerbate health disparities. Reference-based methods are additionally limited in their detection of novel biology: reads from unannotated isoforms may be mismapped or discarded completely. In recent work we introduce a unifying paradigm, SPLASH, which directly analyzes raw sequencing data, using a statistical test to detect a signature of regulation: sample-specific sequence variation. SPLASH detects many types of variation and can be efficiently run at scale, providing a unifying statistical approach to genomic analysis that enables expansive discovery without metadata or references. In this primer I’ll discuss some of the challenges of reference-free analysis, and provide the algorithmic and statistical background for our proposed solution, SPLASH.	statistical drawbacks genomics reference exacerbate algorithmic challenges biology genomic analysis mia meeting		2023-04-03											Tavor Baharav	240	0
Single-cell models for state-dependent eQTL analysis	As single-cell RNA-seq datasets grow larger and more complex, they enable richer analyses of how gene expression varies between cells and people. However, methods designed for bulk data fail to account for the unique structure of single-cell gene expression. Researchers are now developing statistical models tailored to single-cell-resolution data for a variety of applications. In this primer, I will focus on single-cell models for the task of mapping expression quantitative trait loci (eQTLs) to find genetic variants associated with a gene's expression. Single-cell eQTL models have the potential to capture disease-relevant, state-dependent regulatory effects with the right statistical models and representations of cell state. This primer will discuss the evolution of statistical models for eQTL mapping from pseudobulk to single-cell resolution, representations of single-cell states for state-dependent analyses, and outstanding computational challenges.	analysis state researchers disease computational genetic eqtl rna single cell mia meeting		2023-04-10											Aparna Nathan	241	0
Scalable single-cell models for robust cell-state-dependent eQTL mapping	Modelling cell state-dependent genetic associations with single-cell gene expression exhibits statistical and computational challenges. First, parametrization of single-cell gene expression profiles is not a straightforward task because individual genes exhibit distinct distributions. Second, current single-cell datasets consist of hundreds of thousands to millions of cells, which constrains the ability to test associations in a scalable manner. In this talk, I will introduce a new generalizable approach to robustly identify cell state-dependent eQTLs in single-cell data. To overcome the challenge of gene expression parametrization, we implemented a non-parametric bootstrap procedure to compute empirically calibrated p-values for variant-gene expression associations. To speed up the computation, we used the Julia programming language and pre-computed covariate-adjusted gene expression profiles with a linear mixed model before testing cell state-dependent eQTL interactions. Finally, I will demonstrate an application of this approach to identify autoimmune disease risk loci with context-specific effects in memory T cells.	genes autoimmune scalable computation mapping computational genetic eqtl robust cell mia meeting		2023-04-10											Jose Alquicira-Hernandez	242	0
Protein language models learn evolutionary statistics of interacting sequence motifs	Protein language models (pLMs) have exhibited remarkable capabilities in protein structure prediction and design. However, the extent to which they comprehend the intrinsic biophysics of protein structures remains uncertain. We present a suite of analyses that dissect how the flagship pLM ESM-2 predicts structure. Motivated by a consistent error of protein isoforms predicted as structured fragments, we developed a completely unsupervised method to uniformly evaluate any pLM, allowing us to compare coevolutionary statistics to linear models. We further identified that ESM-2 does not require full context for predicting inter-residue contacts. Our study highlights the current limitations of pLMs and contributes to a deeper understanding of their underlying mechanisms, paving the way for more reliable protein structure predictions.	statistics protein learn study biophysics analyses prediction evolutionary language mia meeting		2023-05-01											Sergey Ovchinnikov	243	0
Combining protein language and structure models to redesign E. coli proteome with a reduced amino acid alphabet	All known organisms need all 20 canonical amino acids to survive and reproduce, yet use of different amino acids must’ve evolved over time. Unfortunately, even the last universal common ancestor used all 20, so there is no way to observe how life might have looked without all of them. Here, we’re trying to synthesize such an organism by designing a strain of E. coli using only 19 canonical amino acids, starting from redesigning essential genes one at a time with the goal of preserving fitness. Since there are many diverse genes to design, we’re repurposing and extending machine learning-driven protein design methods to accomplish this task. Each of the currently available methods is capturing specific properties of the design landscape due to its approach and training data provided to the models. Protein language models like ESM have access to a vast number of sequences and can learn patterns favored by nature. Methods using AlphaFold as a loss function like AFDesign or MCMC hallucination are aware of the final structure of the protein, but are susceptible to adversarial examples. Finally, models which perform “inverse folding” like ProteinMPNN have both sequence and structure information and can output structure-aware designs. We’re developing optimization methods which combine these models as part of the design process to find sequences which are scored highly by models coming from different approaches, and how this translates to their biological properties. The experimental results show that our methods can generate designs comparable with wild-type versions in fitness with a small number of attempts.	genes amino protein proteinmpnn coli redesign alphabet 20 mia meeting		2023-05-01											Simon Kozlov	244	0
Protein Design with Deep Learning: Progress, Challenges, and Next Steps	The human proteome comprises tens of thousands of proteins, each tailored for a specific function by the selective pressures of evolution. The field of protein design seeks to develop proteins with new or enhanced functions at will, ultimately bypassing the evolutionary clock. In this talk, we discuss general machine-learning methods for accelerating the crucial components of protein design, with a particular focus on the underlying models. We begin with an overview of the protein design field and discuss traditional approaches. We then focus on two important subtasks, fixed-backbone design and protein-protein docking, and critique deep learning approaches with an emphasis on the modeling considerations that attribute to their success. Finally, we highlight some limitations and outstanding challenges in the field and potential next steps.	proteome protein challenges deep design proteins evolution evolutionary learning mia meeting		2023-05-08											Matthew McPartlon	245	0
Unlocking Generative AI for Drug Discovery with Zero-shot Models	Generative AI has the potential to greatly incrase the speed, quality, and controllability of drug design. Traditional discovery requires time and resource intensive screening of large libraries, which also offer little control on the output molecules, which can result in suboptimal candidates. Here, we show how generative deep learning models can produce molecules and representations that could be used for downstream design of new molecules with specified functions.	intensive learning unlocking screening models drug libraries generative discovery mia meeting		2023-05-08											Joshua Meier	246	0
Geometric deep learning and generative models for protein target discovery	Computational therapeutic target discovery requires deciphering the cell types in which proteins act and their interactions. We present PINNACLE, a contextual AI model for single-cell protein biology. Using a multi-organ single-cell atlas, PINNACLE learns from contextualized protein interaction networks, producing 394,760 protein representations from 156 cell types across 24 tissues. PINNACLE’s embedding space reflects cellular and tissue organization, enabling zero-shot retrieval of tissue hierarchy. Pretrained PINNACLE representations can power a range of tasks: enhancing 3D structure-based representations in immuno-oncology, predicting drug effects across cell types and states, and identifying therapeutic targets in a cell-type-specific manner. We used PINNACLE to nominate protein targets for rheumatoid arthritis and inflammatory bowel disease, identifying predictive cell type contexts. Drugs bind to protein pockets, areas where proteins interact with ligand molecules, a challenging task due to biomolecular interactions and sequence-structure dependencies. We developed PocketGen, a sequence-structure generative model that optimizes protein pockets to serve as optimal binders for ligand molecules. PocketGen iteratively refines the sequence and structure of pockets by maximizing binding affinity with the ligand and sequence-structure consistency. Using a graph transformer for all-atom structure modeling and a protein language model for sequence prediction, PocketGen can help optimize protein pockets with high binding affinity, strong structural validity and generation efficiency.	oncology protein learning biology biomolecular proteins geometric generative discovery mia meeting		2023-05-29											Marinka Zitnik	247	0
Multimodal protein language models for deciphering protein function	Understanding the relationship between a protein's amino acid sequence and its structure or function is a long-standing challenge with far-reaching implications for therapeutic development, as the effects of drugs are often directly linked to proteins. Current protein language models (PLMs) capture evolutionary relationships based on sequences but fall short of directly acquiring protein functions from multimodal molecular data, including protein sequences and structures, peptides, and domains. We develop a multimodal protein language model that integrates textual protein descriptions with a sequence-structure PLM to create a more comprehensive and functionally insightful model of proteins. This integration promises to bridge the current gap in PLMs, transitioning from understanding the structural aspects of proteins to gaining a functional view of vast protein space. The model allows scientists to express their queries in natural language and interact with protein models in an open-ended manner. It allows for text-based prediction of protein targets, multimodal protein captioning, and Q&A sessions with scientists with varying levels of expertise, among others. Trained on a new dataset of protein-text instructions, the model can generalize to new phenotypes in a zero-shot manner, making it versatile for diverse tasks even when functional annotations are scarce. We conclude with an outlook for the future with “AI scientists” as generative agents capable of skeptical learning and reasoning to empower biomedical research.	function scientists deciphering protein biomedical multimodal proteins molecular language mia meeting		2023-05-29											Owen Queen, Yepeng Huang, Marinka Zitnik	248	0
Hybrid protein language models for fitness prediction and design	The ability to accurately model the fitness landscape of protein sequences is critical to a wide range of applications, from quantifying the effects of human variants on disease likelihood, to predicting immune-escape mutations in viruses and designing novel biotherapeutic proteins. Deep generative models of protein sequences trained on multiple sequence alignments have been the most successful approaches so far to address these tasks. The performance of these methods is however contingent on the availability of sufficiently deep and diverse alignments for reliable training. Their potential scope is thus limited by the fact many protein families are hard, if not impossible, to align. Large language models trained on massive quantities of non-aligned protein sequences from diverse families seek to address these problems. However, their performance has not yet matched that of their alignment-based counterparts. This talk will introduce hybrid strategies to leverage the strengths from both model classes	biotherapeutic fitness hybrid protein design proteins hard prediction massive mia meeting		2024-02-14											Pascal Notin	249	0
Unsupervised viral antibody escape prediction for future-proof vaccines	Effective pandemic preparedness relies on predicting immune-evasive viral mutations to ensure early detection of variants of concern and to design future-proofed vaccines and therapeutics. However, current experimental strategies for viral evolution prediction are not available early in a pandemic since  they require host polyclonal antibodies.  Furthermore, the existing paradigm for vaccine evaluation relies on retrospective evaluation against past variants, instead of proactive evaluation against future viral evolution. To address these limitations, we developed EVEscape, a model which integrated fitness predictions from evolutionary models, structure-based features that assess antibody binding potential, and biochemical distances between mutated and wild-type residues. EVEscape quantifies the viral escape potential of mutations at scale and has the advantage of being applicable before surveillance sequencing, experimental scans, or 3D structures of antibody complexes are available. Using only information available pre-pandemic, EVEscape is as accurate as high-throughput experimental scans at anticipating pandemic variation for SARS-CoV-2 and is generalizable to other viruses. Using EVEscape we forecast future SARS-CoV-2 evolution and present a novel and proactive approach for evaluating  and designing vaccines.	antibodies viruses future vaccine prediction antibody vaccines viral mia meeting		2024-02-14											Noor Youssef, Sarah Faye Gurev	250	0
Accurate proteome-wide missense variant effect prediction with Alpha Missens	The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present Alpha Missense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89% of missense variants as either likely benign or likely pathogenic.	proteome genes genome alpha missense accurate genetic prediction pathogenicity pathogenic mia meeting		2024-03-13											Žiga Avsec	251	0
Alpha Missens	The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present Alpha Missense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89% of missense variants as either likely benign or likely pathogenic.	genes genome alpha missens genetic pathogenicity pathogenic mia meeting		2024-03-13											Jun Cheng	252	0
Testing data-driven hypotheses post-clustering	This primer talk is motivated by the practice of testing data-driven hypotheses. In the biomedical sciences, it has become increasingly common to collect massive datasets without a pre-specified research question. In this setting, a data analyst might use the data both to generate a research question, and to test the associated null hypothesis. For example, in single-cell RNA-sequencing analyses, researchers often first cluster the cells, and then test for differences in the expected gene expression levels between the clusters to quantify up- or down-regulation of genes, annotate known cell types, and identify new cell types. However, this popular practice is invalid from a statistical perspective: once we have used the data to generate hypotheses, standard statistical inference tools are no longer valid. To tackle this problem, I developed a conditional selective approach to test for a difference in means between pairs of clusters obtained via hierarchical and k-means clustering. The proposed approach has appropriate statistical guarantees (e.g., selective Type 1 error control), and we demonstrate its use on single-cell RNA-sequencing data.	genes data research post biomedical researchers clustering rna testing hypotheses mia meeting		2024-03-20											Yiqun Chen	253	0
Data thinning to avoid double dipping	"""Double dipping"" is the practice of using the same data to fit and validate a model. Problems typically arise when standard statistical procedures are applied in settings involving double dipping. To avoid the challenges surrounding double dipping, a natural approach is to fit a model on one dataset, and then validate the model on another independent dataset. When we only have access to one dataset, we typically accomplish this via sample splitting. Unfortunately, in some problems, sample splitting is unattractive or impossible. In this talk, we are motivated by unsupervised problems that arise in the analysis of single cell RNA sequencing data, where sample splitting does not allow us to avoid double dipping. We first propose Poisson thinning, which splits a single observation drawn from a Poisson distribution into two independent pseudo-observations. We show that Poisson count splitting allows us to avoid double dipping in unsupervised settings. We next generalize the Poisson thinning framework to a variety of distributions, and refer to this general framework as ""data thinning"". Data thinning is applicable far beyond the context of single-cell RNA sequencing data, and is particularly useful for problems where sample splitting is unattractive or impossible."	statistical data avoid sequencing sample double thinning dipping mia meeting		2024-03-20											Lucy Gao	254	0
SPLASH unifies genomic analysis and discovery through a paradigm shift to statistics-first	Myriad mechanisms diversify the sequence content of DNA and of RNA transcripts. Currently, these events are detected using tools that first require alignment to a necessarily incomplete reference genome alignment in the first step; this incompleteness is especially prominent in human genetic diseases such as cancer, in the microbial world, and in non—model organisms where it severely limits the speed and scope of discovery. Second, today the next step in analysis requires as a custom choice of bioinformatic procedure to follow it: for example, to detect splicing, RNA editing, or V(D)J recombination among many others.  I will present the theory for why SPLASH, a new statistics-first analytic approach captures myriad forms of genome regulation, without a reference or sample metadata, by performing statistical inference directly on raw sequencing reads. By design, SPLASH as an algorithm is highly efficient. Thanks to joint work with Professor Sebastian Deorowicz’s group, SPLASH is now implemented so that it is efficient and simple to run. A snapshot of its findings include new insights into RNA splicing, cancer transcriptomes, single cell RNA-editing, mobile genetic elements and discovers new genes non-model organisms.	genome cancer statistics bioinformatic splash genomic genetic paradigm discovery dna mia meeting		2024-04-03											Julia Salzman	255	0
Statistical and algorithmic challenges in reference-free analysis	Today’s genomics workflows typically begin by aligning sequencing data to a reference. In addition to being slow, this has many statistical drawbacks. Even in the intensely studied human genome, it was found that understudied populations have large amounts of sequence missing from the current reference; such blind spots may exacerbate health disparities. Reference-based methods are additionally limited in their detection of novel biology: reads from unannotated isoforms may be mismapped or discarded completely. In recent work we introduce a unifying paradigm, SPLASH, which directly analyzes raw sequencing data, using a statistical test to detect a signature of regulation: sample-specific sequence variation. SPLASH detects many types of variation and can be efficiently run at scale, providing a unifying statistical approach to genomic analysis that enables expansive discovery without metadata or references. In this primer I’ll discuss some of the challenges of reference-free analysis, and provide the algorithmic and statistical background for our proposed solution, SPLASH.	statistical drawbacks genomics reference exacerbate algorithmic challenges biology genomic analysis mia meeting		2024-04-03											Tavor Baharav	256	0
Single-cell models for state-dependent eQTL analysis	As single-cell RNA-seq datasets grow larger and more complex, they enable richer analyses of how gene expression varies between cells and people. However, methods designed for bulk data fail to account for the unique structure of single-cell gene expression. Researchers are now developing statistical models tailored to single-cell-resolution data for a variety of applications. In this primer, I will focus on single-cell models for the task of mapping expression quantitative trait loci (eQTLs) to find genetic variants associated with a gene's expression. Single-cell eQTL models have the potential to capture disease-relevant, state-dependent regulatory effects with the right statistical models and representations of cell state. This primer will discuss the evolution of statistical models for eQTL mapping from pseudobulk to single-cell resolution, representations of single-cell states for state-dependent analyses, and outstanding computational challenges.	analysis state researchers disease computational genetic eqtl rna single cell mia meeting		2024-04-10											Aparna Nathan	257	0
Scalable single-cell models for robust cell-state-dependent eQTL mapping	Modelling cell state-dependent genetic associations with single-cell gene expression exhibits statistical and computational challenges. First, parametrization of single-cell gene expression profiles is not a straightforward task because individual genes exhibit distinct distributions. Second, current single-cell datasets consist of hundreds of thousands to millions of cells, which constrains the ability to test associations in a scalable manner. In this talk, I will introduce a new generalizable approach to robustly identify cell state-dependent eQTLs in single-cell data. To overcome the challenge of gene expression parametrization, we implemented a non-parametric bootstrap procedure to compute empirically calibrated p-values for variant-gene expression associations. To speed up the computation, we used the Julia programming language and pre-computed covariate-adjusted gene expression profiles with a linear mixed model before testing cell state-dependent eQTL interactions. Finally, I will demonstrate an application of this approach to identify autoimmune disease risk loci with context-specific effects in memory T cells.	genes autoimmune scalable computation mapping computational genetic eqtl robust cell mia meeting		2024-04-10											Jose Alquicira-Hernandez	258	0
Protein language models learn evolutionary statistics of interacting sequence motifs	Protein language models (pLMs) have exhibited remarkable capabilities in protein structure prediction and design. However, the extent to which they comprehend the intrinsic biophysics of protein structures remains uncertain. We present a suite of analyses that dissect how the flagship pLM ESM-2 predicts structure. Motivated by a consistent error of protein isoforms predicted as structured fragments, we developed a completely unsupervised method to uniformly evaluate any pLM, allowing us to compare coevolutionary statistics to linear models. We further identified that ESM-2 does not require full context for predicting inter-residue contacts. Our study highlights the current limitations of pLMs and contributes to a deeper understanding of their underlying mechanisms, paving the way for more reliable protein structure predictions.	statistics protein learn study biophysics analyses prediction evolutionary language mia meeting		2024-05-01											Sergey Ovchinnikov	259	0
Combining protein language and structure models to redesign E. coli proteome with a reduced amino acid alphabet	All known organisms need all 20 canonical amino acids to survive and reproduce, yet use of different amino acids must’ve evolved over time. Unfortunately, even the last universal common ancestor used all 20, so there is no way to observe how life might have looked without all of them. Here, we’re trying to synthesize such an organism by designing a strain of E. coli using only 19 canonical amino acids, starting from redesigning essential genes one at a time with the goal of preserving fitness. Since there are many diverse genes to design, we’re repurposing and extending machine learning-driven protein design methods to accomplish this task. Each of the currently available methods is capturing specific properties of the design landscape due to its approach and training data provided to the models. Protein language models like ESM have access to a vast number of sequences and can learn patterns favored by nature. Methods using AlphaFold as a loss function like AFDesign or MCMC hallucination are aware of the final structure of the protein, but are susceptible to adversarial examples. Finally, models which perform “inverse folding” like ProteinMPNN have both sequence and structure information and can output structure-aware designs. We’re developing optimization methods which combine these models as part of the design process to find sequences which are scored highly by models coming from different approaches, and how this translates to their biological properties. The experimental results show that our methods can generate designs comparable with wild-type versions in fitness with a small number of attempts.	genes amino protein proteinmpnn coli redesign alphabet 20 mia meeting		2024-05-01											Simon Kozlov	260	0
Protein Design with Deep Learning: Progress, Challenges, and Next Steps	The human proteome comprises tens of thousands of proteins, each tailored for a specific function by the selective pressures of evolution. The field of protein design seeks to develop proteins with new or enhanced functions at will, ultimately bypassing the evolutionary clock. In this talk, we discuss general machine-learning methods for accelerating the crucial components of protein design, with a particular focus on the underlying models. We begin with an overview of the protein design field and discuss traditional approaches. We then focus on two important subtasks, fixed-backbone design and protein-protein docking, and critique deep learning approaches with an emphasis on the modeling considerations that attribute to their success. Finally, we highlight some limitations and outstanding challenges in the field and potential next steps.	proteome protein challenges deep design proteins evolution evolutionary learning mia meeting		2024-05-08											Matthew McPartlon	261	0
Unlocking Generative AI for Drug Discovery with Zero-shot Models	Generative AI has the potential to greatly incrase the speed, quality, and controllability of drug design. Traditional discovery requires time and resource intensive screening of large libraries, which also offer little control on the output molecules, which can result in suboptimal candidates. Here, we show how generative deep learning models can produce molecules and representations that could be used for downstream design of new molecules with specified functions.	intensive learning unlocking screening models drug libraries generative discovery mia meeting		2024-05-08											Joshua Meier	262	0
Geometric deep learning and generative models for protein target discovery	Computational therapeutic target discovery requires deciphering the cell types in which proteins act and their interactions. We present PINNACLE, a contextual AI model for single-cell protein biology. Using a multi-organ single-cell atlas, PINNACLE learns from contextualized protein interaction networks, producing 394,760 protein representations from 156 cell types across 24 tissues. PINNACLE’s embedding space reflects cellular and tissue organization, enabling zero-shot retrieval of tissue hierarchy. Pretrained PINNACLE representations can power a range of tasks: enhancing 3D structure-based representations in immuno-oncology, predicting drug effects across cell types and states, and identifying therapeutic targets in a cell-type-specific manner. We used PINNACLE to nominate protein targets for rheumatoid arthritis and inflammatory bowel disease, identifying predictive cell type contexts. Drugs bind to protein pockets, areas where proteins interact with ligand molecules, a challenging task due to biomolecular interactions and sequence-structure dependencies. We developed PocketGen, a sequence-structure generative model that optimizes protein pockets to serve as optimal binders for ligand molecules. PocketGen iteratively refines the sequence and structure of pockets by maximizing binding affinity with the ligand and sequence-structure consistency. Using a graph transformer for all-atom structure modeling and a protein language model for sequence prediction, PocketGen can help optimize protein pockets with high binding affinity, strong structural validity and generation efficiency.	oncology protein learning biology biomolecular proteins geometric generative discovery mia meeting		2024-05-29											Marinka Zitnik	263	0
Multimodal protein language models for deciphering protein function	Understanding the relationship between a protein's amino acid sequence and its structure or function is a long-standing challenge with far-reaching implications for therapeutic development, as the effects of drugs are often directly linked to proteins. Current protein language models (PLMs) capture evolutionary relationships based on sequences but fall short of directly acquiring protein functions from multimodal molecular data, including protein sequences and structures, peptides, and domains. We develop a multimodal protein language model that integrates textual protein descriptions with a sequence-structure PLM to create a more comprehensive and functionally insightful model of proteins. This integration promises to bridge the current gap in PLMs, transitioning from understanding the structural aspects of proteins to gaining a functional view of vast protein space. The model allows scientists to express their queries in natural language and interact with protein models in an open-ended manner. It allows for text-based prediction of protein targets, multimodal protein captioning, and Q&A sessions with scientists with varying levels of expertise, among others. Trained on a new dataset of protein-text instructions, the model can generalize to new phenotypes in a zero-shot manner, making it versatile for diverse tasks even when functional annotations are scarce. We conclude with an outlook for the future with “AI scientists” as generative agents capable of skeptical learning and reasoning to empower biomedical research.	function scientists deciphering protein biomedical multimodal proteins molecular language mia meeting		2024-05-29											Owen Queen, Yepeng Huang, Marinka Zitnik	264	0
A therapy candidate for fatal prion diseases turns off disease-causing gene	Prion diseases lead to rapid neurodegeneration and death and are caused by misshapen versions of the prion protein in the brain. There are currently no treatments, but researchers from the Whitehead Institute for Biomedical Research and Broad Institute of MIT and Harvard have developed an approach that could one day be used to turn off the gene encoding this protein throughout the brain to treat or even prevent prion disease. In a paper published in today’s Science, the team describes their technology: a set of molecular tools that are delivered to the brain and adds a chemical tag to the gene for the prion protein to prevent the protein from being produced by cells. Unlike gene editing, this “epigenetic” editing does not modify the underlying DNA sequence, but it should switch the gene off permanently, which means that this could be a one-time treatment. Research in animals suggests that the prion protein isn’t necessary in a healthy adult, so epigenetic editing that silences the gene for this protein could be an effective approach for treating prion diseases. The researchers, led by Jonathan Weissman of the Whitehead and Sonia Vallabh of the Broad, showed that their system, called CHARM, in a single intravenous injection, could be delivered across the brain in mice and eliminate more than 80 percent of the prion protein. Previous research has shown that as little as 21 percent elimination of the protein can improve symptoms. To deliver CHARM throughout the brain, the team collaborated with scientists in the lab of Ben Deverman, senior director of vector engineering at the Broad and a co-author of the study. They used an engineered adeno-associated virus (AAV) that crosses the blood-brain barrier after intravenous administration. “With the Whitehead and Broad Institutes right next door to each other, I don’t think there’s any better place than this for a group of motivated people to move quickly and flexibly in the pursuit of academic science and medical technology,” said Weissman, co-senior author of the study who is also a professor of biology at the Massachusetts Institute of Technology, a Howard Hughes Medical Institute investigator, and an affiliate of the Broad. “CHARMs are an elegant solution to the problem of silencing disease genes, and they have the potential to have an important position in the future of genetic medicines.” “The spirit of the collaboration since the beginning has been that there was no waiting on formality,” said Vallabh, co-senior author and a senior group leader at Broad. “As soon as we realized our mutual excitement to do this, everything was off to the races.” The study co-first authors are Edwin Neumann, a graduate student, and Tessa Bertozzi, a postdoc, both in Weissman’s lab. Therapy search Vallabh, along with her husband Eric Minikel, leads a lab at Broad focused on developing drugs to prevent and treat prion diseases. They switched careers and became researchers 12 years ago after Vallabh’s mother passed away from a rare form of prion disease called fatal familial insomnia. Vallabh soon found out that she inherited the same disease-causing mutation in the prion protein gene. Vallabh and Minikel’s lab has been working urgently to develop prion disease treatments, so Vallabh was excited to discover that Weissman’s group also likes to work at full throttle. In less than two years, Weissman, Vallabh, and their collaborators developed the CHARM system that can turn off disease-causing genes such as the prion protein gene, as well as, potentially, genes coding for many other proteins implicated in neurodegenerative and other diseases. The team says epigenetic editing could be an effective approach for treating genetic diseases such as inherited prion diseases. They are refining those editing tools to be good candidates for use in patients. Prion disease research in animals suggests that removing the prion protein could improve or even eliminate disease symptoms, and removing it before symptoms develop should prevent disease altogether. Although the CHARM tools still have many hurdles to pass before the researchers will know if they work as therapeutics, the team is encouraged by the speed with which they have developed the technology thus far. To develop CHARM as a potential therapy, the team had a good template: a research tool called CRISPRoff that Weissman’s group previously developed for silencing genes. CRISPRoff uses building blocks from CRISPR gene editing technology, including the guide protein Cas9 that directs the tool to the target gene. CRISPRoff silences the targeted gene by adding methyl groups, chemical tags that prevent the gene from being transcribed or read into RNA and so from being expressed as protein. When the researchers tested CRISPRoff’s ability to silence the prion protein gene, they found that it was effective and stable. Several of its properties, though, prevented CRISPRoff from being a good candidate for a therapy. The researchers’ goal was to create a tool based on CRISPRoff that was just as potent but also safe for use in humans, small enough to deliver to the brain, and designed to minimize the risk of silencing the wrong genes or causing side effects. From tool to drug Led by Neumann and Bertozzi, the researchers began engineering a new epigenome editor. The first problem they had to tackle was the editor’s size, because the editor needs to be small enough to be packaged and delivered to specific cells in the body. Delivering genes into the human brain is challenging; many clinical trials have used adeno-associated viruses (AAVs) as gene-delivery vehicles, which are small and can only contain a small amount of genetic code. CRISPRoff is too big; the code for Cas9 alone takes up most of the available space. The Weissman lab researchers decided to replace Cas9 with a much smaller zinc finger protein (ZFP), which fits in an AAV. Like Cas9, ZFPs can serve as guide proteins to direct the tool to a target site in DNA. ZFPs are also common in human cells, meaning they are less likely to trigger an immune response against themselves than the bacterial Cas9. Next, the researchers had to design the part of the tool that would silence the prion protein gene. At first, they used part of a methyltransferase, a molecule that adds methyl groups to DNA, called DNMT3A. However, in the particular configuration needed for the tool, the molecule was toxic to the cell. The researchers focused on a different solution: instead of delivering outside DNMT3A as part of the therapy, the tool is able to recruit the cell’s own DNMT3A to the prion protein gene. This freed up precious space inside of the AAV vector and prevented toxicity. The researchers also needed to activate DNMT3A. In the cell, DNMT3A is usually inactive until it interacts with certain partner molecules. This default inactivity prevents accidental methylation of genes that need to remain turned on. Neumann came up with an ingenious way around this by combining sections of DNMT3A’s partner molecules and connecting these to ZFPs that bring them to the prion protein gene. When the cell’s DNMT3A comes across this combination of parts, it activates, silencing the gene. “From the perspectives of both toxicity and size, it made sense to recruit the machinery that the cell already has; it was a much simpler, more elegant solution,” Neumann said. “Cells are already using methyltransferases all of the time, and we’re essentially just tricking them into turning off a gene that they would normally leave turned on.” Once the researchers knew that they had a potent gene silencer, they turned to the problem of off-target effects. The genetic code for a CHARM that gets delivered to a cell will keep producing copies of the CHARM indefinitely. However, after the prion protein gene is switched off, there is no benefit to this, only more time for side effects to develop, so they tweaked the tool so that after it turns off the prion protein gene, it then turns itself off. Meanwhile, a complementary project from Deverman’s lab, focused on brain-wide gene delivery and published in Science in May, has brought the CHARM technology one step closer to being ready for clinical trials. Although naturally occurring types of AAV have been used for gene therapy in humans before, they do not enter the adult brain efficiently, making it impossible to treat a whole-brain disease like prion disease. Tackling the delivery problem, Deverman’s group has engineered an AAV vector that can get into the brain more efficiently by grabbing on to a protein that naturally shuttles iron into the brain. Engineered vectors like this one make a therapy like CHARM one step closer to reality. Thanks to these creative solutions, the researchers now have a highly effective epigenetic editor that is small enough to deliver to the brain, and that appears in cell culture and animal testing to have low toxicity and limited off-target effects. “It’s been a privilege to be part of this; it’s pretty rare to go from basic research to therapeutic application in such a short amount of time,” Bertozzi said. “I think the key was forming a collaboration that took advantage of the Weissman lab’s tool-building experience, the Vallabh and Minikel lab’s deep knowledge of the disease, and the Deverman lab’s expertise in gene delivery.” Looking ahead With certain major elements of the CHARM technology solved, the team is now fine-tuning their tool to make it more effective, safer, and easier to produce at scale, which will be necessary for clinical trials. They have already made the tool modular, so that its various pieces can be swapped out and future CHARMs won’t have to be programmed from scratch. CHARMs are also currently being tested as therapeutics in mice. The path from basic research to clinical trials is a long and winding one, and the researchers know that CHARMs still have a way to go before they might become a viable medical option for people with prion diseases, including Vallabh, or other diseases with similar genetic components. However, with a strong therapy design and promising laboratory results in hand, the researchers have good reason to be hopeful. They continue to work at full throttle, intent on developing their technology so that it can save patients’ lives not someday, but as soon as possible. Adapted from a Whitehead Institute news story 	candidate neurodegenerative diseases fatal biology neurodegeneration therapy biomedical scientists disease broad news		2024-06-27											Greta Friar, Whitehead Institute	265	0
Simple test for flu could improve diagnosis and surveillance	Fewer than one percent of people who get the flu every year get tested in part because most tests require trained personnel and expensive equipment. Now researchers have developed a low-cost paper strip test that could allow more patients to find out which type of flu they have and get the right treatment. The test, developed by a team from the Broad Institute of MIT and Harvard and Princeton University, and supported by the US Centers for Disease Control and Prevention, uses CRISPR to distinguish between the two main types of seasonal flu, influenza A and B, as well as seasonal flu subtypes H1N1 and H3N2. It can also identify strains that resist antiviral treatment, and with further work, could potentially detect swine and avian flu strains, including H5N1, which is currently infecting cattle. Appearing today in The Journal of Molecular Diagnostics, the results could help improve outbreak response and clinical care by bringing tests that are accurate, low-cost, and fast to doctors’ offices and labs across the US and in other countries. “Ultimately, we hope these tests will be as simple as rapid antigen tests, and they’ll still have the specificity and performance of a nucleic acid test that would normally be done in a laboratory setting,” said Cameron Myhrvold, co-senior author on the study along with Pardis Sabeti, an institute member at the Broad and a professor at Harvard University and the Harvard T.H. Chan School of Public Health, as well as a Howard Hughes Medical Institute investigator. Myhrvold, who is currently an assistant professor at Princeton University, was a postdoctoral researcher in Sabeti’s lab when the study began. SHINE a light The test is based on a technology called SHINE, which was developed by Sabeti’s lab in 2020 and uses CRISPR enzymes to identify specific sequences of viral RNA in samples. The researchers first used SHINE to test for SARS-CoV-2, and later to distinguish between the Delta and Omicron variants. Then, in 2022, they began adapting the assay to detect other viruses they knew were always circulating: influenzas. They wanted to create tests that could be used in the field or in clinics rather than hospitals or diagnostic labs with expensive equipment. “Using a paper strip readout instead of expensive fluorescence machinery is a big advancement, not only in terms of clinical care but also for epidemiological surveillance purposes,” said Ben Zhang, co-first author on the study, a medical student at Harvard Medical School and an undergraduate researcher in Sabeti’s lab when the study began. Typical diagnostic approaches such as polymerase chain reaction (PCR) require lengthy processing times, trained personnel, specialized equipment, and freezers to store reagents at -80°C, whereas SHINE can be conducted at room temperature in about 90 minutes. Currently, the assay only requires an inexpensive heat block to warm the reaction, and the researchers are working to streamline the process with the goal of returning results in 15 minutes. The researchers also adapted SHINE to distinguish between different flu strains. In the future, they say the assay could be adapted to detect two different viruses with similar symptoms, such as influenza and SARS-CoV-2. “Being able to tease apart what strain or subtype of influenza is infecting a patient has repercussions both for treating them and public health interventions,” said Jon Arizti-Sanz, a postdoctoral researcher in Sabeti’s lab and co-first author on the study. For example, the tests could help clinicians decide whether to use Oseltamivir, a common antiviral that is effective for only some strains, Arizti-Sanz added. In the field, rapid testing could also help scientists collect samples more strategically during an outbreak to better monitor how the virus is spreading. Next, the researchers are adapting SHINE to test for both avian and swine influenza strains. “With SARS-CoV-2 and now flu, we’ve shown that we can easily adapt SHINE to detect new or evolving viruses,” Arizti-Sanz said. “We’re excited to apply it to H5N1.” 	influenza diagnosis improve influenzas surveillance test doctors flu scientists clinicians broad news		2024-06-18											Allessandra DiCorato	266	0
Gut microbiome changes align with increased risk of type 2 diabetes	"The largest and most ethnically and geographically comprehensive investigation to date of the gut microbiome of people with type 2 diabetes (T2D), prediabetes, and healthy glucose status has found that specific viruses and genetic variants within bacteria correspond with changes in gut microbiome function and T2D risk. Results of the study — which represents a collaboration across Brigham and Women’s Hospital, the Broad Institute of MIT and Harvard, and Harvard T.H. Chan School of Public Health — are published in Nature Medicine. ""The microbiome is highly variable across different geographic locations and racial and ethnic groups. If you only study a small, homogeneous population, you will probably miss something,"" said co-corresponding author Daniel (Dong) Wang, an assistant professor of medicine at Brigham and Women's Hospital and of nutrition at Harvard Chan School, and an associate member of Broad's Infectious Disease and Microbiome Program (IDMP). ""Our study is by far the largest and most diverse study of its kind."" ""The gut microbiome's relationship to complex, chronic, heterogeneous diseases like T2D is quite subtle,"" said co-corresponding author Curtis Huttenhower, a professor of biostatistics and immunology and infectious Diseases at Harvard Chan School and also an associate member of Broad's IDMP. ""Much like studies of large human populations have been crucial for understanding human genetic variation, large and diverse populations are necessary — and increasingly feasible — for detailed microbiome variation studies as well."" Co-first authors on the paper are Zhendong Mei of and Women’s Hospital and Broad, and Fenglei Wang of Harvard Chan School and Broad. Expanded understanding T2D affects approximately 537 million people worldwide. In T2D, the body gradually loses its ability to regulate blood sugar effectively. Research over the last decade has linked changes in the gut microbiome — the collection of bacteria, fungi, and viruses that inhabit our intestines — to the development of T2D. However, prior studies of the gut microbiome and its role in T2D have been too small and varied in study design to draw significant conclusions. This paper analyzed data from the newly established Microbiome and Cardiometabolic Disease Consortium (MicroCardio). The investigation included newly generated data and those originally captured during several other experiments, encompassing a total of 8,117 gut microbiome metagenomes from ethnically and geographically diverse participants. People included in the study had T2D, prediabetes, or no changes in their blood sugar levels, and hailed from China, Denmark, Finland, Germany, Israel, Sweden, and the U.S. ""With this large study, we asked two questions,"" Wang said. ""One is, ‘What are the roles of species and strains that make up the gut microbiome in type 2 diabetes?’ The other question is, ‘What are these microbes doing?’ ""When we analyzed this data, we found a relatively consistent set of microbial species linked to type 2 diabetes across our study populations,"" Wang continued. ""Many of those species have never been reported before."" To understand the role of these microbes in the gut, the team analyzed species' functional abilities. Different strains of a microbial species can have varied functions, like the ability to make a specific amino acid. The team found that certain strains had functions that may be linked to varied T2D disease risk. One major functional difference they saw was that a strain of Prevotella copri — a common microbe in the gut that has the capacity to produce large amounts of branched-chain amino acids (BCAAs) — was more commonly seen in diabetes patients’ gut microbiomes. Previous studies have shown that people with chronically high blood levels of BCAAs have a higher risk of obesity and T2D. The researchers also found evidence suggesting that bacteriophages — viruses that infect bacteria — could be driving some of the changes they detected within certain strains of gut bacteria. ""Our findings related to bacteriophages were very surprising,"" Wang said. ""This could mean that the virus infects the bacteria and changes its function in a way that increases or decreases type 2 diabetes risk, but more work is needed to understand this connection."" Clues to a cause In another analysis, the team studied a small subset of samples from patients newly diagnosed with T2D to assess microbiomes that are less likely to have been impacted by medication use or long-term high glucose status. Their results were similar to their larger findings, according to Wang. ""We believe that changes in the gut microbiome cause type 2 diabetes,” said Wang. “The changes to the microbiome may happen first, and diabetes develops later, not the other way around — although future prospective or interventional studies are needed to prove this relation firmly. ""If these microbial features are causal, we can find a way to change the microbiome and reduce type 2 diabetes risk,"" he added. ""The microbiome is amenable to intervention — meaning you can change your microbiome, for example, with dietary changes, probiotics, or fecal transplants."" One major limitation of the study is that, for the most part, it looked at patients' microbiomes at one point in time. It didn't look at changes to the gut microbiome or disease status over time. Future studies that build on this work include studying this link over an extended period and examining the strain-specific functions to understand better how they lead to T2D. ""A benefit and a challenge of the human microbiome is that it is highly personalized,"" said Huttenhower. ""The fact that we each have highly distinct microbial communities and microbial genetics means that very large population studies are needed to find consistent patterns. But once we do, individual microbiomes have the potential to be reshaped to help reduce disease risk."" Adapted from a press release issued by Brigham and Women's Hospital, a founding member of the Mass General Brigham healthcare system. "	increased bacteria microbiome diabetes bacteriophages probiotics risk changes genetics broad news		2024-06-25											Jennifer Welsh, Brigham and Women's Hospital	267	0
#WhyIScience Q&A: A biochemist uses mass spectrometry to find proteins involved in cancer	When Moe Haines first moved from Beirut, Lebanon to the United States for college, his goal was to earn a degree in pharmacy. Haines was the first person in his family to pursue science, and most people he knew with similar interests had chosen a career in medicine. But his first few biology classes in community college exposed him to the possibility of a career in genetics, chemistry, or physics. Haines became particularly interested in protein structure and function and pivoted towards a biochemistry program at Siena College in upstate New York. After graduating from college, Haines moved closer to his passion for proteomics, working as an analytical development research scientist for a pharmaceutical company in Albany, NY before relocating to Massachusetts. He worked as a drug development research associate at Sanofi and then joined the chemical biology and proteomics group of a small startup in Cambridge. As the startup struggled to find funding, Haines heard about the Proteomics Platform at the Broad Institute of MIT and Harvard. He was excited by the prospect of working in a nationally renowned proteomics lab that houses an impressive 13 mass spectrometers, which enable in-depth and higher throughput analysis of a wide range of chemically modified proteins. Now, Haines is a senior research associate in the Proteomics Platform, where he works with Shankha Satpathy, a senior group leader. As part of the National Cancer Institute's Clinical Proteomic Tumor Analysis Consortium (CPTAC), Haines and colleagues in the platform investigate proteins involved in cancer and develop new approaches for proteomic analyses of samples from cancer patients at scale. We spoke with Haines about his journey from big pharma to the Broad, the value of experimenting with career options, and the untapped potential of proteomics in this #WhyIScience Q&A. How did you get interested in proteomics? When I first got to the US, I found a lot of interest in evolution and how science can explain things better than what I was taught back home. That’s how I ended up majoring in biochemistry. And I got into proteomics because I enjoyed thinking about proteins as machines, what they do, and how they operate. In a traditional family, you’re told to be a doctor — that’s just the way things are done. But I knew that I wouldn’t be happy in medicine. None of my immediate family members have a science background, and it’s challenging to craft your path on your own. But I just really enjoyed the research I was doing, and no longer being in a conservative environment in my home country helped me understand this even more. How do you think about proteomics and where the field is headed? Proteomics adds a layer of dimension to the data generated by other teams at the Broad. The human genome consists of about 20,000 genes that code for proteins. Given the dynamic nature of proteins, this translates into more than a million proteins and their modified structures, or proteoforms. Proteomics also generates so much data, so it’s really analytics-intensive. Searching, storing, and maintaining all that data remain a challenge. Compared to fields like genomics, proteomics is in a much earlier stage. We haven’t really tapped into this exponential growth like genomics has. Proteomics is like a puzzle. There is just so much to learn about all the different proteins and their variants, but that’s what I like about this field. We’re striving to improve throughput, depth, and reproducibility. Mass spectrometers are now faster and more sensitive, and database searching algorithms are updated frequently, which is improving data confidence and identification rates. This is all coupled with cloud-based resources like Terra at Broad, which allows for scalability for large cohort studies. How does the Proteomics Platform collaborate with other groups at the Broad? CPTAC itself is a massive collaboration, not just within the Broad, but with other institutions. We receive a lot of genomic data that we analyze in tandem with our lab’s proteomic data. You see what the DNA is telling you, plot that with protein information, and you end up with a really informative, comprehensive view of what’s happening in cancer cells and tissues. More generally, the Proteomics Platform helps Broadies who are interested in knowing what the proteins in their experiments are up to. Mass spectrometry enables us to look beyond genetic data, so we can give other scientists a snapshot of each sample or cell of interest and help them infer the protein-level output. What are you working on within CPTAC? CPTAC works with a lot of clinical samples. Many of our projects use sample multiplexing to achieve great depth and scalability. Despite the ease of analysis and increased depth and input that multiplexed analysis provides, these methods can be inefficient because of the sample preparation needed to plex your samples and the complications that can arise from multiplexed assays. For this reason, we are switching to label-free analyses for newer projects, called data-independent acquisition or DIA. DIA is emerging as a next generation mass spec approach. Rather than sequencing each multiplexed peptide at a time, we analyze each sample individually by taking advantage of faster instrumentation. Switching from multiplexed-based proteomics to label-free analysis cuts sample prep time in half and improves the data-generation throughput by almost 4-5 times. We’re talking about running 45-60 samples a day versus 8-12. Proteomics has come a long way, putting us in a better position for clinical studies. I first applied this label-free approach to a CPTAC project on formalin-fixed paraffin-embedded tissue (FFPE), which is the standard way tumor tissue is stored after being biopsied or surgically removed. Researchers can easily section these blocks to obtain and study tissue samples and follow disease progression. There are millions of FFPE blocks out there. Imagine the amount of data that we can get out of that, especially when combined with data about patient outcomes, diagnoses, and medications. We’ve designed a workflow that circumvents challenges with processing such samples. With this workflow, we can achieve an unprecedented depth of around 10,000 proteins with a turnaround time of almost 4 days from sample preparation to data generation for a 96-well plate of FFPE material. We plan to apply this workflow in our CPTAC study investigating lung adenocarcinoma. What’s your advice for aspiring scientists? Experiment with areas that interest you and you’ll narrow down what you’re truly passionate about. For me personally, doing research in undergrad was really helpful. It gave me an opportunity to think for myself in the lab and gave me an idea of what working in research would be like outside of school. When we say “science”, it doesn’t have to mean chemistry or biology; you might like something else. For example, even though I majored in biochemistry, I didn’t like the biology lectures. I was able to grasp biology better when chemistry got involved. Every person will have to look for these little clues to find what they enjoy in order to navigate their next steps. Go out and experiment. You have nothing to lose. 	proteins genomics biology spectrometry cancer biochemistry startup pharmaceutical mass biochemist broad news		2024-06-11											Claire Hendershot	268	0
Improved prime editing system makes gene-sized edits in human cells at therapeutic levels	Scientists at the Broad Institute of MIT and Harvard have improved a gene-editing technology that is now capable of inserting or substituting entire genes in the genome in human cells efficiently enough to be potentially useful for therapeutic applications. The advance, from the lab of Broad core institute member David Liu, could one day help researchers develop a single gene therapy for diseases such as cystic fibrosis that are caused by one of hundreds or thousands of different mutations in a gene. Using this new approach, they would insert a healthy copy of the gene at its native location in the genome, rather than having to create a different gene therapy to correct each mutation using other gene-editing approaches that make smaller edits. The new method uses a combination of prime editing, which can directly make a wide range of edits up to about 100 or 200 base pairs, and newly developed recombinase enzymes that efficiently insert large pieces of DNA thousands of base pairs in length at specific sites in the genome. This system, called eePASSIGE, can make gene-sized edits several times more efficiently than other similar methods, and is reported today in Nature Biomedical Engineering. “To our knowledge this is one of the first examples of programmable targeted gene integration in mammalian cells that satisfies the main criteria for potential therapeutic relevance,” said Liu, who is senior author of the study, the Richard Merkin Professor and director of the Merkin Institute of Transformative Technologies in Healthcare at the Broad, a professor at Harvard University and a Howard Hughes Medical Institute investigator. “At these efficiencies, we expect that many if not most loss-of-function genetic diseases could be ameliorated or rescued, if the efficiency we observe in cultured human cells can be translated into a clinical setting.” Graduate student Smriti Pandey and postdoctoral researcher Daniel Gao, both in Liu’s group, were co-first authors on the study, which was also a collaboration with Mark Osborn’s group at the University of Minnesota and Elliot Chaikof’s group at the Beth Israel Deaconess Medical Center. “This system offers promising opportunities for cell therapies where it can be used to precisely insert genes into cells outside of the body before administering them to patients to treat disease, among other applications,” Pandey said. “It’s exciting to see the high efficiency and versatility of eePASSIGE, which could enable a new category of genomic medicines,” added Gao. “We also hope that it will be a tool that scientists from across the research community can use to study basic biological questions.” Prime improvements Many scientists have used prime editing to efficiently install changes to DNA that are up to dozens of base pairs in length, sufficient to correct the vast majority of known pathogenic mutations. But introducing entire healthy genes, often thousands of base pairs long, in their native location in the genome has been a long-standing goal of the gene-editing field. Not only could this potentially treat many patients regardless of which mutation they have in a disease-causing gene, but it would also preserve the surrounding DNA sequences, which would increase the likelihood that the newly installed gene is properly regulated, rather than expressed too much, too little, or at the wrong time. In 2021, Liu’s lab reported a key step towards this goal and developed a prime editing approach called twinPE that installed recombinase “landing sites” in the genome, and then used natural recombinase enzymes such as Bxb1 to catalyze the insertion of new DNA into the prime edited target sites. The biotech company Prime Medicine, co-founded by Liu, soon began using this technology, which they called PASSIGE (prime-editing-assisted site-specific integrase gene editing), to develop treatments for genetic diseases. PASSIGE installs edits in only a modest fraction of cells, which is enough to treat some but probably not most genetic diseases that result from the loss of a functioning gene. So Liu’s team, in the new work reported today, set out to boost PASSIGE’s editing efficiency. They found that the recombinase enzyme Bxb1 was the culprit in limiting the efficiency of PASSIGE. They then used a tool previously developed by Liu’s group called PACE (phage-assisted continuous evolution) to rapidly evolve more efficient versions of Bxb1 in the lab. The resulting newly evolved and engineered Bxb1 variant (eeBxb1) improved the eePASSIGE method to integrate an average of 30 percent of gene-sized cargo in mouse and human cells, four times more than the original technique and about 16 times more than another recently published method called PASTE. “The eePASSIGE system provides a promising foundation for studies integrating healthy gene copies at sites of our choosing in cell and animal models of genetic diseases to treat loss-of-function disorders,” Liu said. “We hope this system will prove to be an important step towards realizing the benefits of targeted gene integration for patients.” With this goal in mind, Liu’s team is now working on combining eePASSIGE with delivery systems such as engineered virus-like particles (eVLPs) that may overcome hurdles that have traditionally limited therapeutic delivery of gene editors in the body. 	edits therapeutic editing gene biotech medicine harvard improved biomedical scientists broad news		2024-06-10											Allessandra DiCorato	269	0
Q&A: How to jump-start new psychiatric and neurological drug development	"Psychiatric and neurological disorders are widespread, yet the pace of drug development for these conditions lags far behind that of heart disease, cancer, and other conditions. Brain disorders are difficult to study and many drug candidates have failed in clinical trials, causing pharmaceutical companies to reduce their investments or even exit the field entirely. But a new path for bringing treatments to patients is starting to emerge. In a recent review in Science Translational Medicine, Steven Hyman, director of the Stanley Center for Psychiatric Research at the Broad Institute of MIT and Harvard, and colleagues in the National Academies of Science, Engineering, and Medicine (NASEM) Forum on Neuroscience and Nervous System Disorders — which includes industry — sketched out a six-point framework for re-invigorating psychiatric and neurological drug development that addresses many of the unique challenges this field faces. They wrote that a deeper understanding of the molecular mechanisms driving these disorders will improve diagnosis, enhance patient stratification in clinical trials, and lead to better therapeutics. To achieve this, the authors called for more genetics and longitudinal data types from patients of diverse ancestries, more data- and tool-sharing across sectors, the development of quantitative biomarkers for measuring disease mechanisms, and more. We asked Hyman, who is also a core institute member at Broad, to talk about the new framework and what he thinks are the biggest opportunities. The following conversation was edited for length and clarity. Why did you and your colleagues with the NASEM Forum decide to write this report? One of our long abiding concerns has been the pharmaceutical industry's progressive exit from R&D on treatments for central nervous system disorders apart from Alzheimer's and for large companies a nearly complete exit from new research in psychiatry. We all recognize the vast, unmet medical need. We have no treatments for the disabling cognitive and deficit symptoms of schizophrenia, and no pharmacologic treatments for the core communication difficulties of autism. We do very poorly at treating the depressed phase of bipolar disorder. And we have no pharmacologic treatments for anorexia nervosa, which at approximately 20 percent has the highest long-term mortality rate in psychiatry. So the need and the markets are there. The question becomes, under what circumstances would industry rebuild the infrastructure they need to re-engage in neuroscience and psychiatric development? What do you think it will take for industry to re-engage in this space? The single biggest problem for psychiatric disorders is that we lack the ability to look underneath the surface phenomena such as symptoms and disease course to group or stratify patients according to disease mechanisms. To use the example of depression, there have been many large, costly clinical trials in which drugs fail to separate convincingly from placebo but ultimately prove effective for a subset of patients. The key problem is that there appear to be many different underlying mechanisms that lead to depression. The genetic risk factors are highly complex, and they intersect with environmental risk factors ranging from infections to stress that are also diverse in their nature and effects (and which deserve intensive study). Without robust biomarkers, we cannot account for this mechanistic diversity and appropriately match patients with candidate treatments in clinical trials. Lumping everyone under this umbrella diagnosis of depression ignores the heterogeneous nature of this disorder, dilutes any signal that we might see in a clinical trial, and prevents us from learning from failures. Biomarkers could take many forms. Based on recent success in Alzheimer’s disease and amyotrophic lateral sclerosis, companies are very interested in quantifiable fluid biomarkers, which for neuroscience has meant markers that can be measured initially in CSF [cerebrospinal fluid]. Studies of Alzheimer's disease are teaching us that it's possible to measure some clinically important CSF biomarkers in blood. Some may even be measurable using positron emission tomography, which has the added benefit of providing information about where in the brain a biomarker is present. For some neurologic and psychiatric disorders, perhaps including depression and obsessive-compulsive symptoms, system-level biomarkers — ones that provide functional information about whole circuits instead of individual cells or molecules — appear promising. Thus magnetic resonance imaging or EEG studies may supplement molecular studies in ways that could prove to be highly useful in, for example, stratifying individuals with schizophrenia. At the Stanley Center, we are already gaining powerful evidence for this using EEG. Your review article discussed the need to study genetically diverse patient samples. Can you expand on that? Without a strong commitment to broadening the populations and societal contexts included in research, the promise of precision medicine rings rather hollow. It is becoming quite clear that even when disease mechanisms are alike across populations, polygenic scores and other genetic tools for risk prediction and stratification perform poorly across ancestries. The same may prove true for particular biomarkers. We cannot know — and cannot claim to be making equitable contributions to global public health — without significantly expanding the diversity of the populations we study. The Stanley Center has made it a central goal to increase population diversity in neuropsychiatric genetics l while increasing our sample sizes overall. There is both scientific benefit and a health equity imperative in looking across all of humanity. I see this as a moral necessity. How important will new animal models be? Industry is quite skeptical, and based on long experience rightly so, when it comes to the use of model systems for studying human psychiatric disorders. However, if we are to gain the most benefit from studies of genetics and neurobiology, diverse model systems — including animal models — are critical for investigating candidate disease mechanisms. Human stem cell-derived models and human brain organoids can help address questions arising from human genetics, especially ones related to human polygenic backgrounds. However, organoids are not brains. Animal models, carefully interpreted, are absolutely critical if we are to investigate relevant neurobiology and candidate disease mechanisms in living brains Where do industry and research institutes like the Stanley Center fit into your framework? Our foremost goal at the Stanley Center is to work both ""bottom-up"" from genetics up and ""top down"" from phenotypes and systems-level neuroscience to understand disease mechanisms. It's from an understanding of mechanisms that you have the best chance of identifying meaningful biomarkers and therapeutic targets. Academic centers, and certainly the Stanley Center, ultimately want to share the biomarkers that we discover with industry to ensure that these tools are robust and reliable enough for use in clinical trials. And of course industry has a huge role in optimizing compounds and, above all, in designing and running clinical trials that exceed the financial capacities and core capabilities of academic organizations. Do you think the roadmap you've laid out is something the players in the field will find realistic? There's a long way to travel, but it's not a Pollyanna-ish report. Following this path and breathing new life into treatment development is going to be a multi-sector effort. To meet the vast unmet needs of people with brain disorders, we must commit ourselves to moving forward. Thanks to the amazing discoveries that have come out of genetics over the last decade or so, basic research on psychiatric disorders has finally gained its first durable insights into disease mechanisms. There are now important translational opportunities, beginning with biomarkers. Let’s pursue these opportunities effectively and energetically. "	psychiatric schizophrenia cancer sclerosis drug psychiatry new development neurological broad news		2023-12-18											Tom Ulrich	270	0
Q&A: New approaches are needed to find better cancer drug targets	Tumors depend heavily on certain genetic changes to thrive, and researchers have discovered many such “genetic dependencies” as targets for potential new cancer drugs. At the Broad Institute of MIT and Harvard and elsewhere, researchers are also learning how dependencies affect cancer cells and how they influence each other and contribute to drug resistance. But the field needs fresh approaches to finding dependencies that could lead to new classes of more effective, even curative, cancer drugs, says Bill Sellers, who is director of the Broad’s Cancer Program. “We don't often think hard enough about how to get to cures in cancer,” said Sellers, who is also a core institute member at Broad and faculty member and senior advisor to the president for experimental therapeutics at Dana-Farber Cancer Institute. Since 2018, the Cancer Dependency Map (DepMap) Consortium, an academic-industrial partnership launched by the Broad, has uncovered several potential drug targets by systematically screening cancer models in search of genetic dependencies. As part of the Cancer Program at the Broad, the Sellers lab explores the link between genetic alterations and cancer dependencies with the goal of informing new therapies. Sellers sat down with us to talk about the limitations of current approaches in cancer dependency research and what is needed to move closer to cures. How have researchers looked for cancer dependencies in the past? For the most part, people have knocked out one gene at a time at the genome scale and asked, “What's the consequence of losing that gene's function for the growth of cancer?” Initially, there were two approaches: small hairpin RNA (shRNA)-based and now CRISPR-based experiments. There are a number of limitations to those approaches. First of all, they’re completely in vitro, so they don't take into consideration any of the factors that might be provided in the tumor microenvironment or the host. That’s been difficult to address. Cancer models are also a limitation. You can only do these studies if you have cell lines or models that can be manipulated in vitro at the genome scale. There are a whole host of cancers and cancer subtypes for which we don’t have many cell lines. For example, in prostate cancer, there are maybe three common cancer cell lines, even though it's one of the most common diseases. Usually people attempt to establish models by in vitro selection or by taking biopsies from patients, which is long and laborious. What new kinds of dependencies are you interested in? Over time, evidence has emerged for the idea of a Goldilocks zone for cancer — that tumors may need an optimal amount of signaling or “gas” to fuel their growth. To maintain this optimal signaling, cancers likely modulate gene activity by not just increasing but also decreasing gene expression. In a paper we published this September, we focused on the idea that cancers might be susceptible not just to loss of function of certain genes or gene products, i.e. having too little gas, but also gain of function, or too much gas. We’ve also been focusing on the limitation of studying one gene at a time when it's possible that two genes are performing a similar enough function. You’d need to disable both genes to see how important they are as a drug target. This is the case for highly related paralogs, which are genes with a common genetic ancestor and similar functions. A drug might need to target both paralogs to produce a therapeutic effect. We miss that combinatorial dependence in our current screens. A few years ago, we were building a CRISPR library targeting pairs of closely related genes and we thought we’d study NRAS-mutant melanoma. But we discovered two negative regulators [inhibitors of gene expression], DUSP4 and DUSP6. When they were both depleted, we saw ERK hyperactivation and loss of viability of the NRAS-mutant tumors. We found that cancers could be adversely affected both by inhibitors and activators of that pathway. Perhaps most exciting, Cory Johannessen (former Broad scientist, now at Novartis) took drug-resistant cells and looked for single-gene knockouts that were increasing in their dependency compared to the non-resistant cells. As the cells were becoming resistant, their dependency on negative regulators became higher and higher. This is quite exciting because most of the time, we're trying to create two drugs that have completely separate resistance mechanisms. But in this case, it looks like a first drug or inhibitor would elicit a mechanism of resistance that would increase the cancer’s dependency on the second druggable node. This would mean that for these two mechanisms, drug combinations could be given in cycles, sequentially, rather than together at the same time in order to exploit the nature of the evolution of the cancer. It suggests that we're missing this entire class of potential therapeutics. This is something we’re testing right now. Where do you think the search for genetic dependencies in cancer needs to go in the future, and what tools will that entail? In my first go-around I thought, “We're going to solve all of cancer in one fell swoop.” I think the reality is: Each new experimental approach that we take will solve some piece of the puzzle. Cancer is extraordinarily complex and difficult, and we have to tackle these in doable blocks. If we want to exploit gain-of-function, then we need to have gain-of-function perturbations. Right now we have CRISPR activation (CRISPRa), which turns on genes but not a mutated, activated form of the gene. That could be achieved potentially by something like CRISPR editing. The combinatorial problem is also extremely significant, especially if the reagents you use are not all validated. Having highly validated knockout reagents for every gene would help narrow down the number of reagents that you need to do effective combinatorial screens. What progress do you hope to see in this field in the next five years? We don't often think hard enough about how to get to cures in cancer. We know that it's going to require combination therapeutics, whether that’s combinations of inhibitors or sequential treatment with inhibitors and activators. In thinking about how to get there, a lot of our attempts don't really address the fundamental issue of resistance. I think this idea of taking drugs that we know work, deeply understanding how cancers develop resistance to those drugs, and rationally understanding the common functional consequences of these resistance mutations, is one of our best chances to get to combination therapies that have a chance at curing patients. 	biopsies cancers tumors cancer tumor drug new needed better broad news		2024-01-22											Allessandra DiCorato	271	0
Researchers engineer in vivo delivery system for prime editing, partially restoring vision in mice	Prime editing, a versatile form of gene editing that can correct most known disease-causing genetic mutations, now has a new vehicle to deliver its machinery into cells in living animals. A team of researchers at the Broad Institute of MIT and Harvard has engineered virus-like particles to deliver prime editors to cells in mice at a high enough efficiency to rescue a genetic disorder. In the new work published today in Nature Biotechnology, the team adapted engineered virus-like particles (eVLPs) that they had previously designed to carry base editors — another type of precision gene editor that makes single-letter changes in DNA. Now the researchers describe how they re-engineered both eVLPs and parts of the prime editing protein and RNA machinery to boost editing efficiency up to 170 times in human cells compared to the previous eVLPs that deliver base editors. The team used their new system to correct disease-causing mutations in the eyes of two mouse models of genetic blindness, partially restoring their vision. They also delivered prime editors to the mouse brain, and did not detect any off-target editing. “This study represents the first time to our knowledge that delivery of protein-RNA complexes has been used to achieve therapeutic prime editing in an animal,” said David Liu, senior author of the study and Richard Merkin Professor and director of the Merkin Institute of Transformative Technologies in Healthcare at the Broad. Liu is also a Howard Hughes Medical Institute investigator and a professor at Harvard University. Delivery dilemma Gene editing approaches promise to treat a range of diseases by precisely correcting genetic mutations that cause disease. Prime editing, described in 2019 by Liu’s group, can make longer and more diverse types of DNA changes than other types of editing. However, delivering the complex gene editing machinery to cells in living animals has been challenging. The prime editing system has three components: a Cas9 protein that can nick DNA; an engineered prime editing guide RNA (pegRNA) that specifies the location of the edit and also contains the new edited sequence to install at that location; and a reverse transcriptase that uses the pegRNA as a template to make specific changes to the DNA. Researchers have used a variety of methods to deliver these molecular machines to cells, including lipid nanoparticles and viruses. Virus-like particles (VLPs), composed of a shell of viral proteins that carry cargo but lack any viral genetic material, have also been of particular interest. But VLPs have traditionally yielded modest delivery outcomes in animals, and have to be specifically engineered for each different type of cargo to efficiently deliver to cells. “We initially hoped that we could just take the eVLPs that we had painstakingly developed and optimized for base editing and apply them to prime editors,” said Meirui An, a graduate student in the Liu lab and first author of the new paper. “But when we tried that, we observed almost no prime editing at all.” Bottleneck breakthroughs In the new work, the researchers extensively re-engineered both the eVLP proteins and the prime editing machinery itself so that both the delivery and editing systems worked more efficiently. For instance, they improved how the prime editing cargo was packaged in the eVLPs, how it was separated from the delivery vehicle, and how it was delivered into the target cells’ nuclei. “The prime editor cargo must be efficiently packaged into eVLPs when the particles form but must also be efficiently released from the particles after target cell entry,” said Aditya Raguram, a former Liu lab graduate student and co-author of the study. “All of these steps have to be carefully orchestrated in order to achieve efficient eVLP-mediated prime editing.” While each individual improvement led to small jumps in the efficiency of the prime editors, the changes together had a much larger impact. “When we combined everything together, we saw improvements of roughly 100-fold compared to the eVLPs that we started with,” said Liu. “That kind of improvement in efficiency should be enough to give us therapeutically relevant levels of prime editing, but we didn’t know for sure until we tested it in animals.” In vivo tests Liu and his colleagues, in collaboration with Krzysztof Palczewski of the University of California, Irvine, first tested the system in mice to correct two different genetic mutations in the eyes. One mutation, in the gene Mfrp, causes a disease called retinitis pigmentosa that leads to progressive retinal degeneration. The other, in the gene Rpe65, is associated with blindness seen in the condition known as Leber congenital amaurosis (LCA) in humans. In both instances, the eVLPs corrected the mutation in up to 20 percent of the animals’ retina cells, partially restoring their vision. The research group also showed that the eVLPs loaded with prime editing machinery could effectively edit genes in the brains of living mice. Nearly half of all cells in the cortex of the brain that received the editing machinery showed a gene edit. “The gene editing field largely agrees that, moving into the future, gene editing machinery should ultimately be delivered as proteins to minimize potential side effects and we’ve now shown an effective way to do that,” said Liu. “We plan to continue to actively work on improving eVLPs and adapting the technology to target other tissue types within the body.” 	researchers restoring editing lab engineer harvard transcriptase dna mice biotechnology broad news		2024-01-08											Sarah C.P. Williams	272	0
Evolved prime editors are smaller and more efficient for therapeutic applications	Prime editing technologies allow scientists to precisely edit the genome in a variety of ways and could one day be used to treat genetic diseases. Now researchers at the Broad Institute of MIT and Harvard have used cutting-edge continuous laboratory evolution and engineering methods to develop improved versions of the gene-editing tool. Their new editors are more efficient and specialized than previous versions, and are able to modify DNA in cultured cells and in animals that have been difficult to edit, including in immune system cells and inside the brain. The editing molecules are also smaller, potentially making it easier to deliver them into cells in key parts of the body as new disease treatments. Prime editing can make targeted insertions, deletions and other changes to DNA, and was first described in 2019 by the lab of David Liu, core institute member, Richard Merkin Professor, and director of the Merkin Institute of Transformative Technologies in Healthcare at the Broad Institute. The technique combines multiple molecular machines: a disabled Cas9 protein that can nick DNA; an engineered prime editing guide RNA (pegRNA) that both specifies the location of the edit and also contains new genetic instructions to install at that location; and an engineered version of an enzyme called reverse transcriptase that uses that RNA as a template to make specific changes to the DNA. In the past, Broad researchers have optimized the pegRNA and the way the cell responds to prime editing to boost editing efficiency. In the new work, they focused on improving the heart of the prime editing system—the reverse transcriptase. Their efforts have yielded a suite of new prime editors, each evolved in the lab to specialize in different editing tasks. In a paper published today in Cell, the team unveils the prime editing systems, dubbed PE6a through PE6g, each containing a new reverse transcriptase or Cas9 variant. The new prime editors are 2 to 20 times more efficient than previous ones, making them potentially more useful as therapeutics. The researchers are already using the PE6 editors in nearly all of their prime editing projects to edit a wide range of cell types, including in animals and in therapeutically relevant cultured cells. “We’re really excited to share these state-of-the-art prime editing tools with the community,” said Liu, who is also a professor at Harvard University and a Howard Hughes Medical Institute investigator. “We hope these new prime editors will become an integral part of the gene editing field, which has created so much promise and progress in the life sciences and in medicine.” Jordan Doman and Smriti Pandey, graduate students in the Liu lab, are co-first authors of the study. They note that this new study began in the summer of 2019, before the Liu lab even reported the first prime editing system. “The early days of this project focused on figuring out how this complicated molecular machine was working and what its preferences were. Then, more recently, we worked on turning this enhanced understanding into improved tools and potential therapeutics,” said Doman. Optimizing every component Prime editing promises to correct most disease-causing genetic mutations, but its efficiency can vary widely depending on the location and type of edit and on the type of cells being edited. In some cases, only a few percent of cells exposed to a prime editor end up with the desired genetic edit. To improve this efficiency for therapeutic applications, Liu’s team has focused on studying and improving every part of the complex prime editing system. “We had previously optimized every other component of the prime editing machinery,” Liu said. “What had not been done until now is improving the reverse transcriptase in a way that’s tailor-made for prime editing.” Reverse transcriptase proteins that copy RNA templates into strands of DNA are found naturally in all plant and animal cells and in many viruses. But naturally occurring reverse transcriptases generally result in poor prime editing efficiency, and researchers had not previously reported reverse transcriptases that consistently increase the editing efficiency of prime editors beyond that of the engineered reverse transcriptase used in the original prime editing system. To optimize the reverse transcriptase domain of prime editors in a more directed way, Liu’s group turned to PACE (phage-assisted continuous evolution), a directed evolution approach developed by Liu in 2011. The method involves growing a diversity of rapidly evolving bacteriophages — the viruses that infect bacteria — in laboratory “lagoons” that undergo continuous dilution. Only those expressing gene variants with specified desirable traits can survive by replicating faster than they are diluted. In the new work, the scientists developed a PACE system that imposed a Darwinian selection for bacteriophages that could carry out prime editing to correct a defective bacteriophage gene. Over hundreds of hours, the bacteriophages encoding the prime editors underwent thousands of generations of evolution, rapidly generating new reverse transcriptases that more efficiently make edits. Liu’s team challenged the PACE system with different types of prime editing tasks, such as inserting short or long stretches of DNA, and then tested the editors that survived. Surprisingly, the researchers found that evolved prime editors that improved editing efficiency in one task, such as adding or substituting just a few letters of DNA, performed poorly in other contexts, such as adding long stretches of DNA. “It turned out that PACE evolved these prime editors to specialize in exactly the kind of edits that we demanded they make during PACE,” Liu said. “But an editor that worked best for one edit didn’t work best for another. This discovery disproves the assumption that one type of prime editor can optimally perform any kind of prime edit.” Toward therapeutics As the team tested the PACE-evolved editors in different scenarios, they revealed a set of rules dictating when each of the seven prime editing systems should be used, and then did more experiments to demonstrate their utility. For example, they showed that some PE6 variants can insert longer stretches of DNA ranging from 38 to 108 base pairs long in five different places in the genomes of a human cell line, with increased editing efficiency compared to current prime editors. These PE6 variants performed especially well in settings that have been challenging for researchers to edit, such as the brains of live mice. “After years of optimization, we were excited to see PE6 variants expand the scope of prime editing,” said co-first author Pandey. “PE6 variants can particularly enhance editing at key therapeutically relevant sites that have been more challenging to target using previous systems.” In one experiment, the researchers were able to insert a long sequence of DNA into 40 percent of the cells in the cortex of a mouse brain — a 24-fold improvement over the previous state-of-the art prime editing system. “The difference between less than 2 percent editing efficiency and 40 percent editing efficiency can make the difference between something that’s an interesting research tool and something that can support a potential therapeutic application,” Liu said. The new prime editors are also more compact than previous versions, allowing the entire prime editing platform to fit into some delivery systems that previous prime editors struggled to fit into. The streamlined prime editors may be easier to deliver in animal models and, eventually, human patients. “The real litmus test of whether a technology is useful is whether people end up adopting it,” Liu said. “We’re excited to see how PE6 is applied to the prime editing field.” 	therapeutic evolved medicine smaller harvard prime transcriptase healthcare efficient scientists broad news		2023-08-31											Sarah C.P. Williams	273	0
Researchers reprogram gene therapy viral vectors to bind specific protein targets	Scientists have engineered adeno-associated viruses (AAVs) to package and deliver gene therapies to cells in the body. But the field has struggled to develop AAVs that can efficiently target different cell types and organs such as the brain, driving scientists to look for better ways of developing new viral vectors. A team of researchers at the Broad Institute of MIT and Harvard has built a more focused and efficient method of engineering AAVs. Previous methods introduce millions of AAV capsids — the outer shells of the virus that bind to target proteins — into animals and rely on iterative rounds of screening to find AAVs that reach specific cells. The new approach, developed by the lab of Ben Deverman, an institute scientist and senior director of vector engineering at Broad, instead looks for AAVs that bind to known proteins on the surface of target cells or organs. Using their method, the team found AAVs that bind to two proteins on the surface of cells that line blood vessels in the brain, allowing them to cross the blood-brain barrier in mice. The researchers’ approach, published today in PLOS Biology, could be used to engineer AAVs that target proteins on human cells, potentially accelerating the development of gene therapies. “This is a really nice demonstration that when we engineer AAVs by designing them to interact with certain proteins, we are better able to predict what their activity will be when they’re delivered in vivo,” Deverman said. Qin Huang, a senior research scientist in Deverman’s group, is the first author on the study. Protein binding Existing approaches to AAV engineering are not only labor-intensive but also don’t reveal how specific AAVs are able to reach specific cells, often resulting in AAVs that only work in certain species. “In vivo selection is quite straightforward, but mouse data doesn’t necessarily lead to something that will work in humans, which is a problem if you want to use it in gene therapy,” Huang said. 	researchers biology gene viruses viral harvard therapy protein scientists virus broad news		2023-07-19											Allessandra DiCorato	274	0
Base editing treats spinal muscular atrophy in mice	Researchers have used a gene-editing technique called base editing to restore motor function to near-normal levels in a mouse model of spinal muscular atrophy (SMA) — a disease that leads to paralysis and, in its most severe form, death before the age of two in humans. SMA occurs when cells in the spinal cord that control muscle movement, called motor neurons, die. Patients with the disorder have low levels of the SMN protein because they either have mutations in the SMN1 gene or are missing the gene entirely. The scientists, from the Broad Institute of MIT and Harvard, The Ohio State University Wexner Medical Center, and the University of Massachusetts Chan Medical School and led by David Liu, a core institute member at Broad, focused their strategy on editing a nearly identical gene, SMN2, because they wanted to develop a treatment that works for all patients. People with SMA can have different SMN1 mutations or lack SMN1, but they all have the SMN2 gene, which also produces the SMN protein. However, that protein is truncated and degrades quickly, resulting in SMN protein deficiency. In a study published today in Science, the team showed how they used base editing — a gene-editing technique developed by the Liu lab — to replace a single thymine (T) base in SMN2 with cytosine (C), effectively converting it into a functioning copy of SMN1. The strategy restored the SMN protein to normal levels, while also preserving the natural regulatory mechanisms that control the production of the protein. The scientists tested their approach in a mouse model of spinal muscular atrophy and found that animals that received a single treatment of both the gene-editing system and an FDA-approved SMA drug called nusinersen showed no significant difference in muscle strength, coordination, and physical activity levels compared to healthy mice. The treated mice also lived on average 6.5 times longer than untreated animals with the disease. The team compared their gene-editing approach with nusinersen and two other FDA-approved treatments for SMA and found that base editing increased motor function in mice similarly or more than each of the three existing drugs. However, the scientists discovered the most dramatic improvements when they combined the base-editing treatment with nusinersen. The results suggest that base editing might provide a one-time therapy for SMA and improve existing drug treatments. “The three FDA-approved drugs have revolutionized the treatment of SMA for thousands of patients,” said Liu, who is senior author on the study and also the Richard Merkin Professor and director of the Merkin Institute of Transformative Technologies in Healthcare at the Broad, as well as a Howard Hughes Medical Institute investigator and a professor at Harvard University. “But one of the real promises of precision gene-editing therapies is the possibility that a one-time treatment can provide a therapy for the lifetime of the patient.” Mandana Arbab, a postdoctoral fellow, and Zaneta Matuszek, a graduate student, both in Liu’s lab, are co-first authors on the study. They collaborated with a team from The Ohio State University Wexner Medical Center led by Arthur Burghes. “Base editing is a powerful tool to correct genetic diseases,” said Arbab, who was recently appointed as an assistant professor at Harvard Medical School and the Boston Children’s Hospital Translational Neuroscience Center. Her lab will focus on developing gene editing for SMA and other neurological diseases for the clinic. “Most drugs find ways to compensate for what has already gone wrong in a cell, but here we use base editing to stop SMA where it originates, in the DNA.” Gene fix Existing treatments for SMA, while effective, require multiple doses, do not fully restore SMN protein levels, subvert the natural regulatory mechanisms that control SMN production, may lose effectiveness over time, or may provoke an immune reaction upon repeated dosing. Liu’s team sought to develop a gene-editing approach targeting SMN2, which differs from SMN1 by only one base. The researchers thought that by editing SMN2, they could permanently restore levels of the normal SMN protein while maintaining normal cellular regulation of SMN expression. Using a combination of machine learning and experimental testing, the scientists evaluated 79 different nuclease-editing and base-editing strategies targeting different parts of the SMN2 gene and homed in on one that fully restored levels of the SMN protein with few editing byproducts and little editing elsewhere in the genome. The team ultimately chose an adenine base editor to convert the T•A base pair in the SMN2 gene to a C•G pair, effectively turning the gene into a healthy copy of the SMN1 gene. The treatment increased SMN protein levels 40-fold, restoring them to levels found in healthy cells. The team next used a pair of viruses commonly used in gene therapy called adeno associated viruses (AAVs) to deliver the base editor to the central nervous system in a mouse model of the disease. About 43 percent of spinal motor neurons received the AAV-delivered base editor cargo, and among those neurons, 87 percent showed conversion of SMN2 to SMN1. The animals receiving the base editor treatment retained their motor function and lived longer. By fully restoring SMN protein levels while preserving how they are regulated in cells, the team’s strategy might make treatment of SMA safer and more effective than other options in the long term, while eliminating the need for repeated dosing. Path to the clinic The researchers said that the striking improvements they observed in mice treated with both gene editing and the SMA drug nusinersen likely occurred because nusinersen extended the very short window of time when motor neurons can be rescued in the animals, allowing the base editor more time to convert SMN2 to SMN1. In patients, this window of opportunity is much longer — months rather than days in mice — and so Liu is hopeful that the treatment might be even more successful in humans. He added that since SMA patients would likely be taking an existing SMA drug before receiving any new experimental treatment, a combination therapy is a promising option for any future clinical trials that test gene editing for SMA. Liu also said that using prime editing, a versatile gene-editing method that had not yet been developed when his team chose the editing strategies in this study, may further improve gene editing for SMA in the future. In the meantime, Liu’s lab is developing a simpler single-AAV delivery system that could reduce the dose and simplify their treatment approach for SMA and progeria, a genetic condition that Liu’s lab and their collaborators have successfully treated with base editing in mice. Liu said they hope the improved delivery system could provide a path to clinical trials for these genetic diseases, as he and Arbab are working on for SMA. “There's still a huge amount of work to do,” he said. “But achieving a good understanding of how many different gene editing strategies each affect SMA is an important start to our no-stone-unturned approach to developing one-time treatments for SMA and other serious genetic diseases.” 	atrophy disease editing neuroscience base spinal mouse mice neurological broad news		2023-03-30											Allessandra DiCorato	275	0
Bacterial injection system delivers proteins in mice and human cells	Researchers at the Broad Institute of MIT and Harvard and the McGovern Institute for Brain Research at MIT have harnessed a natural bacterial system to develop a new protein delivery approach that works in human cells and animals. The technology, described today in Nature, can be programmed to deliver a variety of proteins, including ones for gene editing, to different cell types. The system could potentially be a safe and efficient way to deliver gene therapies and cancer therapies. Led by Broad core institute member and McGovern Institute investigator Feng Zhang, the team took advantage of a tiny syringe-like injection structure, produced by a bacterium, that naturally binds to insect cells and injects a protein payload into them. The researchers used the artificial intelligence tool AlphaFold to engineer these syringe structures to deliver a range of useful proteins to both human cells and cells in live mice. “This is a really beautiful example of how protein engineering can alter the biological activity of a natural system,” said Joseph Kreitz, the study’s first author and a graduate student in Zhang’s lab. “I think it substantiates protein engineering as a useful tool in bioengineering and the development of new therapeutic systems.” “Delivery of therapeutic molecules is a major bottleneck for medicine, and we will need a deep bench of options to get these powerful new therapies into the right cells in the body,” added Zhang. “By learning from how nature transports proteins, we were able to develop a new platform that can help address this gap.” Zhang is senior author on the study and is also the James and Patricia Poitras Professor of Neuroscience at MIT and an investigator at the Howard Hughes Medical Institute. Injection via contraction Symbiotic bacteria use the roughly 100-nanometer-long syringe-like machines to inject proteins into host cells to help adjust the biology of their surroundings and enhance their survival. These machines, called extracellular contractile injection systems (eCISs), consist of a rigid tube inside a sheath that contracts, driving a spike on the end of the tube through the cell membrane. This forces protein cargo inside the tube to enter the cell. On the outside of one end of the eCIS are tail fibers that recognize specific receptors on the cell surface and latch on. Previous research has shown that eCISs can naturally target insect and mouse cells, but Kreitz thought it might be possible to modify them to deliver proteins to human cells by reengineering the tail fibers to bind to different receptors. Using AlphaFold, which predicts a protein’s structure from its amino acid sequence, the researchers redesigned tail fibers of an eCIS produced by Photorhabdus bacteria to bind to human cells. By reengineering another part of the complex, the scientists tricked the syringe into delivering a protein of their choosing, in some cases with remarkably high efficiency. The team made eCISs that targeted cancer cells expressing the EGF receptor and showed that they killed almost 100 percent of the cells, but did not affect cells without the receptor. Though efficiency depends in part on the receptor the system is designed to target, Kreitz says that the findings demonstrate the promise of the system with thoughtful engineering. The researchers also used an eCIS to deliver proteins to the brain in live mice — where it didn’t provoke a detectable immune response, suggesting that eCISs could one day be used to safely deliver gene therapies to humans. Packaging proteins Kreitz says the eCIS system is versatile, and the team has already used it to deliver a range of cargos including base editor proteins (which can make single-letter changes to DNA), proteins that are toxic to cancer cells, and Cas9, a large DNA-cutting enzyme used in many gene editing systems. In the future, Kreitz says researchers could engineer other components of the eCIS system to tune other properties, or to deliver other cargos such as DNA or RNA. He also wants to better understand the function of these systems in nature. “We and others have shown that this type of system is incredibly diverse across the biosphere, but they are not very well characterized,” Kreitz said. “And we believe this type of system plays really important roles in biology that are yet to be explored.” 	proteins biology bacterium injection cells bacterial bioengineering bacteria mice broad news		2023-03-29											Allessandra DiCorato	276	0
Survey of brain cell junctions shows striking similarities between schizophrenia and bipolar disorder	Stanley Center for Psychiatric Research Proteomics Platform 	cell research psychiatric schizophrenia proteomics similarities bipolar disorder platform stanley broad news		2023-05-11											Leah Eisenstadt	277	0
Schizophrenia gene mutation causes many changes in the mouse brain  	Researchers have identified common and rare gene mutations that increase risk for schizophrenia. Yet it’s unclear what biological mechanisms go awry in the brain to cause psychosis and other disabling symptoms, due in part to a lack of valid animal models to study in the lab. Now, scientists in the Stanley Center for Psychiatric Research at the Broad Institute of MIT and Harvard and at MIT have taken a thorough, unbiased look at an animal model that carries a rare genetic mutation that greatly increases the risk of schizophrenia in humans. The researchers examined multiple brain regions and cell types in mice lacking the Grin2a gene, which encodes a type of glutamate receptor involved in communication between neurons. They observed wide-ranging changes in gene expression, brain cell activity, cell signaling, synapse protein composition, and animal behavior. Described in Neuron, the findings provide experimental evidence for two long-standing hypotheses that schizophrenia’s symptoms arise from altered signaling by glutamate and dopamine, two neurotransmitters in the brain. Additionally the Grin2a­-deficient mice had neurophysiological features resembling those observed in people with the disorder, including abnormal brain oscillations. The researchers say the mouse model is a valuable new resource that will enable researchers to further explore the disorder’s roots and probe for much-needed new therapeutic avenues. “Very little is known about the neurobiological mechanisms that underlie schizophrenia, so having an animal model with human-genetic validity and clear-cut brain abnormalities could be transformative for the field,” said study senior author Morgan Sheng, a core institute member at Broad, co-director of the Stanley Center for Psychiatric Research, and professor of neuroscience at MIT. “I find it remarkable that this animal model lacking a single gene can mimic multiple facets of schizophrenia, revealing new mechanistic insights into this disabling condition.” “Finally, we have an animal model with human-genetic validity and robust neurobiological overlap with human patients that can help scientists learn how existing treatments work and potentially help identify new ones,” said first author Zohreh Farsi, a staff scientist in the Sheng lab. “We hope others will utilize this rich data resource that we’ve shared for future mechanistic and therapeutics studies and to explore the roles of less studied mechanisms such as cholesterol dysregulation in schizophrenia pathophysiology.” New evidence for old hypotheses A 2022 landmark genetic study led by Broad and other researchers identified rare mutations in 10 genes that strongly increase risk of schizophrenia. One of these is the GRIN2A gene, which encodes a subunit of a protein complex called the NMDA receptor. This receptor binds to the neurotransmitter glutamate and scientists have long speculated that impaired glutamate signaling contributes to schizophrenia, but the biological role of the NMDA receptor in the disorder was still unclear. In the current study, Farsi, Sheng, and colleagues set out to systematically characterize the effects of the Grin2a mutation in mice. In humans, the mutation effectively breaks one copy of the gene (a mechanism they recently confirmed), so the team generated a so-called “heterozygous” mouse model in which one copy of the Grin2a gene is disrupted, leaving one working copy. The team took an unbiased, multidisciplinary approach to understand Grin2a’s effects. Their analysis revealed changes in the expression of a number of genes in different brain regions and at different ages in the mice, compared to mice with two working Grin2a copies and to those with none. “We were surprised to see that just missing one copy of this gene can induce many changes at the RNA level, at the protein level, at the functional level, and at the behavioral level,” said Farsi. The team also found changes in several biochemical pathways, including a reduction in glutamate signaling, which is consistent with the glutamate hypothesis of schizophrenia. Remarkably, their analysis also supported another long-standing hypothesis, centered on dopamine. Researchers have suspected that excessive dopamine signaling is partly to blame in schizophrenia, because medicines that block dopamine receptors are effective in reducing psychotic symptoms. In a brain region called the striatum, the team found evidence for unrestrained dopamine signaling, including a striking increase in expression of the dopamine receptor gene Drd2, which is the target of most antipsychotic drugs. The scientists also found reduced levels of an enzyme that degrades dopamine, providing further evidence for dopamine’s role in the disorder. One mutation, many changes To explore which cell types are involved, the researchers performed single nucleus RNA sequencing of different brain regions in Grin2a mutant mice, which revealed that in addition to neurons, other brain cells were affected in ways not frequently associated with schizophrenia. For example, genes related to cholesterol biosynthesis were more active in astrocytes in some brain regions. Changes in oligodendrocytes were also prominent, pointing to altered myelination, a mechanism often overlooked in studies of psychiatric disorders. At the brain network level, the researchers observed decreased activity of the prefrontal cortex and hyperactivity in the striatum and hippocampus, similar to what is seen in patients with schizophrenia, as well as abnormal locomotor patterns. “The Grin2a mutation has disparate (even opposite) effects on different parts of the brain, which is unpredicted,” said Sheng. “It illustrates the necessity of investigating gene-to-function at the level of the intact brain, to uncover systems-level effects like these that appear late in development.” The researchers say there is much more to learn from studying the Grin2a-mutant model. “We’ve only scratched the surface of insights we can glean using this model,” said Farsi. “By exploring how various antipsychotics work on Grin2a mutant mice, we might be able to tease apart the benefits of these drugs from the unwanted effects, so we can one day develop new drugs that specifically target the symptoms of this debilitating disorder.” Other researchers contributing to the work include Ally Nicollela, Sean Simmons, and Josh Levin of the Broad, who led the transcriptomic and single-nucleus RNA analysis; Sameer Aryal, Borislav Dejanovic, Hasmik Keshishian, and Steven Carr of the Broad, who led the proteomics experiments and analysis; and Robert Datta and Sherry Lin from Harvard Medical School, who analyzed behavioral measurements. 	psychiatric neurophysiological schizophrenia gene neuroscience mutation changes mouse psychotic broad news		2023-08-31											Leah Eisenstadt	278	0
Two large studies reveal genes and genome regions that influence schizophrenia risk	"In a landmark genetic study of more than 121,000 people, an international consortium called SCHEMA, led by researchers at the Broad Institute of MIT and Harvard, has identified extremely rare protein-disrupting mutations in 10 genes that strongly increase an individual's risk of developing schizophrenia — in one instance, by more than 20-fold. A second, complementary study in a larger but overlapping group of 320,400 people, conducted by the Psychiatric Genomics Consortium (PGC) and including the same Broad researchers, brings to 287 the number of regions of the genome associated with schizophrenia risk, including ones containing genes identified by SCHEMA. Together, these studies underscore an emerging view of schizophrenia as a breakdown in communication at the synapse (the junction between neurons), and illustrate how different kinds of genetic variation affecting the same genes can influence the risk for different psychiatric and neurodevelopmental disorders. The two studies appear together in the journal Nature. ""Psychiatric disorders have been a black box for a very long time. Unlike cardiovascular disease or cancer, we have had very few biological clues to disease mechanisms,"" said Tarjinder Singh, a postdoctoral fellow in the Stanley Center for Psychiatric Research at the Broad Institute. ""As a result, we have lacked the necessary insights for development of much needed new treatments. Instead we have been iterating on the antipsychotic drugs serendipitously discovered more than 70 years ago."" Singh, who is also in the Analytic and Translational Genetics Unit (ATGU) at Massachusetts General Hospital, is a collaborator on the PGC study, and a co-corresponding author of the SCHEMA study. ""Identifying these 10 genes is a watershed moment in schizophrenia research because each one of them provides a solid foundation for launching biological inquiry,"" said Benjamin Neale, another co-corresponding author on the SCHEMA study, a PGC collaborator, an institute member and director of genetics in the Stanley Center, co-director of the institute's Program in Medical and Population Genetics, and faculty of the Mass General ATGU. ""By sequencing the DNA of thousands of people, we are starting to see exactly which genes matter. These discoveries are the starting point for developing new therapies that treat the root cause of this devastating condition."" ""We've tried for years and years to gain this kind of traction on the biology of schizophrenia,"" said Broad core institute member and Stanley Center director Steven Hyman. ""Realistically, it will take yet more years to translate these results into biomarkers and treatments that will make a difference in the lives of people who are suffering with this devastating illness. But it is highly motivating to have a compelling path forward."" A global collection The SCHEMA and PGC findings are the fruit of a decade-long push led by researchers in the Stanley Center and nearly four dozen other institutions around the world. Both projects aim to gather and compare DNA from large numbers of people with and without schizophrenia. By working together, investigators across the PGC have built a dataset that now includes more than 320,400 people from collections across the world, including people of European, Finnish, African American, LatinX, East Asian, and Ashkenazi Jewish descent. The SCHEMA cohort comprises a subset of that, representing more than 121,000 people. The two groups have followed complementary paths in their study of schizophrenia genetics. Since 2009, the PGC team has conducted increasingly larger genome-wide association studies cataloging common genetic variations called single nucleotide polymorphisms (or SNPs) that contribute to schizophrenia risk. The SCHEMA (SCHizophrenia Exome Meta-Analysis) Consortium — which came together in 2017 — focuses on the exome, the nearly two-percent of the genome that encodes proteins. Specifically, the SCHEMA Consortium looked for variants that would either knock out or markedly alter a gene’s ability to produce functioning proteins. ""There's 10 years worth of data represented in these studies,"" said Sinéad Chapman, the director, global genetics project management in the Stanley Center who, along with team members Christine Stevens, Caroline Cusick, and many others, spent hundreds of hours ensuring that the samples and data from the SCHEMA collaborators were properly processed and tracked for these analyses. ""It was quite a manual process, as there isn't one magic system to connect all the samples and data and all of their related regulatory and clinical information."" According to Singh, these two studies were possible because the necessary pieces were finally in place. ""The genomic technologies, the sequencing infrastructure, the computational tools needed to understand the data they produce, have advanced dramatically in the last two decades,"" he said. ""The most important piece was the global commitment on the part of PGC and SCHEMA members to share samples and data across institutions and nations to achieve the numbers of people needed to bring these rare mutations to light."" A Manhattan plot of the SCHEMA findings. The red dots indicate genes with a significant relationship to schizophrenia risk. (Credit: Singh TJ et al.) Emerging convergence By sequencing whole exomes from 24,248 people with schizophrenia and 97,322 without, the SCHEMA team identified ultra-rare variants in 10 genes that dramatically increased a person's risk of developing schizophrenia. These variants, called PTVs for “protein truncating variants,” prevent cells from producing a gene’s full-length functional protein. ""In general, any given person has a roughly one percent chance of developing schizophrenia in their lifetime,"" said Neale. ""But if you have one of these mutations, it becomes a 10, 20, even 50 percent chance."" Their findings also hint at an additional 22 genes that also likely influence schizophrenia risk, and which may prove significant after further study. Data from the SCHEMA study are available at schema.broadinstitute.org. Together, these genes point to dysfunction at the synapse — where neurons connect and communicate with each other — as a possible cause of schizophrenia. This idea first emerged several years ago, thanks in part to a 2016 study from researchers at the Broad’s Stanley Center, Harvard Medical School, and Boston Children’s Hospital. In that study, they described for the first time how variations in a single gene — complement component 4, or C4 — raises schizophrenia risk by triggering excessive “pruning” of synapses. Insights into two of the 10 genes from the SCHEMA study, GRIN2A and GRIA3, further implicate the synapse as a key part of schizophrenia's mechanistic roots. These two genes encode portions of the glutamate receptor, a cellular antenna found at the synapse that allows neurons to receive chemical signals from neighboring neurons. Pharmacological studies have previously suggested that glutamate signaling may be involved in schizophrenia, but the SCHEMA study provides the first solid genetic evidence of this. Additionally, GRIN2A activity in the brain peaks during adolescence, around the time people suffering schizophrenia begin to experience symptoms. Most of the SCHEMA genes, however, have never before been associated with a brain disorder or neuron-specific functions. One gene (SETD1A) is involved in transcriptional regulation. Another (CUL1) helps the cell recycle old or unneeded proteins, while yet another (XPO7) helps chaperone molecules out of the cell's nucleus. Yet in the SCHEMA analysis, PTVs in these genes drive a 20- to 52-fold increase in schizophrenia risk. ""We don't yet have a well-developed framework for understanding how these genes might play a role in schizophrenia,"" said SCHEMA co-corresponding author and PGC collaborator Mark Daly, who is also an institute member in the Stanley Center, Mass General ATGU faculty, and director of the Institute for Molecular Medicine Finland at the University of Helsinki. ""These genes will ultimately lead to some new insights, but are going to require a lot of experimental follow-up to see where they might fit in the puzzle."" Separately, the PGC team examined common genetic variations in 76,755 people with schizophrenia and 243,649 without, finding 287 regions of the genome (or loci) as having some involvement in schizophrenia risk, an increase of 94 loci since the last PGC analysis released in 2019. With further analysis they identified 120 genes that potentially increase risk for schizophrenia. Several of these genes were also identified in the SCHEMA study. The PGC team also found that the genomic regions they implicated are largely active only in neurons, only in the brain, and affect mechanisms that directly impact neuron function, such as synaptic structure and organization. The nature and effect of the variants detected by PGC differed in some ways from the SCHEMA findings. For instance, the damaging protein-coding GRIN2A mutations SCHEMA identified are extremely rare and raise schizophrenia risk 24-fold. The variants found in the PGC study are far more common and change GRIN2A expression, increasing risk by only 1.06-fold. However, the fact that both studies' findings converge similar groups of genes and similar biological mechanisms suggests that genetic discoveries are beginning to home in on core aspects of schizophrenia biology, and are close to broader insights into the mechanisms underlying schizophrenia progression. ""Our hope was that we would end up with some amount of overlap in the stories that the common and rare variant associations were telling us,"" said Neale. ""And we see overlap pointing to a relationship between synaptic biology and schizophrenia risk."" Interactive chart displaying the impact and frequency of variants identified in the SCHEMA study (orange) and current and past PGC genome-wide association (GWAS) studies (blue). Hover over the named genes to learn more about them. (Adapted from Singh TJ et al.) Revelations into shared risk The SCHEMA data also shed light on how psychiatric and neurodevelopmental disorders more broadly can share genetic risk. For instance, several SCHEMA genes, including GRIN2A, have previously been implicated with neurodevelopmental conditions such as epilepsy, developmental delay, and intellectual disability. But by comparing their data from that of other large-scale studies, the SCHEMA team noted that the overlaps they saw were driven by different kinds of mutations: PTVs for schizophrenia, missense mutations (which can lead to amino acid swaps that modify a protein's activity) for the neurodevelopmental conditions. ""We see that a spectrum of consequences can arise from different kinds of mutation in the same genes,"" Neale noted. ""We have a lot more to do and a lot more to learn about what these genes do, what variations in these genes do, and what the biological consequences of genetic variation really are writ large."" ""This point is critical for gaining insight into how genetics works across brain disorders,"" Daly added. ""We need to make sure that we don't take a siloed view of these data, and instead remain open to learning what these genetics has to teach us across phenotypes."" And indeed, this perspective is already bearing fruit. In a separate study published in Nature Genetics, members of the international Bipolar Exome Consortium (BipEx), including Neale, report how comparisons of SCHEMA and BipEx data have helped reveal rare PTVs in the gene AKAP11 gene that raise the risk of bipolar disorder several-fold, making it the strongest genetic risk factor found for bipolar disorder to date. Fitting the puzzle pieces together Already a great deal of work is being done to model the effects of the SCHEMA mutations in the laboratory. Researchers also recognize that there are many additional genetic discoveries waiting to be found. ""These first 10 genes are really only the beginning of genetic discovery,"" Neale said. ""There is pretty clear evidence that there are many more genes to discover using the same kind of approach. But we fundamentally need bigger sample sizes to be able to reveal those additional genes. ""But, if you have more pieces of the puzzle,"" he continued, ""it might be a little bit easier to fit them together and come into a slightly more coherent mechanistic view of schizophrenia, and how we might start to approach those processes with the hope of improving patient's lives."" ""The biological complexity of schizophrenia is truly daunting, but this combination of rare protein altering variants from exome sequencing and common variants from GWAS have put us on our way to understanding the roots of that complexity,"" said Hyman. ""In these results, we may be seeing how synaptic abnormalities or losses begin in schizophrenia, giving us openings to diagnosing and treating people much earlier than we can today."" ""With schizophrenia, like with other complex disorders, I think we will ultimately find that many processes are involved in risk or protection,"" Daly added. ""Understanding that may turn out to be one of the most complex undertakings in genetics and biology."" Support for the SCHEMA study was provided by the National Institute of Mental Health, the National Human Genome Research Institute, the Stanley Family Foundation, Kent and Elizabeth Dauten, the Dalio Foundation, and other sources. Support for the PGC GWAS study was provided by the National Institute of Mental Health and other sources."	genomics schizophrenia large genome cancer harvard studies genes genetics dna broad news		2022-04-06											Tom Ulrich	279	0
Researchers find first strong genetic risk factor for bipolar disorder	The main treatment for bipolar disorder, lithium, was approved a half-century ago but doesn't help all patients and has significant side effects. Little progress has been made in finding better therapies, in part because scientists don’t fully understand how the condition arises or exactly how lithium improves symptoms when it does work. A genetic study involving thousands of people with bipolar disorder has revealed new insight into the condition’s molecular underpinnings. Led by scientists at the Stanley Center for Psychiatric Research at the Broad Institute of MIT and Harvard who collaborated with colleagues around the globe, the effort pinpoints a gene called AKAP11 as a strong risk factor for both bipolar disorder and schizophrenia. The findings may provide clues to how lithium works, as the AKAP-11 protein is known to interact with a molecular pathway modified by the drug. While many common genetic variants of small effects have been discovered, AKAP11 is the first gene found to have a large effect on bipolar disorder risk. This result has already kicked off new research at the Broad to further study the disorder in cells and animals, with a focus on molecular mechanisms that can in turn lead to identification of biomarkers to match patients with treatments and develop novel therapies. The study appears in Nature Genetics. “This work is exciting because it’s the first time we’ve had a gene with large-effect mutations for bipolar disorder,” said Steven Hyman, director of the Stanley Center for Psychiatric Research, a core member of the Broad, and Harvard University Distinguished Service Professor of Stem Cell and Regenerative Biology. “This is an important step towards the kind of research into disease mechanisms that, across the history of medicine, has underwritten successful therapeutics.” Big study, big effect Bipolar disorder is a severe, heritable mood disorder that affects approximately 1 percent of the population and often begins in early adulthood. A better understanding of the condition’s biological roots could lead to more effective therapies that can improve quality of life. Scientists in the Stanley Center partnered with colleagues around the world in the Bipolar Exome Consortium to identify rare differences in the DNA sequence that alter proteins with the hope of discovering ones with a large impact on disease risk. Although rare mutations may only occur in a minority of patients, the strong impact on disease risk means that they can illuminate the biological mechanisms involved in the condition. Those insights could one day lead to new ways of treating the disorder that improve symptoms in many people, even those without the rare mutation. The researchers began by comparing the exomes, or protein-coding portion of the genome, of roughly 14,000 people with bipolar disorder to 14,000 healthy controls. People with the condition were more likely to carry gene variants that result in abnormally truncated, dysfunctional proteins. Some of these variants were in genes already associated with risk for schizophrenia, another severe mental illness that often begins after adolescence. The team next incorporated results of a large-scale study conducted by the Schizophrenia Exome Sequencing Meta-analysis (SCHEMA) consortium. They combined the exome sequences of 24,000 people with schizophrenia who participated in the SCHEMA study with those of 14,000 people with bipolar disorder, and compared the genome sequence in those with the conditions to that of healthy controls. This analysis revealed rare protein-truncating variants in the AKAP11 gene that raise disease risk several-fold, making it the strongest genetic risk factor found for bipolar disorder to date. “The AKAP11 variants don’t contribute much to risk among the population as a whole, but the real value is what they reveal about the roots of disease, and that's why we're really focused on them,” said senior author Benjamin Neale, director of genetics for the Stanley Center and co-director of the Program in Medical and Population Genetics at the Broad, where he is also an institute member. Neale is also an associate professor in the Analytic and Translational Genetics Unit at Massachusetts General Hospital and an associate professor in medicine at Harvard Medical School, and he co-led the study with first author Duncan Palmer, a postdoctoral fellow in Neale’s lab. The protein product of AKAP11 interacts with another protein called GSK3B, a molecular target of lithium that is a potential mechanism of efficacy. Thus, the discovery offers intriguing clues to lithium’s effects in the body that may shed light on the action of lithium and lead to the identification of other therapeutic targets. New variants, new models To explore the molecular and behavioral effects of the AKAP11 gene variants uncovered in the study, Stanley Center researchers are now creating cellular and animal models carrying an altered form of the gene. The truncating variants effectively disable one copy of the gene in the genome, potentially cutting the abundance of the AKAP-11 protein in half. Models carrying genetic variants like these — and the protein alterations they produce — are easier to create in the lab than those with more common disease-related variants that occur in non-coding parts of the genome and that have unclear effects on protein function. For the first time, scientists will be able to employ research models harboring the same variants found to clearly increase risk in humans. The researchers are also exploring whether AKAP-11 or one of its molecular partners could serve as a biomarker for the condition, to aid in diagnosis or help ensure that future clinical trials include patients who are most likely to benefit from a particular therapy. The researchers and their colleagues aim to keep recruiting more patients with bipolar disorder for large-scale studies that could uncover still more genetic risk factors. “Ideally, we’d like to find risk variants across the whole genome, which will give us the very best chance of coming up with treatments for everyone,” said Hyman. “This is a first, and we're hoping we're going to find many more genetic factors. It's going to take a lot of exome sequencing, but it is very exciting.” This study was funded by generous support from the Stanley Family Foundation, Kent and Elizabeth Dauten, and The Dalio Foundation, in addition to funding from the National Institutes of Health.	researchers psychiatric schizophrenia lithium bipolar genetic disorder risk genetics broad news		2022-04-06											Leah Eisenstadt	280	0
First large genetic study of bipolar disorder in Asian populations launches	Nearly 60 percent of the world’s population resides in Asian countries, but only 10 percent of participants of genetic studies are of Asian descent. And that disparity is even greater in studies of psychiatric conditions, where participants are almost all of European ancestry, even though serious mental illness affects all human populations evenly. This lack of representation of the world’s population in genetic datasets leaves out a huge amount of genomic variation, limiting what scientists can learn about the biological basis of mental disorders. A global team of scientists is now trying to tackle this problem by launching a genetic study of bipolar disorder in people from India, Pakistan, Singapore, South Korea, and Taiwan. The study, called the Asian Bipolar Genetics Network (A-BIG-NET), will collect and analyze DNA and demographic, environmental, and medical information from 27,500 patients diagnosed with the psychiatric condition and 15,000 controls. The project is a collaboration between experts from the Broad Institute of MIT and Harvard (led by Hailiang Huang), Virginia Commonwealth University (led by Kenneth Kendler), Johns Hopkins University (led by Peter Zandi), National Institute of Mental Health and NeuroSciences in India (NIMHANS, led by Biju Viswanath), Indian Institute of Science (led by Bratati Kahali), Institute of Mental Health in Singapore (led by Jimmy Lee), Korea University College of Medicine (led by Heon-Jeong Lee), and National Taiwan University (led by Po-Hsiu Kuo). They will work together to recruit the participants, sequence the genomes, analyze the data, and build a network for rapid data-sharing. The team hopes to uncover genetic markers of bipolar disorder, which may point towards the biological causes and mechanisms underlying this condition that affects 1-2 percent of the world’s population. By focusing on Asian populations, the scientists aim to find markers that are more common in these groups than in others, which may highlight genetic roots of the disorder that are shared across other populations around the world. Better insight into the causes of bipolar disorder from this research could one day lead to new and better treatments. “There haven’t been any sizable bipolar genetic studies from Asian populations,” said Hailiang Huang, the project’s leader, Director of the Stanley Global Asia Initiatives at the Stanley Center for Psychiatric Research at the Broad, and an Assistant Professor at Massachusetts General Hospital and Harvard Medical School. “If this were to continue, we risk the possibility that therapeutic innovations might exclude large segments of the global population which are under-represented in psychiatric genetics. This is a major unsolved challenge for everyone in the world, including people from South and East Asia.” The new project extends Stanley Global, an initiative launched in 2014 by the Stanley Center to diversify genetic research and include underrepresented populations worldwide. One Stanley Global project, NeuroGAP-Psychosis, launched in 2018 to study the genetics of schizophrenia in four African countries, while another project, NeuroMex, is doing the same in Mexico. NeuroDev is studying neurodevelopmental differences in people in Kenya and South Africa. “Studies like A-BIG-NET have potential to discover rare variant risk genes, which should have a big impact on the mechanistic understanding of bipolar disorder, like the SCHEMA study did for schizophrenia. Because Asian populations have different genetic variants, their inclusion in A-BIG-NET will enhance the diversity and richness of gene discovery for bipolar,” said Morgan Sheng, co-director of the Stanley Center. Global partnerships A-BIG-NET was inspired by NeuroGAP-Psychosis and NeuroMex to expand this kind of genetics research to Asian countries. Though Stanley Global has sequenced genomic samples from East Asian populations before, A-BIG-NET expands that effort to include bipolar disorder and will study a much larger cohort. It will also be the first known large-scale study to explore the genetics of bipolar disorder in South Asian countries, and will build on recent discoveries from the Stanley Center including the first strong genetic signal for bipolar disorder. “The most important finding I would hope would emerge from this project is to find the direct causal genes underlying bipolar disorder,” Huang said. “This study gives us the chance to actually identify the causal genes for bipolar disorder in the Asian population.” “By taking a deep phenotyping approach, we will be collecting information which will allow us to explore a number of clinical subtypes of bipolar illness from a molecular genetic perspective to detect potential differences in their genetic substrate,” said Kendler, a Professor of Psychiatry and Human and Molecular Genetics at Virginia Commonwealth University and Co-Principal Investigator of the project. “Furthermore, studying a range of environmental risk factors will permit us to further clarify how genes and environment jointly act or interact to produce bipolar disorder.” “This study will be an important step in increasing equity in research, especially in the area of psychiatric genetics, ” said Biju Viswanath, Professor of Psychiatry at NIMHANS in India and the lead on the Indian arm of the study. Viswanath has established the India Consortium on Mental Illness And Genetics In the Clinic (IC-MAGIC), which conducts large genetic studies on mental health. Participants from India will make up the largest cohort of the study. “The project will allow advanced training in psychiatric genetics, and engage more researchers and participants. This will allow greater community engagement and expand research capacity in the region. We will then be able to contribute both globally, and importantly, locally to understand these complex disorders,” said Sanjeev Jain, a NIMHANS Professor and senior co-investigator of the study. About a third of A-BIG-NET’s genetic samples will be sequenced at the Broad by the Genomics Platform, with the rest being analyzed in their home countries. The scientists will use a recently developed sequencing technology called Blended Genome Exome (BGE), which deeply sequences the exome — the 2 percent of human DNA that translates into proteins — and more broadly decodes the rest of the genome. This approach was designed to increase the chances of finding new genetic variation from global samples in a cost-effective manner, allowing for a large number of samples to be sequenced. The team will publicly share A-BIG-NET data through the National Institute of Mental Health Data Archive (NDA) and the Bipolar Exomes Browser. They will also contribute their data to the Psychiatric Genomics Consortium Bipolar Workgroup and the Bipolar Sequencing Project, which will allow them to compare their results to those from other studies focused on European populations. “This study puts together a strong team from Asia to work at understanding the biology of bipolar disorder,” said Jimmy Lee, a Senior Consultant at Singapore’s Institute of Mental Health, an associate professor at the Lee Kong Chian School of Medicine at Nanyang Technological University, and a co-senior investigator of the study. “Singapore is glad to be a part of this coordinated effort. I am confident the team will make important and impactful scientific discoveries, which will eventually translate into improved clinical care and recovery outcomes in people living with bipolar disorder. Additionally, I hope this effort will catalyze the growth of psychiatric genetics in Asia to address the gap in ethnic representation and knowledge.” “Taiwan is often excluded from a number of major international organizations and actions. We’re very glad to be part of the global diversity initiative and to contribute to enhancing our understanding of a severe psychiatric disorder and reducing health inequity in the long run,” said the project’s co-lead, Po-Hsiu Kuo, Associate Dean of College of Public Health, and a Professor at Institute of Epidemiology and Preventive Medicine, National Taiwan University. “In South Korea, no large-scale genomic study has been conducted on mental illness. Recently, however, psychiatric genetic researchers have reached a consensus on the need for large-scale collaborative genomic study on major mental illnesses, and formed the Korean Mood Disorder Genomics Consortium (KOMOGEN) with about 40 organizations to move the team to succeed in the project,” said the South Korea site leader, Heon-Jeong Lee, Professor of Psychiatry, Korea University College of Medicine. Funding for this research is provided by the National Institute of Mental Health.	genomics schizophrenia launches large neurodevelopmental neurosciences bipolar genetic asian genetics broad news		2022-10-31											Alex Viveros	281	0
Study reveals how some bacterial infections become chronic	In the early 1900s, a cook named Mary Mallon, better known as “Typhoid Mary”, spread Salmonella Typhi, the causative agent of typhoid fever, to dozens of her patrons even though she showed no symptoms. Many people today harbor pathogenic Salmonella bacteria for years without feeling sick, making them potential sources of new infections. A new study by scientists at the Broad Institute of MIT and Harvard, along with colleagues at Tel Aviv University and the Sheba Medical Center in Israel, sheds light on the biological mechanisms that enable another kind of Salmonella to evade the immune system and cause long-term infections. The team focused on the “nontyphoidal” forms of Salmonella, which cause food-borne illness and, like the typhoidal form, can linger in the body long after the initial infection. By examining the genomes of bacteria collected from hundreds of people with persistent Salmonella infections, they discovered genetic mutations that both reduce the bacteria’s “virulence,” or ability to infect, and dampen the host’s immune responses, creating a kind of molecular camouflage that shields the bacteria from the immune system’s gaze. This insight could one day lead to new diagnostic approaches or treatments that prevent these infections from becoming chronic. The work appears in Cell Host & Microbe. “In our group, we aim to use Broad -omics technology to understand the drivers of persistent infections including the role of pathogen genetics in modulating how the host responds,” said Ashlee Earl, co-senior author on the study and director of the Bacterial Genomics Group at the Broad, where she is also an institute scientist. “In a large collection like this, the patients represent ‘natural experiments’ that we can observe in parallel to uncover the genetic changes in the pathogen underlying persistence.” Salmonella subterfuge To begin answering that question, the Earl group and the Broad’s Microbial Omics Core team led by co-senior author and institute scientist Jonathan Livny connected with the lab of Ohad Gal-Mor, an assistant professor at Tel Aviv University who is co-senior author on the new study. The Gal-Mor group had previously analyzed bacterial samples gathered from more than 48,000 people in Israel with salmonellosis between 1995 and 2012. By studying the samples, which had been collected periodically until each patient tested negative for the pathogen, they found that while most people cleared the infection after a week or so without treatment, roughly 2.2 percent of the cases became persistent infections that lingered for months to years. In the new study, the researchers examined samples from 256 patients in the collection whose infections lasted at least 30 days. They confirmed that most of the ​​cases were due to chronic infection by the same strain, rather than reinfection by different strains of the same bacteria. After analyzing the genomes of Salmonella in patient samples at various time points, the team highlighted mutations in two genes, barA and sirA, that arose in the bacteria repeatedly during chronic infection. These genes help regulate the activity of other genes, and further analysis suggested that mutations in these genes decrease the activity of a set of genes known as SPI-1 genes, which help Salmonella invade host cells. Animal experiments showed that the bacterial isolates carrying a barA or sirA mutation were less competitive than those lacking the mutations, indicating that the mutations reduced the bacteria’s ability to invade and replicate. To investigate the effect of the mutated genes on the host’s immune response, the researchers infected mouse immune cells called macrophages in a dish with Salmonella with barA or sirA mutations. They found that the mutated bacteria dampened the expression of the macrophage’s immune response genes, suggesting that the bacteria with misspelled barA or sirA genes provoked less of an immune response in the host. The scientists then wondered whether these less virulent bacteria would even be able to sustain an infection. They found that, during long-term infection, mice infected with the less virulent Salmonella shed similar amounts of bacteria in their feces and had similar levels of bacteria in their organs as animals carrying the non-mutated bacteria, indicating that the less-virulent Salmonella could still maintain an infection that could possibly be spread to other hosts. The mutated genes had different misspellings in different patients, suggesting that the bacteria evolve independently to lower the host immune response. “These results show us that the pathogen is evolving within the host and potentially adapting to chronic infection,” said first author Alexandra Grote, a postdoctoral fellow in the Bacterial Genomics Group at the Broad. “If we can better understand the pathways involved, it provides an exciting opportunity to develop new treatments or approaches to prevent the infections from becoming persistent.” Other Broad researchers contributing to the work include scientists in the Genomics Platform and Microbial ‘Omics Core. 	study infections salmonellosis salmonella reveals bacterial bacteria chronic scientists broad news		2024-01-19											Leah Eisenstadt	282	0
Battling antibiotic resistance in the lab and the clinic	"As a doctor in training at Massachusetts General Hospital (MGH) in the late 2000’s, Roby Bhattacharyya couldn’t stop thinking about some of the cases he saw. Patients with possible undiagnosed infections kept him up at night as he ran through their medical histories, occupations, and personal life details in his mind, searching for clues to the identity of the microscopic invaders. With the right diagnosis and antibiotics, a desperately sick patient could be feeling better in a couple of days. “The optimist in me loved that,” said Bhattacharyya. Yet, he learned, even the best medicine isn’t always enough. In some patients, seemingly treatable conditions like an ear infection or pneumonia can become life-threatening because of “superbugs” — bacteria that have evolved to evade medicine’s best defenses. In others, an infection can cause the immune system to spin out of control, leading to sepsis — organ dysfunction that lacks effective treatments and is often fatal. For some of these patients, Bhattacharyya and his colleagues would have to tell families, “Curing this infection no longer looks like a realistic option.” More bottles on the medicine shelf would help, but Bhattacharyya, who’s now also a research scientist, realized that science might lead to better tools for diagnosing and treating such challenging cases. “Every question that I've chosen to pursue in my lab today is deeply informed by what I’ve seen in the clinic,” he said. ""I focus my research on the crucial unknowns, the things I wish I knew as I was taking care of patients that would make a difference in how I'm practicing medicine."" In his lab at the Broad Institute of MIT and Harvard, he uses genomic technology to explore how bacteria become drug-resistant, to study how the immune system goes awry in sepsis, and to develop new molecular diagnostic approaches for bacterial infections. One of his main goals is to help physicians and patients better utilize antibiotics — one of medicine’s most precious resources — to slow down the evolution of drug-resistant strains. Bhattacharyya wears many coats today, splitting his time between the Broad and the infectious disease ward at MGH, where a diagnostic method he developed at Broad is now being tested to see if it helps patients quickly receive the best antibiotics for their infections. He has also emerged in recent years as a skilled and relatable science communicator, renowned for his efforts at Broad and beyond during the COVID-19 pandemic to unpack the fast-moving research on the new virus in an accessible way and give practical advice about masking, vaccines, and other public health measures. After contributing to the global medical and scientific response during the pandemic, Bhattacharyya shifted his focus back to his own research on a different public health problem that is still with us and keeps growing: antibiotic-resistant microbes. Driven by the misuse and overuse of antibiotics in humans, plants, and animals and exacerbated by the lack of new medicines in the development pipeline, antimicrobial resistance is a global problem that makes infections difficult to treat and makes medical procedures like surgery riskier. An analysis estimated that nearly 5 million deaths in 2019 were associated with bacterial resistance to antimicrobial medicines, including 1.27 million deaths attributed directly to resistant infections. And by 2050, up to 10 million people could die as a result of drug-resistant infections globally. “Antibiotic resistance is the big challenge of our generation in infectious disease medicine,” said Bhattacharyya, an associate member at the Broad Institute of MIT and Harvard, an assistant professor at Harvard Medical School, and an assistant professor in the Infectious Diseases Division of Massachusetts General Hospital Department of Medicine, where he is also an attending physician. “It’s been an inexorable march from antibiotics being these tremendously useful things a hundred years ago to things that are becoming more and more precious over time and losing their effectiveness,” he said. FROM STARS TO CELLS Bhattacharyya’s interest in science began not in the lab, but in the sky. As a fourth grade student in the Chicago suburb of Naperville, Illinois, he attended the Young Astronauts Club, an afterschool program centered around space exploration that first sparked his love for discovery. He spent many school breaks at Argonne National Laboratory where his parents both worked as scientists. He remembers reading, bouncing a tennis ball against the wall, and seeing a mix of creativity and hard work in the lab, a spirit that would later influence his own approach to scientific leadership. "	physicians lab surgery clinic antibiotic battling medicine resistance physician broad news		2024-01-30											Leah Eisenstadt	283	0
Several pre-existing RSV lineages powered the 2022 surge	Late last year, thousands of children across the United States were hospitalized with respiratory syncytial virus (RSV), but unlike previous RSV surges, this one affected a larger number of people and a broader range of age groups, including older children. As cases climbed faster and earlier in the season than in previous years, researchers wondered whether a fast-spreading RSV variant might be driving this unusual pattern of cases. To learn what was causing the upsurge, a team of scientists and clinical collaborators from Massachusetts General Hospital (MGH) and its outpatient practices in the greater Boston area began collecting specimens from patients diagnosed with RSV and sharing them with scientists at the Broad Institute of MIT and Harvard, who sequenced the viral genomes. They wanted to see if characteristics of the virus, such as the emergence of a new variant, contributed to the severity of the surge. Their analysis, initially released as a preprint on medRxiv and now published in the New England Journal of Medicine, revealed that multiple lineages of RSV, rather than a single, highly transmissible variant, drove the rapid rise in cases. The researchers also found that the lineages had been circulating well before the start of the pandemic. “What was really special about this study was how clear the finding was and how quickly we were able to do it. We were working with our colleagues at MGH within just a week or two of the surge beginning,” said Jacob Lemieux, an associate member of the Broad's Infectious Disease and Microbiome Program and a physician-investigator in the Division of Infectious Disease at MGH. Lemieux is co-senior author on the study along with Broad institute scientist Bronwyn MacInnis and institute member Pardis Sabeti. “When surges of infections arrive like this, we need to move quickly to get the genetic data from residual diagnostic samples to provide public health and clinical leaders with the intelligence that helps guide their response,” said MacInnis. “If we were looking at a highly transmissible or threatening variant of RSV underlying the surge, that would have changed the public health understanding and response to it.” Cross-country comparison At the time, the only other available RSV genomes from the fall 2022 surge, from patients in Seattle, had been sequenced by scientists at the University of Washington. The Broad team compared the viral genomes from Washington and Massachusetts and found similar genetic signatures and ancestry, revealing that the same lineages were driving the surge across the country. “I think we all were under the suspicion that there would be a single RSV variant underlying the surge, but when we built the phylogenetic tree, we saw that wasn't the case,” said Gage Moreno, a postdoctoral associate at the Broad and a co-first author on the study. “Within the phylogenetic clusters of closely related RSV sequences, there was significant genetic diversity, indicating that these lineages had been circulating–and evolving–for years prior to the COVID-19 pandemic,” said Brittany Petros, an MD-PhD student in the Sabeti lab and a co-first author on the study. “This finding further dispelled the notion that a novel RSV variant was underlying the surge.” Other co-first authors include MGH program manager Gordon Adams and clinical research coordinator Rockib Uddin. Scientists have proposed a few hypotheses to explain the spike in cases, which have less to do with the virus and more with the people it infects. A leading one suggests that personal protective behaviors during the COVID-19 pandemic, such as distancing and masking, may have reduced exposure and population immunity to RSV. Toddlers and other young children in particular, who commonly get infected with the virus, may have never been exposed to RSV in 2020 and 2021, and are interacting more now than during the height of the pandemic. Lemieux said it’s not clear whether this hypothesis is right, but added, “What we can say is that it was really surprising that multiple lineages were associated with this surge, and that it seems to be the case across the US.” The investigators are now studying the role of viral and host immunological factors in the spread of RSV to better understand the causes of the surge. 	surge medicine powered outpatient viral pandemic 2022 lineages rsv virus broad news		2023-02-22											Andrea Tamayo	284	0
Injectable agents could improve liquid biopsy for cancer detection and monitoring	Scientists have developed two agents, made of therapeutic nanoparticles and antibodies, that could be given to patients shortly before a blood draw to allow physicians to better detect tumor DNA in blood using a technology called liquid biopsy. Liquid biopsies promise to transform how cancers are diagnosed, monitored, and treated by detecting DNA that tumors shed into the blood. But the body presents a significant challenge. Immune cells in the liver and DNA-degrading enzymes in blood remove circulating tumor DNA from the bloodstream within minutes, making this DNA difficult to capture and detect in a blood test. To overcome this, a team from the Broad Institute of MIT and Harvard and Massachusetts Institute of Technology (MIT) have developed two injectable “priming agents” that briefly slow down the clearance of circulating tumor DNA from the body, allowing levels of this DNA to temporarily increase in blood and be collected for testing. The team says that these priming agents could improve the performance of liquid biopsies for cancer and potentially other diseases — akin to how contrast agents are given to patients to enhance medical imaging scans. Their findings are published in Science. Viktor Adalsteinsson, director of the Gerstner Center for Cancer Diagnostics at Broad, Sangeeta Bhatia, an institute member at Broad, a professor at MIT and director of the Marble Center for Cancer Nanomedicine at MIT’s Koch Institute, and J. Christopher Love, an associate member at Broad and a professor at MIT’s Koch Institute, are co-senior authors of the study. “Liquid biopsy stands to fundamentally change how cancer is diagnosed and treated but requires higher sensitivity,” said Adalsteinsson. “To improve sensitivity, we sought to address for the first time the biology of circulating tumor DNA clearance, recognizing this is a fundamental hurdle upstream of most liquid biopsy tests which, if solved, could broadly benefit patients.” One of the priming agents consists of nanoparticles, which, like circulating tumor DNA, are consumed by immune cells in the liver. “We thought we could design a safe dummy nanoparticle to distract those immune cells and leave the circulating tumor DNA alone so that it could be at a higher concentration in blood samples,” Bhatia said. The other agent comprises engineered antibodies that bind to tumor DNA, protecting them from destruction by circulating enzymes. Both strategies — therapeutic nanoparticles and antibodies — are already well-established forms of medicine for use in humans. “Existing liquid biopsy technologies are limited by the amount of tumor DNA you have in the tube of blood,” Love said. “So we started to think about how we might inject something beforehand to help boost or enhance that signal.” Carmen Martin-Alonso, a graduate student in Bhatia’s lab, spearheaded the design of the nanoparticles. Shervin Tabrizi, a postdoctoral associate in Love’s lab and the Gerstner Center at the Broad and a radiation oncologist at Massachusetts General Hospital, took the lead on engineering the antibodies. And Kan Xiong, a research scientist at the Gerstner Center at the Broad, led an effort to optimize the analysis of single droplets of mouse blood for circulating tumor DNA. In mouse studies, the team showed that administering these priming agents one to two hours before drawing a blood sample each increased the amount of circulating tumor DNA in a blood sample by more than 10-fold. This improved the sensitivity of detecting cancer by liquid biopsy in mice with low tumor burden from below 10 percent to more than 75 percent. Circulating tumor DNA levels in the animals returned to baseline within a day. “The ability to get peak activity of these agents within a couple of hours, followed by their rapid clearance, means that someone could go to their doctor's office, receive an agent like this, and then give their blood for the test itself, all within one visit,” Love said. “This feature bodes well for the potential to translate this concept into clinical use.” The team says their priming agents represent new platform technologies that could in principle enhance liquid biopsies not only for cancer but also for neurodegenerative diseases, metabolic disorders, deep-seeded infectious diseases, and prenatal genetic testing, as well as for the detection of other scarce analytes of clinical significance. “Boosting circulating tumor DNA in blood is just the tip of the iceberg,” Adalsteinsson said. “Priming is a new frontier we’re excited to further develop in cancer diagnostics and beyond.” 	biopsies improve nanomedicine medicine cancer monitoring detection biopsy broad news		2024-01-18											Kat J. McAlpine	285	0
Cancer immunotherapy candidate provokes powerful dual response in cancer and immune cells	Cancer immunotherapy drugs called PD-1 inhibitors are widely used to stimulate the immune system to fight cancer, but many patients either don’t respond or develop resistance to them. A new small-molecule drug candidate being tested in an early-stage clinical trial aims to improve patient responses to immunotherapy. Now scientists have shown, in a study published today in Nature, that the small molecule works through two different mechanisms to slow tumor growth and increase survival in lab animals. Researchers from the Tumor Immunotherapy Discovery Engine (TIDE) at the Broad Institute of MIT and Harvard, AbbVie, and Calico Life Sciences report that the molecule simultaneously makes tumors more sensitive to immune attack and boosts the activity of immune cells to fight tumors in mice. 	immunotherapy cells tumors cancer powerful immune scientists tumor broad news		2023-10-04											Allessandra DiCorato	286	0
A research team searches for every gene that helps tumors evade immunotherapy	In 2011, Robert Manguso was working in a cell biology lab when his mother was diagnosed with Merkel cell carcinoma, a rare and aggressive skin cancer. Manguso, who’d recently graduated from college and was conducting research at the University of Copenhagen as a Fulbright scholar, moved back to the Boston area to be with his mother as she underwent treatment. He also read everything he could about her disease, including emerging evidence that suggested that the immune system could recognize and kill Merkel cell carcinoma. His mother had a presentation of the disease that suggested her immune system was already on the job. But immunotherapy was not yet widely used and had not been applied clinically to Merkel cell carcinoma, so she received traditional chemotherapy and radiation therapy, suffering life-threatening complications along the way. Though the treatment eliminated her cancer, Manguso was struck by the promise of immunotherapy, which offered the potential to harness the immune system to fight cancer without the harsh side effects his mother had experienced. As he searched for graduate school programs that same year, Manguso decided to move away from his interest in fundamental cell biology and focus instead on cancer immunotherapy. “When I began my PhD I completely switched my focus, and I haven’t looked back,” said Manguso. “That’s the only thing I was interested in doing.” 	research immunotherapy biology gene searches tumors cancer chemotherapy carcinoma broad news		2023-10-11											Allessandra DiCorato	287	0
Lung cancer’s molecular features shed light on immunotherapy response	One of the newest types of cancer drugs, immunotherapies called immune checkpoint inhibitors, has transformed the treatment of lung cancer over the last decade — dramatically improving the survival of some patients with the most common form of this disease, non-small cell lung cancer (NSCLC). However, only about 20 percent of patients experience a benefit from these immunotherapies. A new study led by researchers at the Broad Institute of MIT and Harvard and Massachusetts General Hospital (MGH) reveals key molecular features of lung tumors that could explain why some patients respond to these treatments while others do not. The team has pinpointed several genetic and other biological factors that may influence the response of NSCLC patients to immunotherapies that inhibit the PD-1 or PD-L1 proteins. Published in Nature Genetics, this work is the first joint analysis of the Stand Up To Cancer-Mark Foundation cohort, a large dataset gathered through a multi-institution effort to expand the molecular understanding of treatment response in NSCLC. The research team examined whole-exome sequencing and RNA-sequencing data from tumor samples contributed by nearly 400 NSCLC patients before treatment, along with information about their clinical responses to anti-PD-(L)1 therapy. This is one of the largest multi-omic datasets from NSCLC patients who have been treated with these medicines, enabling the scientists to identify a suite of molecular features that are associated with improved treatment outcomes. These results demonstrate the complexity of the biological factors that determine immunotherapy response, and suggest why existing methods of predicting treatment outcomes in NSCLC patients, which look at only a small number of molecular features, aren’t always accurate. The researchers said their study points to the potential for improving these predictions or even developing more personalized approaches to treatment based on a patient's molecular profile. “Right now, long-term disease control is only achievable for some patients,” explains co-senior author Justin Gainor, director of the Center for Thoracic Cancers at MGH and associate professor at Harvard Medical School (HMS). “This analysis offers a deeper understanding of cancer and immunobiology, which we hope could be harnessed to make these treatments effective for a broader population. And as this collaboration continues to grow, it will further increase our understanding of the relevant molecular changes.” “This work also demonstrates the importance of collaborations that enable aggregating data from large cohorts of patients,” adds Gad Getz, an institute member at Broad and faculty at HMS and MGH. “Collectively, we aim for this richly annotated dataset to serve as a useful resource to the field at large, beyond our first analysis.” “We hope that the stratification of tumors by mutations and gene expression patterns will provide principles and mechanistic hypotheses underlying immunotherapy, and in this way, encourage specific mechanistic studies,” explains Nir Hacohen, institute member at Broad and director of the Center for Cancer Immunology at MGH. The work was additionally led by co-first authors Arvind Ravi, Matthew Hellmann, and Monica Arniella of the Broad Institute, Dana-Farber Cancer Institute, and Memorial Sloan Kettering Cancer Center. Building molecular profiles The PD-1/PD-L1 immune checkpoint is a protein interaction that normally suppresses the immune system. Cancer cells use this mechanism to evade the body’s defenses. Anti-PD-(L)1 agents work by blocking this interaction, stimulating the immune system to attack cancer cells. The research team set out to comprehensively profile this molecular landscape in patient samples. Among their findings, they identified specific genetic alterations that disabled the DNA-repair gene ATM and were associated with favorable responses to immunotherapy. They also found genomic changes that could increase expression of the TERT gene, which correlated with negative outcomes. And they identified another key predictor in the expression of genes that encode certain immunoproteasome subunits. By integrating the clinical, genomic, and transcriptomic data, the researchers uncovered two overall collections of features that correlated with a favorable treatment response: an “immune activated/exhausted” environment, in which the immune cells displayed signatures of previously high activity that had waned; and a signature defined by high levels of neoantigens, or foreign proteins displayed on the surface of the tumor cells. A third category — a “wound healing” microenvironment, in which the immune system appeared dampened, similar to how it would behave in the early stages of healing a physical injury — was associated with an unfavorable response to treatment. The team additionally identified a fourth “other” category, which had a mix of signatures correlating both positively and negatively with treatment outcomes. “These features could provide the ability to stratify patients in a more nuanced way,” explains Ravi. “We found that patients whom you would expect to respond well to therapy based on traditional predictors may actually respond poorly, due to the presence of additional unfavorable factors that are not usually assessed in routine clinical care. Understanding this complex architecture will continue to be critical as we investigate how to improve outcomes in all patients.” 	immunotherapy cancers cancer features immunotherapies lung molecular tumor immunobiology broad news		2023-04-18											Karen Zusi-Tran	288	0
Scientists use genetics to dig into a tumor’s past	Cancer Program 	dig cancer past genetics program scientists tumor broad news		2023-04-20											Leah Eisenstadt	289	0
How chromosome imbalances can drive cancer	The vast majority of cancer cells have too few or too many copies of some chromosomes, a state known as aneuploidy. But for decades, researchers have debated whether aneuploidy promotes the growth of cancers, or is simply a side effect of cancer cells’ fast growth. Such large-scale changes in DNA have been difficult to study. Now, researchers at the Broad Institute of MIT and Harvard and the Dana-Farber Cancer Institute have found — thanks to a computational tool they developed — that aneuploidy does drive cancer progression. Using that method, the scientists compared large chromosome changes in tumor cells from more than 10,000 cancer patients and identified key chromosome regions that, when duplicated or deleted, were harmful or beneficial to tumor cells. The work also revealed a new role for a known cancer gene called WRN — a result that, the team said, shows how this type of analysis can reveal new insight into cancer biology. The findings, published today in Nature, could lead to new ways of guiding cancer treatment or developing targeted drugs. “This study provides a computational answer, by directly using tumor samples from patients, to that age-old question of whether these large-scale events are really driving cancer or are just along for the ride,” said Rameen Beroukhim, a co-senior author of the study, associate member in the Cancer Program at the Broad, and an oncologist at Harvard Medical School, Dana-Farber Cancer Institute, and Brigham and Women’s Hospital. “We found that these aneuploidies are being directly selected for or against depending on their impact on cancer cells.” A common problem Most human cells contain 23 pairs of chromosomes, but in the late 19th century, scientists noticed that tumors often had cells with abnormal numbers of chromosomes. More recently, studies have shown that aneuploidies — which also include duplications or deletions of entire arms of chromosomes — are present in almost 90 percent of human cancers, often appear early in cancer, and are associated with worse clinical outcomes. Some researchers suspected that aneuploidies appeared because of the severe dysregulation of cancer cells and didn’t have any real impact on the cancer. Since the deleted or duplicated DNA regions involved in an aneuploidy can include hundreds or thousands of genes, pinning down any molecular mechanism by which an aneuploidy impacts tumor growth has been difficult. “We’ve known for more than a century that these aneuploidies were really prominent in cancer genomes, but we didn’t have great methods to study them,” said Alison Taylor, a co-senior author of the paper and a former postdoctoral research fellow at the Broad and Dana-Farber Cancer Institute who is now an assistant professor at Columbia University Medical Center. The long and the short To study aneuploidy in cancer, Beroukhim and Taylor, in collaboration with first author Juliann Shih and other colleagues, wondered whether they could take advantage of other, shorter types of chromosome changes in cancer cells and tease out what sections of chromosomes might play a role in tumor growth and survival. “There are large-scale changes that don’t quite fit the typical definition of an aneuploidy, but are still impacting a large part of a chromosome arm,” said Shih, previously an associate computational biologist at Broad and now an internal medicine resident at the Kirk Kerkorian School of Medicine at the University of Nevada, Las Vegas. “We began to think that these shorter events could give us signals about whether cancer cells were selecting for certain chromosome changes.” The team developed a method, dubbed BISCUT (Breakpoint Identification of Significant Cancer Undiscovered Targets), to analyze where large changes were most likely to begin or end in each chromosome. If the beginning and endpoints were in completely random spots, that would suggest that the aneuploidy had no direct impact on cancer cell survival. However, if a particular region was often included in a large-scale chromosome change, that would hint that the aneuploidy encompassing this area was helping cancer cells survive. Conversely, if a region was often excluded, that would suggest that the aneuploidy encompassing this area killed cancer cells or stunted their growth. The researchers used BISCUT to analyze 10,872 tumor samples from 33 cancer types, using data from The Cancer Genome Atlas (TCGA). The analysis revealed 193 regions within or near aneuploidies that cancer cells seemed to be selecting for or against. Less than half included known cancer genes. Beroukhim’s group also discovered that the frequencies of aneuploidies on different chromosomes were correlated with the predicted selection pressure on regions within the aneuploidies. “That was a pretty clear way of showing that selection seems to be the major driver of patterns of aneuploidies, and therefore that aneuploidies are having an impact on cancer cell survival,” Beroukhim said. Towards treatments In nearly one-third of all cancers in TCGA, one arm of chromosome 8 is missing, but researchers had never been sure why this aneuploidy is so common. The study showed that deletions on chromosome 8 were more likely to include the cancer gene WRN than other areas of DNA, suggesting that it has a particularly large impact. Certain cancer types are known to rely on WRN and drugs are already under development to block the gene. However, the new study showed a different role in up to a third of cancers, where a partial loss of the gene appears to help cancer cells survive. This observation could lead to new treatment approaches that selectively kill cancer cells harboring WRN loss, and to ways of identifying patients who will most likely benefit from these types of treatments. This kind of finding is one example of the dozens of insights that Beroukhim, Taylor, and Shih think their dataset will eventually lead to. Separate studies can delve into the mechanism behind each chromosome region identified by BISCUT. Many of the regions, they suspect, will point towards new drug targets or ways of screening cancer patients for the most effective treatment. “Our ability to address a centuries-old question is an example of how cancer research can make big leaps even in areas where it had seemed hopelessly stymied,” Beroukhim said. 	cancers tumors drive cancer chromosome imbalances scientists tumor broad news		2023-06-28											Sarah C.P. Williams	290	0
Three studies highlight how proteins are altered in multiple cancer types	Over the past two decades, scientists have shed light on the genetic mutations that drive cancer. More recently, they are focusing on proteins to understand the biological events in cancer cells that lead to disease. In three new studies, researchers including a team from the Broad Institute of MIT and Harvard have harmonized and analyzed data on proteins, DNA, RNA, as well as clinical data from more than 1,000 patients across nearly a dozen different cancer types. They discovered several ways in which proteins are involved in important cancer processes that are common across many cancer types. In one study published today in Cell, the scientists homed in on alterations that occur on proteins and change how they behave, called post-translational modifications (PTMs). The team found key modifications, such as the phosphorylation and acetylation of key proteins, that are associated with various biochemical pathways involved in cancer. A second Cell paper showed how certain mutations drive cancer by modifying the activity and regulation of key proteins. And the third study, published in Cancer Cell, describes the team’s efforts to harmonize and share the data with the research community. Together, the three papers could one day help scientists find new cancer drug targets and predict which tumors might respond better to treatment. The studies are part of a larger effort supported by the Clinical Proteomic Tumor Analysis Consortium (CPTAC) at the National Institutes of Health, which aims to integrate analysis of genes and proteins to learn about the molecular basis of cancer. “Most of biology operates at the level of proteins and their post-translational modifications,” said Gad Getz, a co-senior author on two of the studies and director of the Cancer Genome Computational Analysis Group and institute member at the Broad. “Because proteins and PTMs regulate so many signaling pathways that are activated or deactivated in cancer, they’re very important to study,” said Getz, who is also a professor of pathology at Harvard Medical School and the Paul C. Zamecnik Chair in Oncology at the Massachusetts General Hospital Cancer Center. To immerse themselves in the study of proteins, Getz’s team, along with multi-institutional collaborators, worked with Broad’s Proteomics Platform. The platform harmonized the proteomic data for downstream analyses, including for two of the current publications, using a pipeline developed by Karl Clauser, a principal research scientist in the platform and co-author on the papers. “The critical starting point in the integrated studies being reported now is generation of high-quality, deep-scale and quantitatively reliable proteome and PTMome data across tumor types,” said Steve Carr, a co-author on the studies and senior director of the Proteomics Platform. “With such data, studies like these can provide a valuable resource for obtaining new biological understanding of cancer.” Making sense of modifications In the manuscript focused on post-translational modifications (PTM), co-first author Yifat Geffen, a postdoctoral scholar in Getz’s lab, collaborated with the Proteomics Platform and other institutions to analyze genomic, transcriptomic, proteomic, and PTM data from 11 types of cancer. They then characterized 33 molecular signatures to group biologically similar tumors. With this approach, the team uncovered patterns in protein modifications linked to cancer-related processes such as DNA repair. The authors said these patterns would have been undetectable in smaller cohorts or by studying only genomic data. Phosphorylation, for instance, is a type of PTM that can indicate that a protein is active and hence a potential drug target. The researchers found that even cancers that share similar patterns of genetic mutations — such as colon and endometrial tumors that have similar genomic alterations in a DNA repair mechanism — can have different phosphorylation patterns, which could help explain why tumors with similar patterns of genetic mutations can respond differently to specific treatments. The researchers also found that tumors with reduced levels of acetylation on metabolic proteins were more likely to respond to immunotherapy. Geffen said that future work could translate these findings into better cancer diagnostics and treatments. “How post-translational modifications affect the function of proteins is underexplored,” she said. “This is a rich resource, and I’m excited to see everyone dive into the data to find mechanisms that we can potentially target with therapeutics.” What drivers do The second Cell study, led by Washington University in St. Louis researchers Li Ding and Yize Li with Getz as a co-senior author, used the same pan-cancer approach to focus on cancer “driver” mutations. Scientists know these genetic mutations drive the development of cancer, but don’t fully understand the molecular mechanisms behind the process. Figuring out these mechanisms could help researchers develop more effective drugs, including ones that work for more than one type of cancer. Ding’s team studied a range of features of more than 5,000 driver mutations such as their frequencies across different cancers and their impact on RNA, proteins, protein complexes, and PTMs. They found that certain genetic changes rewire the interactions between proteins. The team also uncovered pairs of genes that, when both are mutated, result in cancer cell death, and could be promising therapeutic targets. (Ding’s team also uncovered drivers of DNA methylation and studied their role in tumor development in a separate study.) Broadly, the researchers say that this kind of pan-cancer proteogenomic analysis has only just begun to connect biological features to their genetic roots, and these insights could one day help improve patient care. For instance, clinical trials using proteomics to study tumor samples from patients before and after treatment could reveal molecular mechanisms underlying drug resistance, and point towards more effective combination treatments. A new resource In the third study, a team led by Yize Li and Samuel Payne of Brigham Young University with Geffen as a co-first author, describes the challenges and solutions CPTAC researchers encountered as they integrated genomic, transcriptomic, proteomic, and clinical data from different cancer cohorts to create a single cohesive resource. The team, which includes the Getz lab, also provides several websites for scientists to interact with the data, and hope that their findings and guidelines will inspire other cancer researchers to use a similar approach in their own studies. “There’s a lot more to be done with this data, but the biggest thing for the community is the resource we’ve created and the availability of the data,” Getz said. “We hope this will be a useful example for how other kinds of studies can integrate genomic and proteomic data, and that this will be a rich dataset for many years to come.” 	proteins cancers biology altered multiple cancer studies dna scientists broad news		2023-08-14											Allessandra DiCorato	291	0
Some CRISPR screens may be missing cancer drug targets	CRISPR/Cas9 gene editing has made possible a multitude of biomedical experiments including studies that systematically turn off genes in cancer cells to look for ones that the cancer cells heavily depend on to survive and grow. These genes, or “cancer dependencies,” are often promising drug targets. But new research shows that many of these CRISPR screening experiments rely on components, called CRISPR/Cas9 guides, that do not perform equally well in cells from people of all ancestries, which can cause CRISPR screens to miss cancer dependencies. These CRISPR guides are short sequences of RNA that steer the CRISPR Cas9 enzyme to a specific site in the genome to cut DNA and deactivate a targeted gene. The new findings, from scientists at the Broad Institute of MIT and Harvard, show about 2 percent of these guides miss their target. This means that Cas9 won’t make a cut and disable a specific gene, thereby obscuring a potential role of that gene in cancer growth. The team found that this happens disproportionately in cells from people of African ancestry, because CRISPR guides were designed using reference genomes from people who are largely of European ancestry and do not fully represent global genetic diversity. “These inaccuracies exist in places we might not recognize and in ways that we wouldn't have predicted,” said Rameen Beroukhim, an associate member at the Broad and a co-senior author on the paper, which appeared recently in Nature Communications. “This work shows that it's really worthwhile to conduct a systematic assessment of all the tools and datasets that we're using so that we can fix these hidden biases before they become an issue.” “CRISPR is used ubiquitously in preclinical research, but only a minority of researchers are thinking carefully about the specific germline and ancestries that relate to their model systems,” added Jesse Boehm, an associated scientist at the Broad and a co-senior author on the paper. “This is a warning call for the community that functional genomics is not immune to ancestry bias, and a source of opportunity to look more closely at this kind of data.” In their study, the team analyzed data from the Broad’s Cancer Dependency Map (DepMap), the largest cancer dependency resource, which currently includes genome-wide screens in more than 1,000 cancer cell lines, about 90 percent of which are from people of European or East Asian descent. Francisca Vazquez, director of the DepMap at the Broad, said that less than 1 percent of cell line-guide pairs in the DepMap are affected by the ancestry bias shown by this study, but that these biases are important to recognize and fix in future libraries. After these results were first posted as a preprint in 2022, the DepMap team removed from their library all guide RNAs that didn’t work, so that instead of falsely returning no dependencies for the affected genes, the database indicates that there is not sufficient data to draw conclusions. A new kind of dependency search Previously, the search for cancer dependencies focused on genetic changes that arise in some cells during a person’s life, called somatic mutations. But when postdoctoral researcher and study first author Sean Misek joined Boehm’s and Beroukhim’s labs in 2020, he wanted to know how germline genetic variants — which are inherited and in all cells throughout the body — influence how tumors respond to treatment. Misek found many strong associations between ancestry and genetic dependencies, and that most of those associations came from artifacts related to germline variants. In particular, he saw these effects in CRISPR guides. The sequence of the guide RNAs didn’t sufficiently match the target genetic sequence because that target sequence varied depending on ancestry. The scientists found that 89 percent of guides in genome-scale libraries have a mismatch in at least one cell line. They also found that mismatches occur to a greater degree in cells from people of African ancestry. “These sorts of experimental biases are probably everywhere in preclinical research,” Misek said. “We hope that this paper is part of a larger conversation.” Understanding the extent of this bias in a research project can be challenging for a scientist because it can take several days to download all the necessary data to do so. To address this, Boehm, Beroukhim, and the Pattern team at the Broad built Ancestry Garden, a website based on data from the Genome Aggregation Database (gnomAD) that can help researchers determine the effect of ancestry on a guide of their choosing. “A lot of labs use CRISPR in some sense, and they should have a mechanism to check their reagents,” Misek said. “Our goal is to make it a little bit easier for people to mitigate this issue in their own hands.” Library lessons Boehm said that genetic variation due to ancestry affects research far beyond the search for cancer dependencies, and that the extent to which the team’s findings will impact individual studies will vary. Although the effect of this bias was relatively modest in the DepMap, it may be much larger in experiments that study only one or a small number of cell lines, Boehm said. Going forward, the study team and DepMap researchers say that an important way to address this bias is to increase the genetic diversity in large-scale cell line libraries. “We encourage the community to send us cell lines from under-represented populations if they have them,” Vazquez said. “This is a very important issue to address.” 	genomics screens tumors cancer crispr drug missing biomedical dna broad news		2024-06-14											Allessandra DiCorato	292	0
New gene delivery vehicle shows promise for human brain gene therapy	"In an important step toward more effective gene therapies for brain diseases, researchers from the Broad Institute of MIT and Harvard have engineered a gene-delivery vehicle that uses a human protein to efficiently cross the blood-brain barrier and deliver a disease-relevant gene to the brain in mice expressing the human protein. Because the vehicle binds to a well-studied protein in the blood-brain barrier, the scientists say it has a good chance at working in patients. Gene therapy could potentially treat a range of severe genetic brain disorders, which currently have no cures and few treatment options. But FDA-approved forms of the most commonly used vehicle for packaging and delivering these therapies to target cells, adeno-associated viruses (AAVs), aren’t able to efficiently cross the blood-brain barrier at high levels and deliver therapeutic cargo. The enormous challenge of getting therapies past this barrier — a highly selective membrane separating the blood from the brain — has stymied the development of safer and more effective gene therapies for brain diseases for decades. Now researchers in the lab of Ben Deverman, an institute scientist and senior director of vector engineering at the Broad, have engineered the first published AAV that targets a human protein to reach the brain in humanized mice. The AAV binds to the human transferrin receptor, which is highly expressed in the blood-brain barrier in humans. In a new study published today in Science, the team showed that their AAV, when injected into the bloodstream in mice expressing a humanized transferrin receptor, crossed into the brain at much higher levels than the AAV that is used in an FDA-approved gene therapy for the central nervous system, AAV9. It also reached a large fraction of important types of brain cells, including neurons and astrocytes. The researchers then showed that their AAV could deliver copies of the GBA1 gene, which has been linked to Gaucher’s disease, Lewy body dementia, and Parkinson’s disease, to a large fraction of cells throughout the brain. The scientists add that their new AAV could be a better option for treating neurodevelopmental disorders caused by mutations in a single gene such as Rett syndrome or SHANK3 deficiency; lysosomal storage diseases like GBA1 deficiency; and neurodegenerative diseases such as Huntington’s disease, prion disease, Friedreich’s ataxia, and single-gene forms of ALS and Parkinson’s disease. “Since we came to the Broad we’ve been focused on the mission of enabling gene therapies for the central nervous system,” said Deverman, senior author on the study. “If this AAV does what we think it will in humans based on our mouse studies, it will be so much more effective than current options.” “These AAVs have the potential to change a lot of patients’ lives,” said Ken Chan, a co-first author on the paper and group leader from Deverman’s group who has been working on solving gene delivery to the central nervous system for nearly a decade. Mechanism first For years, researchers developed AAVs for specific applications by preparing massive AAV libraries and testing them in animals to identify top candidates. But even when this approach succeeds, the candidates often don’t work in other species, and the approach doesn’t provide information about how the AAVs reach their targets. This can make it difficult to translate a gene therapy using these AAVs from animals to humans. To find a delivery vehicle with a greater chance of reaching the brain in people, Deverman’s team switched to a different approach. They used a method they published last year, which involves screening a library of AAVs in a test tube for ones that bind to a specific human protein. Then they test the most promising candidates in cells and mice that have been modified to express the protein. As their target, the researchers chose human transferrin receptor, which has long been the target of antibody-based therapies that aim to reach the brain. Several of these therapies have shown evidence of reaching the brain in humans. The team’s screening technique identified an AAV called BI-hTFR1 that binds human transferrin receptor, enters human brain cells, and bypasses a human cell model of the blood-brain barrier. “We’ve learned a lot from in vivo screens but it has been tough finding AAVs that worked this well across species,” added Qin Huang, a co-first author on the study and a senior research scientist in Deverman’s lab who helped develop the screening method to find AAVs that bind specific protein targets. “Finding one that works using a human receptor is a big step forward.” Beyond the dish To test the AAVs in animals, the researchers used mice in which the mouse gene that encodes the transferrin receptor was replaced with its human equivalent. The team injected the AAVs into the bloodstream of adult mice and found dramatically higher levels of the AAVs in the brain and spinal cord compared to mice without the human transferrin receptor gene, indicating that the receptor was actively ferrying the AAVs across the blood-brain barrier. The AAVs also showed 40-50 times higher accumulation in brain tissue than AAV9, which is part of an FDA-approved therapy for spinal muscular atrophy in infants but is relatively inefficient at delivering cargo to the adult brain. The new AAVs reached up to 71 percent of neurons and 92 percent of astrocytes in different regions of the brain. In work led by research scientist Jason Wu, Deverman’s team also used the AAVs to deliver healthy copies of the human GBA1 gene, which is mutated in several neurological conditions. The new AAVs delivered 30 times more copies of the GBA1 gene than AAV9 in mice and were delivered throughout the brain. The team said that the new AAVs are ideal for gene therapy because they target a human protein and have similar production and purification yields as AAV9 using scalable manufacturing methods. A biotech company co-founded by Deverman, Apertura Gene Therapy, is already developing new therapies using the AAVs to target the central nervous system. With more development, the scientists think it’s possible to improve the gene-delivery efficiency of their AAVs to the central nervous system, decrease their accumulation in the liver, and avoid inactivation by antibodies in some patients. Sonia Vallabh and Eric Minikel, two researchers at the Broad who are developing treatments for prion disease, are excited by the potential of the AAVs to deliver brain therapies in humans. ""When we think about gene therapy for a whole-brain disease like prion disease, you need really systemic delivery and broad biodistribution in order to achieve anything,"" said Minikel. ""Naturally occurring AAVs just aren't going to get you anywhere. This engineered capsid opens up a world of possibilities."" "	neurodegenerative gene biotech neurodevelopmental brain promise therapy new biodistribution scientists broad news		2024-05-16											Allessandra DiCorato	293	0
Merkin Prize in Biomedical Technology awarded to F. William Studier for development of widely used protein- and RNA-production platform	F. William Studier of Brookhaven National Laboratory has won the second annual Richard N. Merkin Prize in Biomedical Technology for his development of an efficient, scalable method of producing RNA and proteins in the laboratory. His T7 expression technology can be used to make large quantities of nearly any RNA or protein and has been for decades, and continues to be, a mainstay of biomedical research and pharmaceutical production. The approach has been used to produce numerous therapeutics, diagnostics, and vaccines — including the COVID-19 mRNA vaccines credited with extending millions of lives in recent years. “F. William Studier’s brilliant work on the T7 system transformed biomedicine, saving millions of lives globally and improving the chances for further research that will change healthcare delivery,” said Dr. Richard Merkin, CEO and Founder of Heritage Provider Network, one of the country’s largest physician-owned integrated health care systems. “His work exemplifies why I created this prize initiative that honors and showcases amazing innovators like Bill. I’m honored to be celebrating his remarkable achievements.” The Merkin Prize, which recognizes novel technologies that have improved human health, carries a $400,000 cash award and is administered by the Broad Institute of MIT and Harvard, one of the world’s leading biomedical research institutes. All nominations for the 2024 Merkin Prize were evaluated by a selection committee, composed of nine scientific leaders from academia and industry in the US and Europe. Studier will be honored in a prize ceremony held on September 17, 2024. 	technology 2024 biomedicine decades harvard protein biomedical prize rna broad news		2024-05-14											Broad Communications	294	0
Calico and Broad Institute extend collaboration, adding focus on age-related neurodegeneration	Calico Life Sciences LLC (Calico) and the Broad Institute of MIT and Harvard announced today that the two organizations have further extended their partnership with an added focus on age-related neurodegeneration. Initially announced in March 2015, this renewed agreement extends the collaboration until September 2029 and will continue to support ongoing programs focused on the biology and genetics of aging as well as early-stage drug discovery. Terms of the agreement were not disclosed. “We are pleased to continue our collaboration with the Broad Institute. It is entering its tenth year and we’ve made a considerable amount of progress, including discoveries that could make immunotherapies more effective for more patients. We are currently testing this approach in two early-stage clinical trials evaluating a pair of PTPN2 inhibitors,” said Arthur Levinson, founder and CEO of Calico. “With the expansion of our partnership to include age-related neurodegeneration, we are tackling a critical area of discovery that will allow us to access our collective expertise to advance an important area of research and clinical development.” “Renewing our commitment to this partnership with Calico reflects our shared goal of advancing transformative biomedical research and therapies for age-related diseases,” said Todd Golub, director and founding core member of the Broad Institute. “Since we initiated our partnership, we have seen tremendous advances across new technologies and analytic methods that are enabling the discovery of new biological insights into human disease that have immediate impact on drug discovery. We look forward to working with the Calico team to further our insights into how aging impacts the brain and neurological function.” 	biology extend neurodegeneration adding harvard collaboration biomedical genetics 2029 calico broad news		2024-05-09											Calico and Broad Communications	295	0
#WhyIScience Q&A: How a computational biologist balances work with life as an elite rower	As a child, Liz Martin was always active; she spent years dancing and figure skating and tried soccer and basketball. But no one sport stuck. When she entered high school, Martin’s parents encouraged her to find a team sport and — remembering boats gliding across the Charles River when they’d been students at MIT — suggested crew. Martin liked the sport and the feeling of working with a team and being on the water, but wasn’t yet sure she’d row after high school. She didn’t want a sport to conflict with her academics. But as an undergraduate at MIT, Martin found she could study biology and computer science and still row. In 2018, she graduated with a bachelor’s degree in computer science and biology and joined the lab of Gad Getz at the Broad Institute of MIT and Harvard to complete her master’s. Today, she is a senior associate computational biologist in the Getz lab, where she applies computational techniques to DNA and RNA sequencing data to analyze rapid autopsy samples, taken from multiple sites throughout the body at the time of a cancer patient’s death. She aims to better understand how cancers evolve during treatment and throughout a patient’s lifetime. When Martin started working at the Broad, she also joined the Riverside Boat Club in Cambridge, Massachusetts. She began putting in long hours on the river and by 2019 was competing internationally in the lightweight sculls category. She flew to places like Chile and the Czech Republic for competitions, bringing a laptop with her and working when she could, her labmates cheering her on from afar. In 2021, Martin competed in the US Olympic trials in a lightweight double, and won the world-renowned Head of the Charles regatta in lightweight single sculls. In 2022, she rowed in the world championships and finished second in her division. In 2023, she won a silver medal at the Pan-American Games in Chile. This year, she is training to qualify again for the world championships in August. This year will be the last year she will compete at the world level — she has decided to scale back her rowing to focus more on her scientific career, and 2024 will be the final year that Martin’s category, lightweight rowing, is offered at the Olympics. We talked to Martin about her interest in cancer biology and what it’s like to juggle time-intensive commitments in this #WhyIScience Q&A. 	regatta olympics labmates olympic elite rower life computational biologist broad news		2024-05-02											Allessandra DiCorato	296	0
Scientists work out the effects of exercise at the cellular level	The health benefits of exercise are well known but new research shows that the body’s response to exercise is more complex and far-reaching than previously thought. In a study on rats, a team of scientists from across the United States has found that physical activity causes many cellular and molecular changes in all 19 of the organs they studied in the animals. Exercise lowers the risk of many diseases, but scientists still don’t fully understand how exercise changes the body on a molecular level. Most studies have focused on a single organ, sex, or time point, and only include one or two data types. To take a more comprehensive look at the biology of exercise, scientists with the Molecular Transducers of Physical Activity Consortium (MoTrPAC) used an array of techniques in the lab to analyze molecular changes in rats as they were put through the paces of weeks of intense exercise. Their findings appear today in Nature. The team studied a range of tissues from the animals, such as the heart, brain, and lungs. They found that each of the organs they looked at changed with exercise, helping the body to regulate the immune system, respond to stress, and control pathways connected to inflammatory liver disease, heart disease, and tissue injury. The data provide potential clues into many different human health conditions; for example, the researchers found a possible explanation for why the liver becomes less fatty during exercise, which could help in the development of new treatments for non-alcoholic fatty liver disease. The team hopes that their findings could one day be used to tailor exercise to an individual’s health status or to develop treatments that mimic the effects of physical activity for people who are unable to exercise. They have already started studies on people to track the molecular effects of exercise. Launched in 2016, MoTrPAC draws together scientists from the Broad Institute of MIT and Harvard, Stanford University, the National Institutes of Health, and other institutions to shed light on the biological processes that underlie the health benefits of exercise. The Broad project was originally conceived of by Steve Carr, senior director of Broad’s Proteomics Platform; Clary Clish, senior director of Broad’s Metabolomics Platform; Robert Gerszten, a senior associate member at the Broad and chief of cardiovascular medicine at Beth Israel Deaconess Medical Center; and Christopher Newgard, a professor of nutrition at Duke University. Co-first authors on the study include Pierre Jean-Beltran, a postdoctoral researcher in Carr’s group at Broad when the study began, as well as David Amar and Nicole Gay of Stanford. Courtney Dennis and Julian Avila, both researchers in Clish’s group, were also co-authors on the manuscript. “It took a village of scientists with distinct scientific backgrounds to generate and integrate the massive amount of high quality data produced,” said Carr, a co-senior author of the study. “This is the first whole-organism map looking at the effects of training in multiple different organs. The resource produced will be enormously valuable, and has already produced many potentially novel biological insights for further exploration.” The team has made all of the animal data available in an online public repository. Other scientists can use this site to download, for example, information about the proteins changing in abundance in the lungs of female rats after eight weeks of regular exercise on a treadmill, or the RNA response to exercise in all organs of male and female rats over time. Whole-body analysis Conducting such a large and detailed study required a lot of planning. “The amount of coordination that all of the labs involved in this study had to do was phenomenal,” said Clish. In partnership with Sue Bodine at the Carver College of Medicine at the University of Iowa, whose group collected tissue samples from animals after up to eight weeks of training, other members of the MoTrPAC team divided the samples up so that each lab — Carr’s team analyzing proteins, Clish’s studying metabolites, and others — would examine virtually identical samples. “A lot of large-scale studies only focus on one or two data types,” said Natalie Clark, a computational scientist in Carr’s group. “But here we have a breadth of many different experiments on the same tissues, and that’s given us a global overview of how all of these different molecular layers contribute to exercise response.” In all, the teams performed nearly 10,000 assays to make about 15 million measurements on blood and 18 solid tissues. They found that exercise impacted thousands of molecules, with the most extreme changes in the adrenal gland, which produces hormones that regulate many important processes such as immunity, metabolism, and blood pressure. The researchers uncovered sex differences in several organs, particularly related to the immune response over time. Most immune-signaling molecules unique to females showed changes in levels between one and two weeks of training, whereas those in males showed differences between four and eight weeks. Some responses were consistent across sexes and organs. For example, the researchers found that heat-shock proteins, which are produced by cells in response to stress, were regulated in the same ways across different tissues. But other insights were tissue-specific. To their surprise, Carr’s team found an increase in acetylation of mitochondrial proteins involved in energy production, and in a phosphorylation signal that regulates energy storage, both in the liver that changed during exercise. These changes could help the liver become less fatty and less prone to disease with exercise, and could give researchers a target for future treatments of non-alcoholic fatty liver disease. “Even though the liver is not directly involved in exercise, it still undergoes changes that could improve health. No one speculated that we’d see these acetylation and phosphorylation changes in the liver after exercise training,” said Jean-Beltran. “This highlights why we deploy all of these different molecular modalities — exercise is a very complex process, and this is just the tip of the iceberg.” “Two or three generations of research associates matured on this consortium project and learned what it means to carefully design a study and process samples,” added Hasmik Keshishian, a senior group leader in Carr’s group and co-author of the study. “Now we are seeing the results of our work: biologically insightful findings that are yielding from the high quality data we and others have generated. That’s really fulfilling.” Other MoTrPAC papers published today include deeper dives into the response of fat and mitochondria in different tissues to exercise. Additional MoTrPAC studies are underway to study the effects of exercise on young adult and older rats, and the short-term effects of 30-minute bouts of physical activity. The consortium has also begun human studies, and are recruiting about 1,500 individuals of diverse ages, sexes, ancestries, and activity levels for a clinical trial to study the effects of both endurance and resistance exercise in children and adults. 	work biology medicine effects labs exercise medical cellular scientists broad news		2024-05-01											Allessandra DiCorato	297	0
A new viral surveillance system in West Africa is showing the world how to prevent the next pandemic	As night fell on July 20th, 2014, genomicist Christian Happi was at home with his family in Lagos, Nigeria when he received a phone call he would never forget. There was a suspected case of Ebola in Lagos: a diplomat who’d flown in from Liberia with a fever. Blood and urine samples from the man were waiting for Happi in his lab. Happi felt chilled. Lagos is Africa’s largest city, home to about 25 million people, with a busy seaport and airport. He started to imagine how the deadly and contagious disease, if confirmed, might spread to half the city’s population. Within an hour, Happi was in the car, speeding through the dark to his lab. By 6 am the following morning, he and his assistant had confirmed the first case of Ebola in Nigeria using a PCR test. Happi immediately contacted the Lagos State Ministry of Health and together, they began tracking down everyone who’d been on the patient’s flight. They identified 20 cases and isolated everyone who’d been exposed. Eight of the 20 patients died, but the spread of the disease in Nigeria stopped there. 	fever july viral pandemic surveillance ebola genomicist africa new liberia broad news		2024-04-25											Allessandra DiCorato	298	0
Scientists uncover 95 regions of the genome linked to PTSD	In posttraumatic stress disorder (PTSD), intrusive thoughts, changes in mood, and other symptoms after exposure to trauma can greatly impact a person’s quality of life. About 6 percent of people who experience trauma develop the disorder, but scientists don’t yet understand the neurobiology underlying PTSD. Now, a new genetic study of more than 1.2 million people has pinpointed 95 loci, or locations in the genome, that are associated with risk of developing PTSD, including 80 that had not been previously identified. The study, from the PTSD working group within the Psychiatric Genomics Consortium (PGC - PTSD) together with Cohen Veterans Bioscience, is the largest and most diverse of its kind, and also identified 43 genes that appear to have a role in causing PTSD. The work appears today in Nature Genetics. “This discovery firmly validates that heritability is a central feature of PTSD based on the largest PTSD genetics study conducted to date and reinforces there is a genetic component that contributes to the complexity of PTSD,” said Caroline Nievergelt, co-first and corresponding author on the study and a professor in the Department of Psychiatry at the University of California, San Diego. Adam Maihofer, a genetic epidemiologist in Nievergelt’s lab, was a co-first author as well. The findings both confirm previously discovered genetic underpinnings of PTSD and provide many novel targets for future investigation that could lead to new prevention and treatment strategies. “It's exciting that we see the exponential increase in loci with increases in sample size we see for other disorders,” said Karestan Koenen, senior author on the study, an institute member of the Broad Institute of MIT and Harvard, and an investigator with the Stanley Center for Psychiatric Research at Broad. Koenen leads the Stanley Center’s Biology of Trauma Initiative and the Global Neuropsychiatric Genomics Initiative, and is a professor of psychiatric epidemiology at Harvard T.H. Chan School of Public Health. “This is a milestone for PTSD genetics.” Genetic roots Previous twin and genetic studies, including an investigation by the same team in 2017 and an expanded study in 2019, showed that PTSD has a genetic component, and that many genes contribute to the condition. But these analyses pointed to different genetic loci across datasets, and many studies struggled to distinguish loci that were specific to PTSD risk from those that were also linked to conditions such as depression and cardiovascular disease. Genetic datasets have also historically focused on people of European ancestry, even though there is a disproportionately high burden of trauma and PTSD among people of African, Native American, and Latin American ancestry in the United States and globally. In the new study, Nievergelt, Koenen, and other researchers from the PGC compiled data from 88 different genome-wide association studies, which use genetic data from large groups of people to look for associations between regions of the genome and the chance of developing a condition or trait. In all, the dataset contained information about the risk of developing PTSD from more than 1.2 million individuals of European ancestry (including about 140,000 with PTSD), about 50,000 with African ancestry (including about 12,000 with PTSD), and about 7,000 with Native American ancestry (about 2,000 with PTSD). Meta-analysis of the data revealed 95 loci strongly associated with PTSD, including 80 that had not been identified previously. Forty three genes appeared to play a role in causing PTSD, including some that affect brain cells called neurons, brain chemicals called neurotransmitters, ion channels (which allow ions to pass in and out of cells), connections between neurons called synapses, and the endocrine and immune systems. The researchers found that PTSD shared many genetic features with depression, as well as several PTSD-specific loci. Although previous studies found a higher prevalence of PTSD in females than males, the researchers did not find evidence for this in their data. They examined the X chromosome, which earlier studies did not do, and found five loci linked with PTSD. But they add that these changes on the X chromosome would have similar effects in males and females. To more deeply probe how PTSD genetics affect the brain, the team studied gene expression data and found that the cerebellum, the brain region that controls movement and balance, may be involved in the disorder in addition to regions scientists have previously connected with PTSD, such as the cortex and amygdala. In particular, the research team found that interneurons, which connect motor and sensory neurons, were involved in PTSD risk. Future studies could help determine how key genes in these tissues and cells affect PTSD symptoms and behaviors. “For the first time, we are approaching a genetic architecture for PTSD, which both validates prior understanding of some of the critical biology underlying trauma-related disorders, while also pointing towards exciting and novel new targets and mechanisms,” said Kerry Ressler, a co-leader of the PGC - PTSD working group, chief scientific officer at McLean Hospital, and Professor of Psychiatry at Harvard Medical School. “These data are an important first step in next generation approaches to novel interventions for PTSD.” In line with previous findings, Nievergelt, Koenen, and their colleagues also found that polygenic scores — a calculation of a person’s genetic chance of developing a certain condition based on millions of single-letter changes in their DNA — for PTSD risk are not readily translatable across populations. The researchers say this disparity highlights the importance of continuing to expand the depth and diversity of populations included in future studies of PTSD. “We know that trauma and PTSD disproportionately affect under-resourced populations globally, particularly African ancestry populations,” said Koenen. “Our next steps will focus on addressing that inequity through partnerships with African scientists to make sure research in PTSD genetics benefits everyone equally.” 	psychiatric ptsd 95 genome psychiatry genetics scientists epidemiologist uncover broad news		2024-04-18											Allessandra DiCorato	299	0
Scientists link certain gut bacteria to lower heart disease risk	Changes in the gut microbiome have been implicated in a range of diseases including type 2 diabetes, obesity, and inflammatory bowel disease. Now, a team of researchers at the Broad Institute of MIT and Harvard along with Massachusetts General Hospital has found that microbes in the gut may affect cardiovascular disease as well. In a study published in Cell, the team has identified specific species of bacteria that consume cholesterol in the gut and may help lower cholesterol and heart disease risk in people. Members of Ramnik Xavier’s lab, Broad’s Metabolomics Platform, and collaborators analyzed metabolites and microbial genomes from more than 1,400 participants in the Framingham Heart Study, a decades-long project focused on risk factors for cardiovascular disease. The team discovered that bacteria called Oscillibacter take up and metabolize cholesterol from their surroundings, and that people carrying higher levels of the microbe in their gut had lower levels of cholesterol. They also identified the mechanism the bacteria likely use to break down cholesterol. The results suggest that interventions that manipulate the microbiome in specific ways could one day help decrease cholesterol in people. The findings also lay the groundwork for more targeted investigations of how changes to the microbiome affect health and disease. “Our research integrates findings from human subjects with experimental validation to ensure we achieve actionable mechanistic insight that will serve as starting points to improve cardiovascular health,” said Xavier, who is a core institute member, director of the Immunology Program, and co-director of the Infectious Disease and Microbiome Program at the Broad. He is also a professor at Harvard Medical School and Massachusetts General Hospital. Postdoctoral researcher Chenhao Li and research scientist Martin Stražar, both in Xavier’s lab, were co-first authors on the study. Cholesterol cues In the past decade, other researchers have uncovered links between composition of the gut microbiome and elements of cardiovascular disease, such as a person's triglycerides and blood sugar levels after a meal. But scientists haven’t been able to target those connections with therapies in part because they lack a complete understanding of metabolic pathways in the gut. In the new study, the Broad team gained a more complete and detailed picture of the impact of gut microbes on metabolism. They combined shotgun metagenomic sequencing, which profiles all of the microbial DNA in a sample, with metabolomics, which measures the levels of hundreds of known and thousands of unknown metabolites. They used these tools to study stool samples from the Framingham Heart Study. “The project outcomes underline the importance of high-quality, curated patient data,” Stražar said. “That allowed us to note effects that are really subtle and hard to measure and directly follow up on them.” The approach uncovered more than 16,000 associations between microbes and metabolic traits, including one that was particularly strong: People with several species of bacteria from the Oscillibacter genus had lower cholesterol levels than those who lacked the bacteria. The researchers found that species in the Oscillibacter genus were surprisingly abundant in the gut, representing on average 1 in every 100 bacteria. The researchers then wanted to figure out the biochemical pathway the microbes use to break down cholesterol. To do this, they first needed to grow the organism in the lab. Fortunately, the lab has spent years collecting bacteria from stool samples to create a unique library that also included Oscillibacter. After successfully growing the bacteria, the team used mass spectrometry to identify the most likely byproducts of cholesterol metabolism in the bacteria. This allowed them to determine the pathways the bacteria uses to lower cholesterol levels. They found that the bacteria converted cholesterol into intermediate products that can then be broken down by other bacteria and excreted from the body. Next, the team used machine-learning models to identify the candidate enzymes responsible for this biochemical conversion, and then detected those enzymes and cholesterol breakdown products specifically in certain Oscillibacter in the lab. The team found another gut bacterial species, Eubacterium coprostanoligenes, that also contributes to decreased cholesterol levels. This species carries a gene that the scientists had previously shown is involved in cholesterol metabolism. In the new work, the team discovered that Eubacterium might have a synergistic effect with Oscillibacter on cholesterol levels, which suggests that new experiments that study combinations of bacterial species could help shed light on how different microbial communities interact to affect human health. Microbial messages The vast majority of genes in the human gut microbiome remains uncharacterized, but the team is confident that their success in pinpointing cholesterol-metabolizing enzymes paves the way for the discovery of other similar metabolic pathways impacted by gut microbes, which could be targeted therapeutically. “There are many clinical studies trying to do fecal microbiome transfer studies without much understanding of how the microbes interact with each other and the gut,” Li said. “Hopefully stepping back by focusing on one particular bug or gene first, we’ll get a systematic understanding of gut ecology and come up with better therapeutic strategies like targeting one or a few bugs.” “Because of the large number of genes of unknown function in the gut microbiome, there are gaps in our ability to predict metabolic functions,” Li added. “Our work highlights the possibility that additional sterol metabolism pathways may be modified by gut microbes. There are potentially a lot of new discoveries to be made that will bring us closer to a mechanistic understanding of how microbes interact with the host.” 	immunology eubacterium lower oscillibacter heart bacteria diabetes scientists disease broad news		2024-04-02											Allessandra DiCorato	300	0
Ancient DNA reveals possible origin of a racial/ethnic disparity in a childhood cancer	"People who identify as Hispanic/Latino have the highest risk of a blood cancer called acute lymphoblastic leukemia (ALL) compared to other populations in the US, with 40 percent more Hispanic/Latino children being diagnosed than non-Hispanic white children. However, the basis for this difference is not well understood. Researchers have identified a genetic variant in people with Indigenous American ancestry that may account for the increased risk of ALL in Hispanic/Latino children, who have more of this ancestry than other populations. The team analyzed ancient DNA and traced the variant all the way back to the first people to enter the Americas about 13,000 years ago. ""We were able to use genetic studies in diverse populations to identify this new risk factor that explains some of the population differences in ALL risk,"" says Vijay Sankaran, a lead author of the study, a physician-scientist at the Dana-Farber/Boston Children’s Cancer and Blood Disorders Center, and an associate member in the Program in Medical and Population Genetics at the Broad Institute of MIT and Harvard. The findings were published in Cell Genomics and are the result of a close collaboration with colleagues at the University of Southern California. Sankaran and colleagues employed genome-wide association studies GWAS to look for genetic mutations contributing to racial/ethnic differences in a subtype of ALL that affects the development of immune cells called B cells. The team discovered that the genetic variant reduces the expression of a gene called IKZF1, which encodes for a protein, Ikaros, that is required for B cell development. The researchers also found that the mutation is much less common in white non-Hispanic/Latino children. Sankaran, postdoctoral fellow and first author Lara Wahlster, and their colleagues provide functional data that suggest the variant slows B cell maturation and, in turn, increases the chances of a cancerous mutation popping up in the cells. Self-identified Hispanic/Latino individuals in the United States are known to have diverse ancestral origins, including Indigenous American ancestry. The researchers found that this risk variant appeared to arise from Indigenous American ancestral origins and is nearly absent in people with predominantly European ancestry. This observation may explain the higher prevalence of ALL in some countries in Latin America, such as Mexico, where there is a greater contribution of Indigenous American ancestry, compared to countries like Argentina, where the contribution of that ancestry is much lower. The researchers then analyzed ancient DNA samples to understand when the risk variant arose in human history. The oldest previously sequenced ancient DNA from an Indigenous American individual, found at the Anzick site in Montana, carried the mutation. This means the risk variant was present among the first people who entered the Americas approximately 13,000 years ago. Further investigation revealed that the variant was promoted by natural selection. Sankaran and colleagues speculated that carrying the mutation may have protected people against infection since IKZF1 plays a role in immune function. ""Exploring ancient DNA provides insights into the roots of modern-day health differences, bridging the gap between our past and the pressing health challenges facing our society today,"" says Sankaran. The study's findings may provide insights into the higher rates of treatment resistance and relapse observed in Hispanic/Latino children with ALL. Sankaran emphasizes the need for further research to gain a comprehensive understanding of the implications of this variant. Ultimately, Sankaran hopes this knowledge may lead to ways of preventing leukemia in children carrying the identified genetic variant. ""I hope our work will ultimately pave the path towards preventing this disease,"" says Sankaran. Adapted from a press release issued by Dana-Farber/Boston Children's Cancer and Blood Disorder Center. "	racial ethnic cancerous leukemia cancer ancient hispanic genetics dna broad news		2024-03-26											Gina Mantica, Dana-Farber/Boston Children's Cancer and Blood Disorders Center	301	0
#WhyIScience Q&A: A cell biologist now helps recent college graduates launch their scientific careers	Alex Navarro didn’t always aspire to a career in science. Growing up in El Paso, Texas, as the daughter of Mexican immigrants, she never envisioned herself pursuing an advanced degree. Then, while watching the news one evening with her family, she was fascinated by a segment featuring primatologist Jane Goodall and her efforts to study the behavior of chimpanzees in the Congo. Navarro was inspired as she realized, for the first time, that it’s possible to have a career observing nature and asking questions. Navarro later became the first in her family to attend a four-year college, earning her degree in microbiology from the University of Texas at El Paso, followed by a stint doing research at Novartis in Cambridge, MA, and then graduate studies at MIT to earn her Ph.D. in cell biology. Now at the Broad Institute of MIT and Harvard, Navarro helps young researchers envision their own paths to a scientific career as the senior program coordinator for the Broad Biomedical Post-baccalaureate Scholars (BBPS) program, run by the Office for STEM Engagement and Inclusion. The two-year program provides recent college graduates, especially those from backgrounds underrepresented in the sciences or those dedicated to addressing inequalities in STEM, with support and guidance as they begin their first professional research positions at the Broad and prepare for graduate school in STEM fields. Having navigated that road herself, Navarro serves as the participants’ advisor, guide, and advocate, drawing from her own experiences to help them pursue their goals. 	graduates college biology daughter texas harvard mexican careers scientific biologist broad news		2024-03-25											Leah Eisenstadt	302	0
Messenger RNAs with multiple “tails” could lead to more effective therapeutics	Messenger RNA (mRNA) made its big leap into the public limelight during the pandemic, thanks to its cornerstone role in several COVID-19 vaccines. But mRNAs, which are genetic sequences that instruct the body to produce proteins, are also being developed as a new class of drugs. For mRNAs to have broad therapeutic uses, however, the molecules will need to last longer in the body than those that make up the COVID vaccines. Researchers from the Broad Institute of MIT and Harvard and MIT have engineered a new mRNA structure by adding multiple “tails” to the molecules that boosted mRNA activity levels in cells by 5 to 20 times. The team also showed that their multi-tailed mRNAs lasted 2 to 3 times longer in animals compared to unmodified mRNA, and when incorporated into a CRISPR gene-editing system, resulted in more efficient gene editing in mice. The new mRNAs, reported in Nature Biotechnology, could potentially be used to treat diseases that require long-lasting treatments that edit genes or replace faulty proteins. “The use of mRNA in COVID vaccines is fantastic, which prompted us to explore how we could expand the possible therapeutic applications for mRNA,” said Xiao Wang, senior author of the new paper, a core institute member at the Broad and an assistant professor of chemistry at MIT. “We’ve shown that non-natural structures can function so much better than naturally occurring ones. This research has given us a lot of confidence in our ability to modify mRNA molecules chemically and topologically.” “I’m most excited by the fact that this new shape of mRNA is so well tolerated by cellular translation machinery,” said Hongyu Chen, first author of the paper and a graduate student from MIT Chemistry in Wang’s lab. “This opens up many new opportunities for synthetically modifying mRNA to extend its therapeutic uses.” Staying power The mRNA in today’s COVID vaccines is so effective because very little is needed – once injected into the body, it stimulates the production of proteins that resemble parts of the COVID virus. “The immune system is very robust, so it’s able to create many antibodies in response to transient expression of a foreign protein,” Chen said. But for that same type of mRNA to produce enough proteins to treat diseases that disrupt normal production of essential proteins, a much larger dose would be needed, which could cause toxic side effects. Wang’s lab specializes in understanding how RNA works from the time of its synthesis all the way through to its final degradation and disposal in cells. Wang, Chen, and their team wanted to take on the complex challenge of designing an mRNA structure that could be stable, active, and produce sustained therapeutic effects in low doses. “I find mRNA very fascinating because as an informational molecule, its function is encoded by its sequence, while its stability is dictated by the chemical properties of its backbone,” Chen said. “This feature gives chemists the versatility to extensively engineer the mRNA structure without worrying about changing the information it carries.” Based on previous research, Wang and Chen knew that one part of mRNA’s structure, a branch called the poly(A) tail, plays an important role in protecting mRNA from degradation inside cells. In 2022, they showed that chemically modifying the poly(A) tail slows down the natural decay of mRNA, rendering it more useful for a wider range of therapies. They named those modified molecules “mRNA-oligo conjugates” or mocRNAs. To build on this work, Wang and Chen hypothesized that engineering an even more complex shape of mRNA, containing multiple modified tails of poly(A), would enhance therapeutic effects of mRNA even more. In their latest effort, the team made their multi-tailed mRNAs, tested them in human cells, and found that they sustained mRNA translation much longer than both natural mRNA and mocRNA, producing up to 20 times more proteins per dose over time. In mouse experiments, the researchers discovered that just one dose of multi-tailed mRNA led to protein production that lasted as long as 14 days – nearly double the lifetime demonstrated by previous mRNA technologies. They also used their multi-tailed mRNA to encode the DNA-cutting Cas9 protein as part of the CRISPR-Cas9 gene-editing system and tested that in mice to edit genes linked to high cholesterol, Pcsk9 and Angptl3. They found that just a single dose of multi-tailed Cas9 mRNA could induce higher levels of gene editing, resulting in decreased cholesterol circulating in the bloodstream, compared to animals treated with control Cas9 mRNA. Wang and Chen are now focused on making their multi-tailed mRNA synthesis and purification process more scalable. They are also taking a closer look at how mRNA modifications affect the interplay between its therapeutic stability and activity. “We want to see where else we can engineer mRNA’s structure to increase efficiency,” Chen said, adding that they are also interested in modifications that would improve the rate at which cells can scan and translate mRNA’s instructions. 	messenger vaccines effective mrnas therapeutics multiple dna rnas mrna biotechnology broad news		2024-03-22											Kat J. McAlpine	303	0
Spatial study of lung cancer reveals immune markers of response to immunotherapy	"Most patients with cancer who are treated with immunotherapies called PD-1 inhibitors don’t respond to the treatments and many researchers have been trying to figure out why by studying immune cells in human tumors. Scientists at the Broad Institute of MIT and Harvard, Brigham and Womens’ Hospital, and Massachusetts General Hospital (MGH) focused on non-small cell lung cancer, the leading cause of cancer death. They analyzed individual immune cells from human lung tumor samples taken from 68 people before they were treated with PD-1 inhibitors. They mapped the cells’ genetic activity as well as the location of the cells in the tumors. The team found organized hubs of immune cells, or ""immunity hubs"", within some tumors. Tumors from people who responded well to PD-1 blockers tended to have a subtype of hub, called “stem-immunity hubs”, that consisted of specific types of immune cells and signaling molecules known to drive effective anti-tumor responses. The work was published in Nature Immunology. Two members of the research team, Nir Hacohen, co-senior author of the study, an institute member at Broad and director of the Center of Cancer Immunology at MGH, and Jonathan Chen, co-first author, a member of the Hacohen lab, and an investigator in the department of pathology at MGH describe their findings and how they are now translating them into potential diagnostics and therapeutics. Tell us more about these immunity hubs. Networks of cells are critical in mediating immune responses. How do immune cells organize within tumors to effectively eliminate cancer cells? In 2021, we reported the discovery of a network of immune cells in colorectal cancer. We called these networks “immunity hubs.” These consist of activated T cells abutting tumor and immune myeloid cells expressing T cell-attracting molecules. This finding suggested the existence of a positive feedback loop in which activated T cells drive further T cell recruitment by local cells in the tumor. We reasoned that immunity hubs might be predictive of response to immunotherapy because they were enriched in a class of colorectal tumors known to have higher rate of response to PD-1 blockade immunotherapy. However, while our study of colorectal samples includes this class of tumors, the patients in our study were not treated with immunotherapy. In this new study, we sought to answer whether immunity hubs are indeed predictive of response to standard of care immunotherapy. We studied non-small cell lung cancer (NSCLC), which is commonly treated with PD-1 blockade immunotherapy. What did you find in your study? We found that patients without immunity hubs in their tumors prior to PD-1 blockade therapy had poor outcomes relative to patients with hubs. Critically, we discovered the “stem-immunity” hub, a subtype of immunity hub that is strongly associated with favorable immunotherapy response. Stem-immunity hubs were enriched for a type of T cell that is remarkable for its ability to divide and invigorate the antitumor immune response after PD-1 blockade. So the finding of these stem-immunity hubs represents a new way to think about how the immune response is organized in human cancer. How important was the spatial analysis in your study? This high-resolution spatial approach allowed us to discover important cell-cell interactions that may regulate the formation and function of these hubs. What are the implications of your findings? The most obvious implication of our work is that we can use the presence of the immunity hub, particularly the stem-immunity hub subclass, as a biomarker to predict response to immunotherapy. The current standard biomarker for prediction of immunotherapy response is PD-L1 antibody staining, but it can be inaccurate and difficult to use. We are currently testing a simple two-marker tissue stain that reflects immunity and can be assessed by pathologists using a standard workflow. We think the immunity hub may be how the immune system organizes to fight tumors. Therefore, we aim to develop therapeutics based on findings in this study to augment immunity hubs and support the anti-tumor immune response. Adapted from a Mass General Research Spotlight "	immunotherapy myeloid tumors cancer immune immunotherapies lung markers tumor broad news		2024-03-20											Broad and Mass General Communications	304	0
Researchers roll out a more accurate way to estimate genetic risks of disease	Researchers have developed statistical tools called polygenic risk scores (PRSs) that can estimate individuals’ risk for certain diseases with strong genetic components, such as heart disease or diabetes. However, the data on which PRSs are built is often limited in diversity and scope. As a result, PRSs are less accurate when applied to populations that differ demographically from the PRS training data. 	researchers estimate diseases polygenic genetic diabetes accurate disease broad news		2024-03-19											Claire Hendershot	305	0
Scientists generate new targeted protein degradation system that tunes a cell’s own proteins	Researchers studying the role of proteins in health and disease use experimental tools that inactivate proteins, destroy them, or prevent them from being made in cells. In one approach, they mark targeted proteins with “destroy me” tags that work with small molecules known as molecular glues to prompt the cell’s own protein-clearing machinery to gobble up the proteins. Yet, many tags used today are too large to tag the genes that encode a cell’s native proteins, or they cause collateral damage, sparking destruction of proteins beyond the targeted one. Now, scientists at the Broad institute of MIT and Harvard have used a continuous evolution platform called PACE to generate smaller protein degradation tags, or degrons, that form molecular glue complexes capable of precisely triggering depletion of a cell’s own proteins. The team then used a gene-editing technology they previously developed called prime editing to insert the compact degron into the genome of human cells, where it recruited cereblon, a key component of the cell’s protein destruction pathway, in the presence of an otherwise-inert small molecule to rapidly induce the protein’s degradation. The scientists solved the three-component complex’s 3D structure and revealed insights into its activity and specificity, and also evolved degron variants that work in mouse cells. The platform has the potential to evolve additional new degrons and molecular glue complexes that could be used to explore protein function or to validate therapeutic targets. The new study appears in Science. “We've shown that continuous evolution is a powerful approach to rapidly evolve molecular glue systems that can become useful research tools,” said David Liu, senior author of the study and Richard Merkin Professor and director of the Merkin Institute of Transformative Technologies in Healthcare at the Broad. “We’re excited to see how the approach can also be applied to evolve other proteins that interact with small molecules in creative and powerful ways.” Liu is also a Howard Hughes Medical Institute investigator and a professor at Harvard University. NEW GLUE BREAKTHROUGH The effort builds on work published earlier this year and led by co-senior author Amit Choudhary, an associate member of the Broad and an assistant professor of medicine at Harvard Medical School. That study identified a number of molecules related to thalidomide, a classic molecular glue that interacts with cereblon to trigger protein degradation and is used to treat some cancers and skin conditions. Whereas thalidomide triggers the destruction of numerous proteins, a related molecule known as PT-179 was relatively inert, making it a good starting point for a more precise molecular glue system. In the new study, the researchers used a system called phage-assisted continuous evolution (PACE), first developed in Liu’s lab at Harvard in 2011, to generate a degron that might work with PT-179. PACE allows researchers to rapidly evolve new proteins that have useful features. In experiments led by co-first authors Jaron Mercer and Stephan DeCarlo, the team started with a zinc finger motif, a protein structural element known to engage molecular glue-bound cereblon. Through hundreds of generations of evolution during PACE, they evolved new zinc finger domains that interact with cereblon when bound to the PT-179 molecular glue. The researchers then trimmed the zinc finger domain down to just 36 amino acids, dubbed SD40. “We wanted to find the smallest motif possible, so that we could use our prime editing technology to efficiently tag endogenous genes in the genome,” said DeCarlo, a graduate student at Harvard University and researcher in the Liu lab. “It’s a big goal in biology to study loss of proteins under endogenous regulatory control, not only for validating drug targets, but also for studying native protein function in biology.” They then used prime editing to insert SD40 into the genome of human cells and tag two different proteins. The targeted proteins began disappearing from the cell mere minutes after adding PT-179, with no observed effect on any of thousands of non-targeted proteins evaluated. “Other systems have shown degradation of a protein that's foreign to the cell, but using this potent tag that we evolved, we showed degradation of native target proteins from that cell, which is more biologically meaningful,” said Mercer, a postdoctoral fellow in the Liu lab. For a deep look at how SD40, cereblon, and PT-179 interact, the team analyzed the three-dimensional structure of the complex through work led by co-first author Shourya Roy Burman, a research fellow in the lab of co-senior author and cereblon expert Eric Fischer at Dana-Farber Cancer Institute. Using cryo-electron microscopy, the team showed that when bound to SD40 and PT-179, cereblon is in a closed conformation, with SD40 appearing to hold the receptor’s two ends together. The work suggests that cereblon may need to be “closed” in order to relay the message to other proteins in the complex to flag the targeted protein for destruction, although more work is needed to verify and understand this mechanism. Since the cellular machinery that degrades proteins in human cells and in mice differs, the team also used their approach to evolve a degron that binds to cereblon found in mouse cells, which could be useful in studies involving transgenic mouse models of human disease. The platform could also be used to evolve molecular glue complexes with novel degrons, or other combinations of proteins that interact in new, interesting ways. The researchers are already working with scientists in cancer biology and other fields to harness their evolved degrons to tag proteins of potential therapeutic interest. This approach allows them to remove a target protein in minutes by adding PT-179 while preserving the corresponding gene’s natural genomic context, thereby minimizing perturbation of regulatory mechanisms crucial to the native biological function of many proteins. 	proteins cell cancers biology cancer harvard protein new scientists broad news		2024-03-14											Leah Eisenstadt	306	0
Study reveals genetic clusters that may explain differences in type 2 diabetes risk	The development and progression of type 2 diabetes are affected by numerous biological processes, such as the body’s response to insulin, the health of insulin-producing pancreatic beta cells, and the functioning of metabolic pathways. In a recent study published in Nature Medicine that analyzed individuals from diverse backgrounds, a team led by investigators at Massachusetts General Hospital (MGH) and the Broad Institute of MIT and Harvard identified various genetic clusters involved in a broad range of biological mechanisms that may help explain ancestry-associated differences in type 2 diabetes clinical presentations. “Type 2 diabetes is a disease of elevated blood sugar impacting approximately one in 10 people in the United States that can cause devastating health complications and is usually not cured. It is currently not fully understood why a given person develops the disease or why there is a lot of variation around clinical features across people with the disease,” said senior author Miriam Udler, director of the MGH Diabetes Genetics Clinic, an assistant professor of medicine at Harvard Medical School, and an associate member at Broad. Udler and her colleagues assessed genetic findings from more than 1.4 million individuals across various genetic ancestral backgrounds: African/African American, admixed American, East Asian, European, South Asian, and multi-ancestry. Analyses resulted in a final set of 650 genetic variants that had independent associations with type 2 diabetes and a final list of 110 diabetes-related clinical traits. The scientists’ analyses validated diabetes-associated genetic clusters that they had identified in a previous study. (A genetic cluster is a group of 2 or more genetic regions that are suspected to share a generalized biological function.) The work also uncovered new genetic clusters related to decreased cholesterol levels, abnormal metabolism of bilirubin (which is created when the body breaks down hemoglobin from aged red blood cells), and abnormal lipid processing in fat and liver tissues. In addition to identifying 12 genetic clusters and their biological functions that are associated with type 2 diabetes, the investigators found that the clusters helped to explain some of the dissimilarities in type 2 diabetes among different populations. For example, it is well-documented that individuals from various self-identified non-white populations are more susceptible to type 2 diabetes at a given body mass index. The study’s data suggest that this disparity is at least partially explained by variations in 2 of the clusters that the researchers identified that relate to how the body uses and stores fat—so that individuals with certain variants in these clusters (most often individuals from East Asian populations) face a higher risk of type 2 diabetes at lower body mass index levels than other individuals. This discovery could help clinicians calculate an individual’s target body mass index level based on their genetic profile. “Our study shows that the genetic underpinnings of type 2 diabetes can help explain clinical differences across populations,” said co–lead author Kirk Smith, a computational biologist in MGH’s Center for Genomic Medicine. “Also, the genetic mechanisms of disease that we have identified offer the potential to guide development of curative therapies,” added co–lead author Aaron Deutsch, an instructor in the division of Endocrinology at MGH. Additional authors include Carolyn McGrail, Hyunkyung Kim, Sarah Hsu, Alicia Huerta-Chagoya, Ravi Mandla, Philip Schroeder, Kenneth Westerman, Lukasz Szczerbinski, Timothy Majarian, Varinderpal Kaur, Alice Williamson, Noah Zaitlen, Melina Claussnitzer, Jose Florez, Alisa Manning, Josep Mercader, and Kyle Gaulton. Adapted from an MGH press release. 	study differences endocrinology medicine genetic diabetes genetics clusters insulin broad news		2024-03-08											Brandon Chase, Massachusetts General Hospital Communications	307	0
A close research partnership with African scientists helps solve the mystery of malaria-like illnesses	Malaria prevalence has decreased drastically over the past two decades, but clinics in West Africa are still full of patients with fevers and symptoms similar to, but not exactly like, malaria. Little is known about what pathogens cause these infections, and so these “non-malarial febrile illnesses” (NMFI) often fly under the radar of infectious disease surveillance programs because researchers don’t know which pathogens to look for. Understanding how genomics could help detect and identify these mysterious infections has been the focus of a multi-year research partnership between University Cheikh Anta Diop in Dakar, Senegal and the Broad Institute of MIT and Harvard. 	research malaria african malarial pathogens illnesses scientists disease broad news		2024-03-08											Claire Hendershot	308	0
Schizophrenia and aging may share a common biological basis	Researchers from the Stanley Center for Psychiatric Research at the Broad Institute of MIT and Harvard, Harvard Medical School, and McLean Hospital have uncovered a strikingly similar suite of changes in gene activity in brain tissue from people with schizophrenia and from older adults. These changes suggest a common biological basis for the cognitive impairment often seen in people with schizophrenia and in the elderly. In a study published today in Nature, the team describes how they analyzed gene expression in more than a million individual cells from postmortem brain tissue from 191 people. They found that in individuals with schizophrenia and in older adults without schizophrenia, two brain cell types called astrocytes and neurons reduced their expression of genes that support the junctions between neurons called synapses, compared to healthy or younger people. They also discovered tightly synchronized gene expression changes in the two cell types: when neurons decreased the expression of certain genes related to synapses, astrocytes similarly changed expression of a distinct set of genes that support synapses. The team called this coordinated set of changes the Synaptic Neuron and Astrocyte Program (SNAP). Even in healthy, young people, the expression of the SNAP genes always increased or decreased in a coordinated way in their neurons and astrocytes. “Science often focuses on what genes each cell type expresses on its own,” said Steve McCarroll, a co-senior author on the study and an institute member at the Broad Institute. “But brain tissue from many people, and machine-learning analyses of those data, helped us recognize a larger system. These cell types are not acting as independent entities, but have really close coordination. The strength of those relationships took our breath away.” Schizophrenia is well-known for causing hallucinations and delusion, which can be at least partly treated with medications. But it also causes debilitating cognitive decline, which has no effective treatments and is common in aging as well. The new findings suggest that the cognitive changes in both conditions might involve similar cellular and molecular alterations in the brain. “To detect coordination between astrocytes and neurons in schizophrenia and aging, we needed to study tissue samples from a very large number of individuals,” said Sabina Berretta, a co-senior author of the study, an associate professor at Harvard Medical School, and a researcher in the field of psychiatric disorders. “Our gratitude goes to all donors who chose to donate their brain to research to help others suffering from brain disorders and to whom we’d like to dedicate this work.” McCarroll is also director of genomic neurobiology for the Broad’s Stanley Center for Psychiatric Research and a professor at Harvard Medical School. Berretta also directs the Harvard Brain Tissue Resource Center (HBTRC), which provided tissue for the study. Emi Ling, a postdoctoral researcher in McCarroll’s lab, was the study’s first author. SNAP insights The brain works in large part because neurons connect with other neurons at synapses, where they pass signals to one another. The brain constantly forms new synapses and prunes old ones. Scientists think new synapses help our brains stay flexible, and studies — including previous efforts by scientists in McCarroll’s lab and international consortia — have shown that many genetic factors linked to schizophrenia involve genes that contribute to the function of synapses. In the new study, McCarroll, Berretta, and colleagues used single-nucleus RNA sequencing, which measures gene expression in individual cells, to better understand how the brain naturally varies across individuals. They analyzed 1.2 million cells from 94 people with schizophrenia and 97 without. They found that when neurons boosted expression of genes that encode parts of synapses, astrocytes increased the expression of a distinct set of genes involved in synaptic function. These genes, which make up the SNAP program, included many previously identified risk factors for schizophrenia. The team’s analyses indicated that both neurons and astrocytes shape genetic vulnerability for the condition. “Science has long known that neurons and synapses are important in risk for schizophrenia, but by framing the question a different way — asking what genes each cell type regulates dynamically — we found that astrocytes too are likely involved,” said Ling. To their surprise, the researchers also found that SNAP varied greatly even among people without schizophrenia, suggesting that SNAP could be involved in cognitive differences in healthy humans. Much of this variation was explained by age; SNAP declined substantially in many — but not all — older individuals, including both people with and without schizophrenia. With better understanding of SNAP, McCarroll says he hopes it might be possible to identify life factors that positively influence SNAP, and develop medicines that help stimulate SNAP, as a way to treat the cognitive impairments of schizophrenia or help people maintain their cognitive flexibility as they age. In the meantime, McCarroll, Berretta, and their team are working to understand if these changes are present in other conditions such as bipolar disorder and depression. They also aim to uncover the extent to which SNAP appears in other brain areas, and how SNAP affects learning and cognitive flexibility. With reporting from Karen Zusi-Tran 	common psychiatric schizophrenia aging harvard basis astrocytes biological neurobiology broad news		2024-03-06											Allessandra DiCorato	309	0
Global survey of gut microbes uncovers 18 new bacterial species and clues to antibiotic resistance	One day in 2015, Joseph Manson placed in his refrigerator the colon of a wild turkey he’d just hunted near his small farm in South Carolina. A physics professor at Clemson University, he’d been recruited by his daughter, Abigail Manson, a scientist at the Broad Institute of MIT and Harvard, to help in a global study she was participating in to discover new species of gut bacteria. She’d wondered if any of the cows or chickens her father raised or the wild animals he hunted might carry some new variants of Enterococcus bacteria, a type of microbe found in the gut of all land animals on the planet and a leading cause of drug-resistant infections in humans. He mailed a bit of the wild turkey’s waste to Massachusetts, where his daughter and her collaborators discovered that the bird had carried in its bowels a never-before-seen type of bacteria. To recognize Joseph’s contributions of dozens of animal fecal samples to the study, the research team named the bacteria Enterococcus mansonii, an unlikely distinction for a physicist and farmer. The microbe is just one of 18 new species of Enterococcus discovered by the team, led by researchers at the Broad Institute and Massachusetts Eye and Ear. The researchers analyzed hundreds of scat, soil, and other samples that were collected from an unexplored peak in Nepal, a remote trail in Uganda, and many more places across the globe by an international team of scientists and elite adventurers. The new species they found expand the genus diversity of known enterococcal strains by more than 25 percent and add unprecedented detail to this microbial family tree. In the new microbes’ DNA, the researchers found hundreds of novel genes that may offer clues to how enterococci are able to resist antibiotic treatment and thrive in the hospital environment. The findings could one day help monitor the emergence of new drug-resistant threats or highlight possible ways to prevent or treat those infections. The work appears in Proceedings of the National Academy of Sciences (PNAS). “Our results are part of a multi-phase effort to understand the origins of a major hospital pathogen through the lens of its long-term evolution over hundreds of millions of years,” said co-senior author Ashlee Earl, director of the Bacterial Genomics Group and an institute scientist at the Broad. “Over the past 30 years, many of the most problematic bacteria have become increasingly resistant to antibiotics and this is now reaching crisis proportions,” said co-senior author Michael Gilmore, chief scientific officer at Mass Eye and Ear, director of the Infectious Disease Institute at Harvard Medical School, and an associate member at the Broad. “Our findings may improve understanding of how resistance genes spread to hospital bacteria and threaten human health.” A microbial menagerie The new study builds on an earlier effort by the team to explore the origins of antibiotic-resistant bacteria, which revealed that enterococci arose from an ancestral microorganism that dates back 450 million years, when animals first began crawling onto land. Since then, these bacteria have evolved to be able to survive in harsh conditions, including hospitals despite frequent disinfection. Enterococci are now one of the leading causes of drug-resistant bacterial infections, a public health menace that in 2019 was directly responsible for 1.27 million deaths globally. In the current study, the Gilmore and Earl groups aimed to broadly survey the diversity of genes present across all kinds of enterococci. “Enterococci are found in almost every land animal on the planet,” said Abigail Manson, a co-author on the new study and a senior computational group leader at the Broad. “Understanding what genes are capable of living in the genus as a whole is really crucial to identifying what threats we could be facing in the future in hospitals.” To conduct such a survey, the researchers created the Enterococcal Diversity Consortium, an international group of scientists and adventurers tasked with sampling the gut microbes of as many animals from as many places across the globe as possible. Their thorough survey included remote trails, peaks, and other areas untouched by humans, which they reasoned could harbor bacteria that naturally carry genes conferring drug-resistant traits. Those genes could one day be transferred to enterococcal species already residing in humans, leading to new “superbug” strains that cause untreatable infections. The team collected specimens from a diverse menagerie including penguins migrating through sub-Antarctic waters; Kemp’s Ridley sea turtles stranded on the New England coast; wild duiker and elephants from Uganda; dragonflies, butterflies, ground beetles, and other insects from diverse locales; kestrel and vultures from Mongolia; wallabies, swans, and wombats from Australia; and zoo animals and wild birds from Europe. In addition to recruiting her dad’s help, Abigail Manson and her children gathered droppings from chickens on a Cape Cod farm and from geese resting in a field. To procure more exotic specimens, members of Adventure Scientists, a non-profit group of outdoor enthusiasts who assist with data collection in remote places, ascended an unexplored peak in Nepal to collect fresh scat from Himalayan blue sheep and traversed remote trails in Afghanistan to gather droppings from donkeys and marmots. 	microbes global refrigerator antibiotic harvard bacterial bacteria manson 18 broad news		2024-02-29											Leah Eisenstadt	310	0
#WhyIScience Q&A: A software engineer develops computational tools for psychiatric and brain research	Raised in a family of educators in Philadelphia, Khalid Shakir was exposed to both computational and biological sciences at a young age. His first scientific experiments involved tinkering with spare equipment from his parents’ high school classrooms including a Commodore 64 from his father’s computer lab and microscopes from his mother’s biology classroom. Now, Shakir has traded in his Commodore 64 for large-scale computational tools that he develops as a software engineer at the Broad Institute of MIT and Harvard. After earning a degree in Computer Science and working for multiple technology startups, Shakir first came to the Broad to work on a project studying human genetic variation called the 1000 Genomes Project, which launched in 2008. He was intrigued by the prospect of scaling computational tools to analyze ever-growing biological datasets. As part of the Data Sciences Platform, Shakir helped build Terra, an open-source, cloud-based biomedical data sharing platform. 	research software psychiatric classrooms biology engineer harvard biomedical startups computational broad news		2024-02-21											Claire Hendershot	311	0
Count Me In Launches Osteosarcoma Project in Spanish / Count Me In Lanza el Osteosarcoma Project en español	"Leer en español In a move to increase Hispanic and Latino representation in cancer research, Count Me In (CMI) has recently launched a Spanish-language version of one of their patient-partnered research projects. The Osteosarcoma Project, designed to enable individuals across the United States and Canada living with osteosarcoma to contribute their medical histories, biological samples, and their experiences for research, is now fully accessible in Spanish. This comprehensive translation encompasses all relevant content related to participation and enrollment, opening doors for a more diverse range of individuals to engage with the Osteosarcoma Project and providing researchers with data that better reflects the demographics of those affected by this disease. The Spanish speaking population constitutes one of the largest ethnic groups in the United States. Despite this, they face a disproportionate impact from cancer, coupled with a lack of representation in research. By making the Osteosarcoma Project accessible to Spanish speakers, Count Me In aims to dismantle a longstanding barrier to enrollment in cancer research: the lack of information available in languages other than English. All necessary materials for Osteosarcoma Project enrollment, including surveys, consent and medical release forms, website content (including FAQs), and sample collection kits, have been translated into Spanish. These materials have been thoughtfully crafted to be culturally sensitive, fostering a stronger connection within the community. Diane Diehl, Director of Scientific Operations at Count Me In, recently shared, ""We must continue to enhance accessibility and inclusivity of direct-to-patient studies to ultimately ensure treatment options reflect representation among all diverse communities, with emphasis on historically marginalized and excluded patients in the realm of cancer research."" One participant in the Osteosarcoma Project recently expressed their optimism, stating, ""Participating in the Osteosarcoma Project gives me hope that we can work towards improved treatment options, and the availability of resources in Spanish ensures that everyone’s experience can be counted."" Learn more about Count Me In and the Osteosarcoma Project at: Count Me In: https://joincountmein.org Osteosarcoma Project: https://osproject.org Count Me In’s Osteosarcoma Project is made possible by federal funding through the Participant Engagement and Cancer Genome Sequencing (PE-CGS) grant as part of the Cancer Moonshot Initiative. En un intento por aumentar la representación Hispana y Latina en la investigación del cáncer, Count Me In (CMI) lanzó recientemente la versión en español de uno de sus proyectos de investigación en colaboración con pacientes. El Proyecto de Osteosarcoma, diseñado para permitir que personas de todo Estados Unidos y Canadá que viven con Osteosarcoma contribuyan con sus historias médicas, muestras biológicas y sus experiencias para la investigación, ahora es completamente accesible en Español. Esta traducción integral abarca todo el contenido relevante relacionado con la participación y la inscripción, abriendo puertas para que una gama más diversa de personas participen en el Proyecto de Osteosarcoma y brindando a los investigadores datos que reflejen mejor la demografía de los afectados por esta enfermedad. La población de habla Hispana constituye uno de los grupos étnicos más grandes de los Estados Unidos. A pesar de esto, enfrentan un impacto desproporcionado del cáncer, sumado a una falta de representación en la investigación. Al hacer que el Proyecto de Osteosarcoma sea accesible para los hispanohablantes, Count Me In tiene como objetivo desmantelar la gran barrera para la inscripción en la investigación del cáncer: la falta de información disponible en otros idiomas además del Inglés. Todos los materiales necesarios para la inscripción en el Proyecto de Osteosarcoma, incluidas encuestas, formularios de consentimiento, autorización médica, contenido del sitio web (incluidas las preguntas frecuentes) y kits de recolección de muestras, se han traducido al Español. Estos materiales han sido cuidadosamente elaborados para ser culturalmente sensibles, y fomentar una conexión más fuerte dentro de la comunidad. Diane Diehl, directora de operaciones científicas de Count Me In, compartió recientemente: ""Debemos continuar mejorando la accesibilidad y la inclusión de los estudios directos al paciente para, en última instancia, garantizar que las opciones de tratamiento reflejen la representación entre todas las comunidades diversas, con énfasis en los pacientes que históricamente han sido marginados y excluidos en el ámbito de la investigación del cáncer."" Un participante en el Proyecto Osteosarcoma expresó recientemente su optimismo y afirmó: ""Participar en el Proyecto Osteosarcoma me da la esperanza de que podemos trabajar para mejorar las opciones de tratamiento, y la disponibilidad de recursos en español garantiza que se pueda contar la experiencia de todos"". Obtenga más información sobre Count Me In y el Proyecto de Osteosarcoma en: Count Me In: https://joincountmein.org Proyecto Osteosarcoma: https://osproject.org El Proyecto de Osteosarcoma de Count Me In es posible gracias al financiamiento federal del fondo de Involucramiento de Participantes y Secuenciación del Genoma del Cáncer (PE-CGS, por sus siglas en Inglés) que forma parte de la Iniciativa Cáncer Moonshot. "	cáncer launches lanza latino cancer biológicas spanish hispanic español count broad news		2024-02-21											Count Me In	312	0
Genetic risk prediction for 10 chronic diseases moves closer to the clinic	By analyzing millions of small genetic differences across a person’s genome, researchers can calculate a polygenic risk score to estimate someone’s lifetime odds of developing a certain disease. Over the past decade, scientists have developed these risk scores for dozens of diseases, including heart disease, kidney disease, diabetes, and cancer, with the hope that patients could one day use this information to lower any heightened risk of disease. But determining whether such tests work effectively across all populations, and how they can guide clinical decision-making, has been a challenge. Now, a team of researchers at the Broad Institute of MIT and Harvard, in collaboration with 10 academic medical centers across the US, has implemented 10 such tests for use in clinical research. In a study published today in Nature Medicine, the team outlined how they selected, optimized, and validated the tests for 10 common diseases, including heart disease, breast cancer, and type 2 diabetes. They also calibrated the tests for use in people with non-European ancestries. The scientists worked in collaboration with the national Electronic Medical Records and Genomics (eMERGE) network, which is funded by the National Human Genome Research Institute to study how patients’ genetic data can be integrated with their electronic medical records to improve clinical care and health outcomes. The 10 collaborating medical centers are part of the project and enrolling 25,000 participants for it, while researchers at Broad Clinical Labs, a subsidiary of the Broad Institute, carry out the polygenic risk score testing for those participants. “There have been a lot of ongoing conversations and debates about polygenic risk scores and their utility and applicability in the clinical setting,” said Niall Lennon, chief scientific officer of Broad Clinical Labs, an institute scientist at Broad, and first author of the new paper. “With this work, we’ve taken the first steps toward showing the potential strength and power of these scores across a diverse population. We hope in the future this kind of information can be used in preventive medicine to help people take actions that lower their risk of disease.” What’s the score? Most polygenic risk scores have been developed based on genetic data largely from people of European ancestry, raising questions about whether the scores are applicable to people of other ancestries. To optimize polygenic risk scores for a diversity of people, Lennon and his colleagues first combed the literature looking for polygenic risk scores that had been tested in people from at least two different genetic ancestries. They also searched for scores that indicate a disease risk that patients could reduce with medical treatments, screening, and/or lifestyle changes. “It was important that we weren’t giving people results that they couldn’t do anything about,” said Lennon. The team selected 10 conditions to focus on for polygenic risk scores: atrial fibrillation, breast cancer, chronic kidney disease, coronary heart disease, hypercholesterolemia, prostate cancer, asthma, type 1 diabetes, obesity, and type 2 diabetes. For each condition, the researchers identified the exact spots in the genome that they would analyze to calculate the risk score. They verified that all those spots could be accurately genotyped, by comparing the results of their tests with whole genome sequences from each patient’s blood sample. Finally, the researchers wanted to make polygenic risk scores work across different genetic ancestries. They studied how genetic variants differ across populations by analyzing data from the National Institutes of Health’s All of Us research program, which is collecting health information from one million people from diverse backgrounds across the U.S. The team used that information to create a model to calibrate a person’s polygenic risk score according to that individual’s genetic ancestry. “We can’t fix all biases in the risk scores, but we can make sure that if a person is in a high-risk group for a disease, they’ll get identified as high risk regardless of what their genetic ancestry is,” explained Lennon. With that optimization complete, Lennon’s team at Broad Clinical Labs ended up with 10 tests that they are now using to calculate risk scores for the 25,000 people enrolled in the eMERGE study. With their eMERGE collaborators, they are also planning detailed follow-up studies to analyze how polygenic risk scores might influence patients’ health care. “Ultimately, the network wants to know what it means for a person to receive information that says they’re at high risk for one of these diseases,” Lennon said. 	genomics diseases clinic cancer 10 genetic harvard diabetes chronic scientists broad news		2024-02-19											Sarah C.P. Williams	313	0
Largest and most diverse genome-wide association study of type 2 diabetes reveals new genetic factors	An international collaboration of research teams has conducted the largest and most ancestrally diverse genome-wide association study for type 2 diabetes (T2D). By analyzing the DNA of 2.5 million participants, the researchers identified over 600 regions in the genome that are associated with increased risk for T2D, including 145 that had not been previously linked to the disorder. They recently reported their findings in Nature. 	researchers genome largest genetic diabetes new dna 145 broad news		2024-02-19											Claire Hendershot	314	0
Study finds youth-onset diabetes is a genetically distinct form of the disorder	The diabetes field has long classified the disorder into genetically distinct groups, including type 1 and type 2. However, new genetics research focused on a form of type 2 diabetes (T2D) that is becoming more common in adolescents suggests a more complicated picture. Researchers at the Broad Institute of MIT and Harvard, Boston Children's Hospital, and Harvard Medical School analyzed DNA from more than 3,000 T2D participants between 12 and 18-years-old and nearly 9,800 adult controls, more than three-quarters of whom were of African American or Hispanic ancestry. They found that youth-onset T2D is a genetically intermediate form of the disorder that lies on a spectrum between adult-onset T2D and rare forms of the disorder caused by a single gene. Adult-onset T2D is influenced by thousands of common genetic variants, whereas the rare genetic forms, known as monogenic diabetes, are caused by a single variant. However, in a recent Nature Metabolism paper, the researchers showed that youth-onset T2D shared some of the same genetic features as both forms, carrying both common and rare genetic variants. Moreover, these individuals harbored more of these variants than people with adult-onset T2D, suggesting that genetics has a larger role in causing youth-onset T2D than in the adult-onset form. 	genetically distinct harvard genetic disorder diabetes genetics youth dna broad news		2024-02-16											Claire Hendershot	315	0
Researchers uncover genetic factors for severe Lassa fever	While combing through the human genome in 2007, computational geneticist Pardis Sabeti made a discovery that would transform her research career. As a then postdoctoral fellow at the Broad Institute of MIT and Harvard, Sabeti discovered potential evidence that some unknown mutation in a gene called LARGE1 had a beneficial effect in the Nigerian population. Other scientists had discovered that this gene was critical for the Lassa virus to enter cells. Sabeti wondered whether a mutation in LARGE1 might prevent Lassa fever — an infection that is caused by the Lassa virus, is endemic in West Africa, and can be deadly in some people while only mild in others. To find out, Sabeti decided later in 2007, as a new faculty member at Harvard University, that one of the first projects her new lab at the Broad would take on would be a genome-wide association study (GWAS) of Lassa susceptibility. She reached out to her collaborator Christian Happi, now the Director of the African Center of Excellence for Genomics of Infectious Diseases (ACEGID) at Redeemer’s University in Nigeria, and together they launched the study. Now, their groups and collaborators report the results of that study in Nature Microbiology — the first ever GWAS of a biosafety level 4 (BSL-4) virus. The team found two key human genetic factors that could help explain why some people develop severe Lassa fever, and a set of LARGE1 variants linked to a reduced chance of getting Lassa fever. The work could lay the foundation for better treatments for Lassa fever and other similar diseases. The scientists are already working on a similar genetics study of Ebola susceptibility. The paper also describes the many challenges the team had to overcome during their 16-year collaborative effort, such as studying a dangerous virus and recruiting patients with a disease that is not well documented in West Africa. Dozens of scientists contributed to the work and spent seven years recruiting patients in Nigeria and Sierra Leone and many additional years establishing the research program and analyzing the results. “It truly took a village to get this done,” said Happi, a co-senior author along with Sabeti. “Generations of people in our labs, across different institutions and countries, spent significant parts of their careers bringing this to fruition,” added Sabeti, an institute member at the Broad, a Howard Hughes Medical Institute investigator, a professor at the Center for Systems Biology and the Department of Organismic and Evolutionary Biology at Harvard University, and a professor in the Department of Immunology and Infectious Disease at the Harvard T. H. Chan School of Public Health. The co-first authors of the study are Dylan Kotliar, an internal medicine resident at Brigham and Women’s Hospital and an MD/PhD student in Sabeti’s lab while the project was ongoing; Siddharth Raju, a graduate student in Sabeti’s lab; Shervin Tabrizi, a postdoctoral researcher at the Broad; and Ikponmwosa Odia, a researcher at Irrua Specialist Teaching Hospital in Nigeria. Lassa learnings Sabeti recalls the team’s early discussions when launching the project. They knew they had to be cautious at every step: To work with a BSL-4 virus, scientists must wear pressurized suits connected to HEPA-filtered air in a special containment lab. The virus causes fever, sore throat, coughing, and vomiting, but can quickly progress to organ failure in some people. “This was an extremely challenging study to get off the ground,” said Kotliar, who worked on the project throughout his entire PhD in the Sabeti lab. “I think the battle scars, the things we’ve learned along the way about how to get a project like this done, are going to be important for future research into viruses in developing countries.” Finding participants for the study would be challenging too. There are currently no FDA-approved diagnostics for Lassa, and Lassa virus cases are typically not documented. There are fewer than 1,000 cases reported each year in Nigeria, the most populous country where the virus is endemic, and cases are often in rural areas far from diagnostic centers, many of which don’t have the technology to detect the virus. Infections with other viruses, and genomic complexity among different strains of the same Lassa virus can complicate analysis. Moreover, African populations have been historically underrepresented in past genetic studies, which reduces statistical power in data analyses and can make it difficult to identify key genetic variants. When Sabeti began thinking about how to start the project, she reached out to Happi, whom she knew through their mutual work on the malaria-causing pathogen, Plasmodium falciparum. With the help of collaborators including Peter Okokhere, a doctor treating Lassa patients at the Irrua Specialist Teaching Hospital, they began recruiting patients from both Nigeria and Sierra Leone. Then, they compared the genomes of about 500 people who’d had Lassa fever and nearly 2,000 who hadn’t. In the Nigerian cohort, the team found that people with a set of variants in the LARGE1 gene — which modifies a cell receptor that binds to certain viruses — were less likely to get Lassa fever. Sabeti, Happi, and their colleagues also found genomic regions associated with Lassa fatality: in the LIF1 gene, which encodes an immune-signaling molecule, and, in the Nigerian cohort, the GRM7 gene, which is involved in the central nervous system. The team then used a large-scale screen called a massively parallel reporter assay to home in on which variants within these genomic regions might be functional and could be targets of new treatments. Better detection The researchers say that to improve detection and treatment of Lassa fever, more diagnostic centers and diagnostics that work in the field are needed, along with better health infrastructure to connect remote locations with major hospitals. “This really highlights the need for continued investment in understanding African population genetics,” added Raju. “Even with a relatively limited sample set, we’ve increased our understanding of some African populations, specifically in immune-related genes — and that shows how much more there is to do going forward.” Sixteen years after they first started thinking about the genetics of Lassa fever, Sabeti and Happi are excited about the study’s findings, which could explain the biological differences between mild and severe illness. They said the work also shows that, as thoughtful collaborations between countries, genome-wide association studies of BSL-4 viruses are possible. The researchers have already begun conducting a similar study of Ebola in Sierra Leone and Liberia, and other scientists are calling for increased pathogen surveillance and scientific training in Africa. “We’re standing at a moment where we can actually start developing point-of-need diagnostics for Lassa virus and testing much more broadly,” Happi said. “We need better infrastructure, but I think we’ve shown that this kind of study is a worthwhile pursuit.” 	genomics lassa researchers fever biology geneticist severe genetic genetics scientists broad news		2024-02-08											Allessandra DiCorato	316	0
Study reveals links between blood vessel biology and heart disease risk	Over the past 15 years, researchers have identified hundreds of regions in the human genome associated with heart attack risk. However, researchers lack efficient ways to explore how these genetic variants are molecularly connected to cardiovascular disease, limiting efforts to develop therapeutics. To streamline analysis of hundreds of genetic variants associated with coronary artery disease (CAD), a team of researchers led by investigators from Brigham and Women’s Hospital (BWH), in collaboration with the Broad Institute of MIT and Harvard and Stanford Medicine, combined multiple sequencing and experimental techniques to map the relationship between known CAD variants and the biological pathways they impact. In a study published in Nature, the researchers applied this technique to endothelial cells, which line blood vessels. The team found that a key biological mechanism involved in a rare vascular disease may influence CAD risk. “Studying how hundreds of regions of the genome, individually or in groups, influence risk of heart attack can be a painstaking process,” said corresponding author Rajat Gupta of the Divisions of Genetics and Cardiovascular Medicine at BWH and the Cardiovascular Disease Initiative at Broad. “We decided we needed to have better maps showing how genetic variants affect gene expression and how genes affect biological function. If we could combine those two kinds of maps, we could make the bigger connection from variant to biological function.” The mapping technique developed by the researchers is called the Variant-to-Gene-to-Program (V2G2P) approach. First, in collaboration with researchers at Stanford Medicine, the researchers – including co-first authors Gavin Schnitzler of BWH and Broad and Helen Kang of Stanford Medicine – matched CAD loci previously identified through genome-wide association studies to genes impacted by these genetic variants. Then, they used CRISPRi-Perturb-seq, a technology developed at Broad, to “delete” thousands of CAD-associated genes, one at a time, and to examine how each deletion impacted the expression of all the other genes in that cell. In total, the researchers sequenced 215,000 endothelial cells to determine how 2,300 “deletions” influenced expression of 20,000 other genes in each cell. With applied machine learning algorithms, they were able to identify the biological mechanisms that consistently appeared to be related to CAD-associated variants. In particular, the researchers found that 43 of 306 of the CAD-associated variants in endothelial cells were linked to genes in the cerebral cavernous malformations (CCM) signaling pathway. CCM is a rare, devastating vascular disease that impacts the brain, but the researchers hypothesized that smaller, subtler mutations in the genes involved in CCM may contribute to CAD risk by affecting vascular inflammation, thrombosis, and the structural integrity of the endothelium. Moreover, the researchers highlighted a previously unrecognized role for the TLNRD1 gene in regulating the CCM pathway alongside other known CCM regulators and hypothesized that TLNRD1 may be involved in both CAD, a common disease, and CCM, a rare one. Going forward, the researchers hope to study patients with endothelial CAD-associated variants as well as CCM patients to determine whether there are distinct opportunities for treating these populations. For the latter, the researchers are interested in determining whether further investigation into TLNRD1 can lead to better forms of genetic testing and risk stratification. This study focused on endothelial cells, which line blood vessels and are increasingly understood to influence CAD risk. It examined endothelial mechanisms unrelated to lipid metabolism (a known driver of CAD risk with effective therapies, like statins) in hopes of uncovering other mechanisms driving CAD risk for which therapies may yet be developed. “Now that we know more about this collection of endothelial cell variants, we can return to patients who have them to see if they have different clinical features or respond differently to the therapies we are already using,” Gupta said. “We are also focused on this study’s implications for CCM patients. It was a coincidence that from this genetic screen designed to look at coronary disease, we implicated new genes for a rare vascular disease, CCM. Perhaps now we can better describe the risk factors and pathways that drive it.” Beyond CAD and CCM, the researchers emphasize that the V2G2P approach can be used to explore the biological mechanisms driving any disease for which a cell-type relevant to that disease can be genetically modified in the lab. “It was remarkable that this unbiased, systematic approach — in which we deleted all candidate CAD genes in a single experiment — pointed us straight to new genes and pathways that had escaped notice. This approach will be a powerful strategy for studying many other diseases where genetic risk factors remain to be discovered,” said co-corresponding author Jesse Engreitz,assistant professor of genetics at Stanford Medicine. Adapted from a press release issued by Brigham and Women's Hospital, a founding member of the Mass General Brigham healthcare system. Rajat Gupta talks about his work studying the biology of coronary artery disease during a 2023 Broad Discovery Series event. 	blood biology links thrombosis heart harvard genetics endothelial disease broad news		2024-02-07											Brigham and Women's Hospital Communications	317	0
With retinal images and genetic data, researchers predict cardiovascular, metabolic, and other disease risks	By combining retinal imaging, genetics, and big data, physician-researchers from Mass Eye and Ear, Massachusetts General Hospital (MGH), and the Broad Institute of MIT and Harvard have found that they can estimate how likely a person is to develop eye and systemic diseases in the future. They found significant associations between the thinning of different retinal layers and increased risk of developing ocular, cardiac, pulmonary, metabolic, and neuropsychiatric diseases and identified genes that are associated with retinal layer thickness. Their findings are published in Science Translational Medicine. “We showed that retinal images could be used to predict the future risk of both ocular disease and systemic disease,” says Seyedeh Maryam Zekavat, an ophthalmology resident at Mass Eye and Ear and postdoctoral scholar at Broad and co-first author of the study with Saman Doroodgar Jorshery, a postdoctoral fellow at MGH and Broad. “This could potentially help with disease prevention — if we know from someone’s retinal image that they are at high risk of developing glaucoma or cardiovascular disease in the future, we could refer them for follow-up screening or preventative treatment.” Because of its position behind the transparent structures of the eye, the retina is easy to visualize and image non-invasively, and retinal imaging is already a routine procedure in ophthalmology. The new study uncovers possibilities for preventative medicine and crosstalk between ophthalmologists and other areas of medicine. Previous studies have shown that there are links between retinal health and health conditions including aging, cardiometabolic diseases such as diabetes and hypertension, and neurological diseases such as dementia, stroke, and multiple sclerosis. “We’ve come to realize recently that there is a lot more information that we can get from our retina images than we thought was possible,” says senior author Nazlee Zebardast, director of glaucoma imaging at Mass Eye and Ear and an assistant professor of ophthalmology at Harvard Medical School. “It's really exciting to be able to see that these images, which are obtained without having to do any sort of invasive procedure, are associated with so many systemic conditions, both at a genetic level as well as an epidemiologic level.” To identify associations between retinal health and disease risk, and to identify genes associated with retinal health, the researchers analyzed data from 44,823 UK Biobank participants who underwent optical coherence tomography (OCT) imaging of the retina, genotyping, and baseline measurements of health in 2010 and were then followed for disease development for an average of ten years. Unlike previous studies that searched for genes associated with overall retina health, this study delved deeper into the role of the different cell layers that make up the retina. “Each layer of the retina is made up of different types of cells with diverse structures and functions, and we show that the thicknesses of these different layers are associated with different conditions,” says Zebardast, who is also an associated scientist at Broad. The study also provides insight into the genes and biological pathways that determine retinal health, which could be leveraged to develop future therapies, the researchers say. Altogether, the team identified 259 genetic loci that were associated with retinal thickness. One particular insight from this work was that multiple systemic health conditions including poor cardiac, metabolic, pulmonary, and renal function are linked to thinning of the photoreceptor segment of the retina, though further research would be needed to confirm causality. Future studies should also aim to replicate the study’s methods in more diverse populations and different age groups, since participants in the UK BioBank were predominantly white and aged 40-70 years old at baseline. Retinal OCT imaging is already a standard clinical procedure in ophthalmology at Mass Eye and Ear and elsewhere, but the authors say that their results suggest that its use could be widened. Further work on the connection between ocular and cardiometabolic health will enable understanding of its clinical utility, and the researchers are extending this line of research along with co-author Pradeep Natarajan, director of preventive cardiology at MGH and an associate member in the Cardiovascular Disease Initiative at Broad. “Patients come to us for their eye health, but what if we could tell them more than that?” says Zebardast. “What if we could use someone's retinal images to tell them, ‘You seem to have a high risk of having high blood pressure, maybe you should get screened, or maybe your primary care doctor should know about that.’” The authors have developed an online user-interface for all of their findings on the Ocular Knowledge Portal, to enable researchers to explore associations between retinal layer thickness, disease and genetics. Adapted from a press release issued by Mass Eye and Ear. Written by Liana Wait, a freelance science writer based in Philadelphia specializing in writing about the life sciences. 	cardiovascular cardiology researchers ophthalmologists harvard genetic ophthalmology retinal disease biobank broad news		2024-01-25											Liana Wait	318	0
Terra is now generally available on Microsoft Azure	"The Broad Institute of MIT and Harvard has made Terra generally available on Microsoft Azure. Terra is Broad’s flagship biomedical data platform, co-developed by Broad, Microsoft, and Verily. The open-source platform is used by over 65,000 individuals globally for biomedical data analysis, secure data sharing, and cross-enterprise data science collaborations. Through Terra, researchers can gain access to genomics and other data modalities used for biomedical research, as well as run state-of-the-art workflows developed by Broad and wider bioinformatics community. Expanding Terra onto Azure enhances support for enterprises and data scientists worldwide. Organizations such as AnalytixIndiana and Vanderbilt University Medical Center are adopting Terra on Azure to provide a Trusted Researcher Environment for their employees and affiliates. Enhanced functionality with Terra on Azure include: Connection to enterprise data: Terra on Azure is a preferred option for commercial organizations as it can be deployed within an organization’s Azure tenant and connect to data within the organization's IT network, and integrates with an organization’s existing authentication and authorization systems via Active Directory. Advanced policy configuration for cross-organization collaboration: Terra on Azure enables organizations to share their data securely in a manner that enforces data governance and privacy policies. This allows controlled data access and collaboration across organization and geographical borders. Compliance agreements: Terra can now sign HIPAA Business Associate Agreements for U.S. health system customers and Data Processor Agreements for customers regulated by GDPR. Integration with Microsoft offerings: Researchers can seamlessly use the Azure ecosystem from within their Terra Workspace environment, such as connecting to Azure OpenAI Service and Azure Health Services. Platform-wide Security: Terra’s support for Azure is authorized as a FedRAMP Moderate Impact system with an Agency Authorization. ""The Broad Institute has always been at the forefront of driving progress in genomics and biomedical research,” said Clare Bernard, head of the data sciences platform at Broad, which is responsible for Terra development and operations. “Our partnership with Microsoft Azure further extends the reach and impact of Terra, accelerating the pace of scientific discovery and impact on human health. We are thrilled to have so many partners at the forefront of this exciting journey."" “The responsible use of omics and health data requires robust security and compliance controls, but also ease of access and use to unlock the scientific potential,” said Jonathan Carlson, Managing Director, Microsoft Health Futures. “Terra on Microsoft Azure represents an important step toward accelerating scientific discovery through empowering responsible collaborative research across the global scientific community.” Darshan Shah, EVP, Data and AnalytiXIN, Central Indiana Corporate Partnership (CICP) said, “AnalytiXIN’s goal is to build a clinico-genomic health data asset that benefits Indiana researchers, and Terra on Azure is the backbone for this collaboration hub. By leveraging this platform alongside our partners at the Broad Institute and Microsoft, we have the ability to accelerate the utility of this unique data asset and catalyze an ecosystem of innovation for Indiana.” Melissa Basford, Senior Director, Big Data Support Services for Vanderbilt University Medical Center, said, “Our journey with Terra started several years ago with a strategic partnership providing critical data and cloud workbench capabilities. The platform has helped us to more efficiently store and reuse data while broadening access to more of our VUMC researchers. Now that Terra is on Azure, we are excited to align our use of Terra with our internal IT strategy.” Ashish Koshy, Group Chief Operating Officer, M42, an Abu Dhabi, UAE headquartered global health company, said, “At M42, we are dedicated to sustainably transforming global health through technology. The integration of trusted research environments like Terra on Azure is pivotal in driving our population genomics and clinical research programs. Terra on Azure provides a level of scalability which enhances our ability to deliver personalized, precision, and preventive health solutions.” The launch of Terra on Azure represents a significant milestone in Broad’s commitment to democratize access to technology and advance collaborative science to improve human health. Researchers and scientists worldwide can now use the power of Terra on Azure to drive advancements in population genetics, public health surveillance, and cancer research. For more information on Terra on Azure, please visit Terra.Bio. "	terra available microsoft harvard bioinformatics azure biomedical scientists generally broad news		2024-01-24											Broad Communications	319	0
With AI, researchers identify a new class of antibiotic candidates	Using a type of artificial intelligence known as deep learning, MIT researchers have discovered a class of compounds that can kill a drug-resistant bacterium that causes more than 10,000 deaths in the United States every year. In a study appearing in Nature, the researchers showed that these compounds could kill methicillin-resistant Staphylococcus aureus (MRSA) grown in a lab dish and in two mouse models of MRSA infection. The compounds also show very low toxicity against human cells, making them particularly good drug candidates. A key innovation of the new study is that the researchers were also able to figure out what kinds of information the deep-learning model was using to make its antibiotic potency predictions. This knowledge could help researchers to design additional drugs that might work even better than the ones identified by the model. “The insight here was that we could see what was being learned by the models to make their predictions that certain molecules would make for good antibiotics,” said James Collins, the Termeer Professor of Medical Engineering and Science in MIT’s Institute for Medical Engineering and Science (IMES) and Department of Biological Engineering, a core faculty member of the Wyss Institute for Biologically Inspired Engineering at Harvard University, and an institute member at the Broad Institute of MIT and Harvard. “Our work provides a framework that is time-efficient, resource-efficient, and mechanistically insightful, from a chemical-structure standpoint, in ways that we haven’t had to date.” Felix Wong, a postdoc at IMES and Broad, and Erica Zheng, a former Harvard Medical School graduate student who was advised by Collins, are the lead authors of the study, which is part of the Antibiotics-AI Project at MIT. The mission of this project, led by Collins, is to discover new classes of antibiotics against seven types of deadly bacteria, over seven years. Explainable predictions MRSA, which infects more than 80,000 people in the United States every year, often causes skin infections or pneumonia. Severe cases can lead to sepsis, a potentially fatal bloodstream infection. Over the past several years, Collins and his colleagues in MIT’s Abdul Latif Jameel Clinic for Machine Learning in Health (Jameel Clinic) have begun using deep learning to try to find new antibiotics. Their work has yielded potential drugs against Acinetobacter baumannii, a bacterium that is often found in hospitals, and many other drug-resistant bacteria. These compounds were identified using deep learning models that can learn to identify chemical structures that are associated with antimicrobial activity. These models then sift through millions of other compounds, generating predictions of which ones may have strong antimicrobial activity. These types of searches have proven fruitful, but one limitation to this approach is that the models are “black boxes,” meaning that there is no way of knowing what features the model based its predictions on. If scientists knew how the models were making their predictions, it could be easier for them to identify or design additional antibiotics. “What we set out to do in this study was to open the black box,” Wong said. “These models consist of very large numbers of calculations that mimic neural connections, and no one really knows what's going on underneath the hood.” First, the researchers trained a deep learning model using substantially expanded datasets. They generated this training data by testing about 39,000 compounds for antibiotic activity against MRSA, and then fed this data, plus information on the chemical structures of the compounds, into the model. “You can represent basically any molecule as a chemical structure, and also you tell the model if that chemical structure is antibacterial or not,” Wong added. “The model is trained on many examples like this. If you then give it any new molecule, a new arrangement of atoms and bonds, it can tell you a probability that that compound is predicted to be antibacterial.” To figure out how the model was making its predictions, the researchers adapted an algorithm known as Monte Carlo tree search, which has been used to help make other deep learning models, such as AlphaGo, more explainable. This search algorithm allows the model to generate not only an estimate of each molecule’s antimicrobial activity, but also a prediction for which substructures of the molecule likely account for that activity. Potent activity To further narrow down the pool of candidate drugs, the researchers trained three additional deep learning models to predict whether the compounds were toxic to three different types of human cells. By combining this information with the predictions of antimicrobial activity, the researchers discovered compounds that could kill microbes while having minimal adverse effects on the human body. Using this collection of models, the researchers screened about 12 million compounds, all of which are commercially available. From this collection, the models identified compounds from five different classes, based on chemical substructures within the molecules, that were predicted to be active against MRSA. The researchers purchased about 280 compounds and tested them against MRSA grown in a lab dish, allowing them to identify two, from the same class, that appeared to be very promising antibiotic candidates. In tests in two mouse models, one of MRSA skin infection and one of MRSA systemic infection, each of those compounds reduced the MRSA population by a factor of 10. Experiments revealed that the compounds appear to kill bacteria by disrupting their ability to maintain an electrochemical gradient across their cell membranes. This gradient is needed for many critical cell functions, including the ability to produce ATP (molecules that cells use to store energy). An antibiotic candidate that Collins’ lab discovered in 2020, halicin, appears to work by a similar mechanism but is specific to Gram-negative bacteria (bacteria with thin cell walls). MRSA is a Gram-positive bacterium, with thicker cell walls. “We have pretty strong evidence that this new structural class is active against Gram-positive pathogens by selectively dissipating the proton motive force in bacteria,” Wong said. “The molecules are attacking bacterial cell membranes selectively, in a way that does not incur substantial damage in human cell membranes. Our substantially augmented deep learning approach allowed us to predict this new structural class of antibiotics and enabled the finding that it is not toxic against human cells.” The researchers have shared their findings with Phare Bio, a nonprofit started by Collins and others as part of the Antibiotics-AI Project. The nonprofit now plans to do more detailed analysis of the chemical properties and potential clinical use of these compounds. Meanwhile, Collins’ lab is working on designing additional drug candidates based on the findings of the new study, as well as using the models to seek compounds that can kill other types of bacteria. “We are already leveraging similar approaches based on chemical substructures to design compounds de novo, and of course, we can readily adopt this approach out of the box to discover new classes of antibiotics against different pathogens,” Wong said. Adapted from a story published by the MIT News Office. 	researchers bacterium antibiotic class bacteria bacterial new scientists candidates broad news		2023-12-20											Anne Trafton, MIT News Office	320	0
New method tags cells with location coordinates for single-cell studies	When a scientist wants to study individual cells at the molecular level within an organ like the heart or brain, they usually break the tissue up to analyze the cells. This provides rich detail about gene activity, but doesn’t retain information about the cells’ location in the tissue. Now, scientists can capture both genetic and location information of individual cells using standard single-cell workflows in the lab. A new method developed at the Broad Institute of MIT and Harvard lets researchers attach precise location tags to individual cell nuclei that they can then isolate for a variety of single-cell experiments, while still collecting information about the cells’ original location in tissue. The new method, known as Slide-tags, was developed by the labs of Fei Chen, a Broad core institute member, a former Merkin Institute Fellow at Broad, and an assistant professor of stem cell and regenerative biology at Harvard University, and Evan Macosko, an institute member in the Stanley Center for Psychiatric Research at Broad and an associate professor at Massachusetts General Hospital. Slide-tags builds on another approach, Slide-seq, which was developed by the same labs and can map spatial patterns of genetic activity within tissues, but doesn’t reach single-cell resolution like the new Slide-tags method. “With this new approach, we figured out a way for scientists to do all the single-cell experiments that they are already doing while still knowing exactly where a cell comes from,” said Chen. “This is the first time anyone has been able to completely merge the worlds of spatial data and single-cell data.” The team describes Slide-tags today in Nature and also showed how they used their technique to study cells within tissues including human brain, tonsils, and a melanoma tumor. “We’ve shown how you can leverage spatial data to discover new biology that you would never turn up if you were just doing standard single-cell experiments,” said Macosko. “Our experiments go beyond just looking at the genes being expressed in a given cell,” said Andrew Russell, a postdoctoral fellow at Broad and a co-first author on the study. “Slide-tags is compatible with virtually any single-cell sequencing assay, and so brings high-resolution spatial information to single-cell measurements of the cell’s genetic sequence and epigenetic regulation as well.” Jackson Weir, a graduate student, and Naeem Nadaf, a research scientist, both at the Broad, are also co-first authors on the study. 	cell scientist biology cells labs harvard studies tags new scientists broad news		2023-12-13											Sarah C.P. Williams	321	0
Scientists map the locations of hundreds to thousands of cell types across a mammalian brain 	Since the invention of the microscope, scientists have been painstakingly inspecting the neurons and other cell types that make up the nervous system to unravel their roles in health and disease. In recent years, single-cell methods have allowed researchers to identify new brain cell types, but they also wanted to know where those individual cells are in the brain, because their location can influence their function. Now, two teams of scientists at the Broad Institute of MIT and Harvard have mapped the mouse nervous system with unprecedented depth and scale using recently developed technology called spatial transcriptomics, which can reveal not just the gene activity of individual cells, but also their locations within tissues and organs. The two atlases, described in Nature, delineate hundreds to thousands of cell types across the mouse brain, revealing surprising cellular diversity in understudied brain regions and offering more precise and comprehensive looks at brain structures than were possible before. One study was led by senior authors Evan Macosko, an institute member at the Broad and associate professor and attending psychiatrist at Massachusetts General Hospital, and Fei Chen, a core institute member at the Broad and an assistant professor in the Department of Stem Cell and Regenerative Biology at Harvard University. The other study was led by senior authors Xiao Wang, a Broad core institute member, a Merkin Institute Fellow, and an assistant professor of chemistry at MIT, and Jia Liu, an assistant professor of engineering at Harvard University. The studies are part of a package of 10 papers in Nature that take distinct, yet complementary, approaches to mapping the mouse nervous system at the single-cell level. The studies are from groups at the Broad, Allen Institute for Brain Science, the Salk Institute for Biological Studies, and other institutions that are part of the National Institutes of Health’s Brain Research Through Advancing Innovative Neurotechnologies® Initiative, or The BRAIN Initiative — Cell Census Network (BICCN). Together the papers describe the first complete cell type atlas of a whole mammalian brain. The team led by Macosko and Chen took an unbiased approach to measure activity of all genes in the genome of individual cells throughout the mouse brain, and assigned the cells’ locations within the tissue. Their analysis uncovered an estimated 90 percent of all cell populations in the mouse brain. The scientists found most cellular diversity within relatively understudied subcortical areas of the brain, especially the midbrain, pons, medulla, and the hypothalamus. “We suspected the most diversity would be found in these areas, so we prioritized them in our profiling,” said Macosko. “A lot of the real nuts and bolts stuff that a brain is doing is in these basic areas, which have received very little attention compared to the cortex. Our results underscore the need to study them more deeply.” The researchers also discovered clues about cellular function and the potential roles of brain structures in disease. “Efforts like these generate crucial resources for the neuroscience community, because the brain is so enormously complicated,” said Chen. Macosko added, “Our atlas represents the culmination of a decade of work at the Broad. Fei and I developed the technology in our labs and used it to process the largest single-cell and spatial dataset ever generated, leading to the first comprehensive atlas of cell types in a mammalian brain.” The package also includes the spatial, single-cell atlas of the mouse brain and spinal cord that was led by Wang and Liu and was first published online in September in Nature. Independently of BICCN, the team used a spatial transcriptomics technology they developed to analyze the expression of more than 1,000 genes and detail the locations of individual cells with unparalleled sub-cellular resolution. They identified hundreds of cell types, generated highly precise, molecularly defined tissue maps of the mouse brain and spinal cord, predicted the spatial single-cell expression profiles of more than 10,000 additional genes, and demonstrated their method’s utility in revealing which cell types and brain regions are accessible with gene-delivery viruses. “Our atlas represents the largest spatial single-cell dataset our lab has analyzed to date,” said Wang. “This resource provides a foundation for future work to further explore the roles of various genes, cells, and tissue regions in health and disease.” An unbiased, comprehensive atlas In the study from the Macosko and Chen labs, the scientists worked together to develop their spatial transcriptomic approach and apply it across the entire mouse brain. They also relied on the expertise of members of the Broad’s Genomics Platform and the team that supports Hail, an open-source tool for scalable genomic analysis. The researchers identified several thousand unique cell populations, and mapped their locations in the whole tissue with near-cellular resolution. They estimated that their analysis captured about 90 percent of cell types in the mouse brain, including a large diversity in underexplored areas of the brain. The researchers created an online browser to house and share their datasets with the scientific community. 	cell neuroscience hundreds thousands mammalian labs transcriptomics neurotechnologies scientists broad news		2023-12-13											Leah Eisenstadt	322	0
Approach studies how rare gene variant pairs contribute to disease	Each gene in the human genome has two copies. When researchers detect two mutations within a particular gene in a patient’s genome, it can be difficult or expensive to determine if those two mutations are present in the same copy of the gene (“in cis”) or different copies of the gene (“in trans”). A team led by investigators at Massachusetts General Hospital (MGH) and the Broad Institute of MIT and Harvard recently developed a strategy for inferring which of these phases is present for rare variant pairs within genes. As reported in Nature Genetics, the work will be helpful for interpreting findings from clinical genetic testing — especially for recessive diseases, which arise when both copies of a gene are impacted by a damaging genetic variant. For the study, researchers analyzed sequencing data of the expressed genes — or the protein coding regions of the genome — from 125,748 individuals from the Genome Aggregation Database (gnomAD), a large international public open-access human genome resource. The team applied a statistical method called an expectation-maximization algorithm to the genetic data from gnomAD to estimate whether a pair of rare variants are seen in cis or in trans. “Our method to estimate the phase of rare variants was 96% accurate in two independent datasets, including a set of patients with recessive Mendelian conditions,” said senior author Kaitlin Samocha, an assistant investigator in the Center for Genomic Medicine at MGH and an associated scientist in the Program in Medical and Population Genetics at Broad. “The accuracy of our approach remained high even for very rare variants and across genetic ancestry groups.” Additionally, the investigators, including co-first authors Michael Guo and Laurent Francioli, found that only a small number of genes were impacted by loss-of-function variants predicted to be in trans, which would be predicted to lead to the complete loss of that protein. In most individuals, if two rare loss-of-function variants were found in the same gene, the variant pair was in cis. Therefore, when a pair of rare loss-of-function variants is observed in the same gene in an individual in the general population, it is more likely that these variants are carried on the same copy of the gene rather than on different copies. “We have publicly released phasing predictions for over five billion pairs of rare variants seen in the gnomAD dataset, as well as our counts per gene of variant pairs predicted to be in trans, at gnomad.broadinstitute.org,” Samocha said. Although this work focused on estimating the phase of rare coding variants in expressed genes, Samocha and her colleagues hope to incorporate noncoding and other variant types in their phasing estimates. “Additionally, as more genome sequencing data become available, we will evaluate how our approach compares with more sophisticated phasing algorithms,” she said. “Finally, we will seek out more evaluations of the utility of our approach in a clinical genetic setting.” Adapted from a press release issued by MGH. 	variant gene medicine medical harvard genetic studies genetics rare disease broad news		2023-12-07											Tracy Hampton, Massachusetts General Hospital	323	0
Using 76,000 genomes, researchers build new map of regions of the human genome under natural selection	Every human’s genome has millions of genetic variants, but most have little to no effect, making it difficult for clinicians to make medical diagnoses based on genetic differences. Using patterns of variation from tens of thousands of individuals with whole-genome sequence data, a team led by investigators at Massachusetts General Hospital (MGH) and the Broad Institute of MIT and Harvard recently identified regions of the genome that lack typical variation, indicating that they are important sequences conserved during evolution and natural selection. The authors of the study, which is published in Nature, note that when a variant arises in one of these regions, it’s more likely to have an effect on an individual’s health. “We sought to examine how natural selection shapes patterns of human genetic variation across the whole genome, especially in the non-coding genome, which has been much less characterized than protein-coding regions,” said senior author Konrad Karczewski, an assistant professor in the Analytic and Translational Genetics Unit in the Department of Medicine at MGH and associate member of Program in Medical and Population Genetics at Broad. “While our previous work evaluated the 2 percent of the genome that encodes genes, our new metrics extend to the entire genome, greatly expanding our knowledge about which functional genomic elements likely harbor variation with potential clinical significance.” Karczewski and his colleagues — including co-first authors Siwei Chen and Lauren Fancioli, and co-senior authors Benjamin Neale of Broad and MGH and Daniel MacArthur of Garvan Institute of Medical Research in Australia — aggregated and processed information from 76,156 human genomes into the Genome Aggregation Database (gnomAD), a large international human genome reference resource that they have been expanding and releasing to the public continuously. The variants in this database have been helping clinical labs worldwide perform diagnoses of rare diseases, and this release greatly expands the ability to do so in non-coding regions. The team used the results to build a “genomic constraint map” for the whole genome (called Gnocchi, for Genomic NOn-Coding Constraint of HaploInsufficient variation). The map indicates which regions of the genome are “constrained,” meaning that when variants in the region occur, they are often too damaging and are removed from the population by natural selection. The team found that constrained regions are enriched for regulatory elements (which control gene expression) and variants implicated in complex human diseases and traits. The scientists also found that more constrained regulatory elements tend to regulate more constrained protein-coding genes, which in turn suggests that studying non-coding constraint can aid in the identification of constrained genes. “We anticipate that Gnocchi could be used to prioritize genetic variation discovered in non-coding regions of the genome in patients with rare diseases, which can potentially provide clues for genetic causes of diseases and starting points for targeted therapeutics,” Karczewski explained. Next, it will be important to add genomic information from other individuals into this newly developed dataset. “Future efforts towards a larger, more diverse human reference dataset would further improve rare disease diagnoses for all, and create better powered constraint metrics, giving us a better understanding of the distribution and effects of human genetic variation,” Karczewski said. Adapted from a press release issued by Massachusetts General Hospital. 	76 researchers genome harvard genetic build genetics scientists genomes broad news		2023-12-07											Tracy Hampton, Massachusetts General Hospital	324	0
New “dictionary” of immune responses reveals far more complexity in the immune system than previously thought	The immune system can carry out many biological processes, from killing viruses to fighting cancer, thanks in large part to approximately 100 key cell-signaling proteins called cytokines, which instruct immune cells what to do. Cytokines are also targeted by drugs for many diseases such as rheumatoid arthritis, COVID-19, and cancer, but until now, scientists haven’t had a comprehensive view of how different immune cells respond to different cytokines because the immune system is so complex. A new, large-scale reference created by researchers at the Broad Institute of MIT and Harvard could help scientists and clinicians better understand the role of cytokines in health and disease. The reference, called the Immune Dictionary, appears today in Nature. Using single-cell RNA sequencing to analyze gene expression in individual cells, the researchers have found how 86 major cytokines affect 17 immune cell types in mice. They found a surprising level of complexity in the immune system: Cytokines can trigger more immune responses, and immune cells can perform more functions than previously thought. The team also developed software for scientists, called Immune Response Enrichment Analysis (IREA), that they can use to identify the most active cytokines involved in a disease or drug response, and how different immune cells carry out different functions depending on which cytokine signal they receive. We spoke with Ang Cui, first and co-corresponding author on the study, formerly a postdoctoral researcher in Nir Hacohen’s lab at Broad and now an assistant professor at the Harvard School of Dental Medicine and Harvard Medical School (HMS); and Hacohen, a co-corresponding author, institute member at the Broad, and professor of medicine at HMS and Massachusetts General Hospital; about what makes their immune dictionary unique and how it could impact immunology research in this Q&A. What makes this study significant? NH: This is the first single-cell resolution dictionary of each major immune cell type responding to each major cytokine in vivo at an unprecedented scale. Typical studies of immune responses may look at roughly five immune cell types in a couple of conditions, whereas this study looked at nearly all major immune cell types responding to nearly all of the major cytokines. That’s more than 1,400 cytokine-cell type combinations — two orders of magnitude larger than typical studies, allowing the team to comprehensively document the complexity of the immune system. The scale was unique, but also, doing this at single-cell resolution was critical because it turns out that if you isolate a macrophage, there are actually different types of monocytes and macrophages. Single-cell resolution allows for a more natural view of those subsets. We also made the decision to do this in the mouse rather than in culture. There have been a lot of papers over the years where people take cells and stimulate them with cytokines in dishes in the lab, but we never knew what it meant in an animal. This was the first time we've done it in a physiological context. AC: This research could have far-reaching implications, accelerating our understanding of natural immune responses and human immune-related diseases. For many immune-mediated diseases, there's no cure or treatment. Some patients develop resistance to treatment and we cannot predict who they will be. There are many open questions, and having this foundational reference can significantly improve our understanding of the immune system. In the future, when doctors give patients cytokine therapies targeting the immune system, they could potentially look in the Immune Dictionary for expected cell-level immune responses. Did any results surprise you? AC: We found that both the immune responses to cytokines and the plasticity of immune cells were much more complex than we previously appreciated. Even IL-1β, one of the first discovered and most well-studied cytokines, induces much more complex responses than previously known. IL-1β can induce distinct responses in each cell type, which shows how a single cytokine can trigger a coordinated, multicellular immune response. This could only have been revealed by creating this kind of global map of every immune cell response to the cytokine. NH: The dictionary gave us many surprises. I was shocked by what we found about IL-1β. I think for many people, this will help them make sense of this central cytokine. AC: The study also showed us how plastic immune cells are. For example, macrophages are well known to be polarized into M1-like (proinflammatory) or M2-like (reparative) states (which helps determine their function), but we didn’t know how other immune cell types are polarized. We found that every immune cell type can be polarized into diverse states depending on which cytokines they receive. Natural killer cells, for example, can perform different functions depending on which cytokines we give them. How do you hope other scientists will use these findings? AC: Long-term, a more precise understanding of in vivo immune responses could enable precision medicine, overcoming current limitations for creating effective immunotherapies for a wide range of diseases. The dictionary could also be used for basic biology studies, if you want to know what cytokines can trigger a specific gene, for example. We’ve already used our software to interrogate the immune response in four diseases: lupus, cancer, COVID-19, and hepatitis C. It identified the most active cytokines for each disease. NH: If I were an immunologist working on my single-cell dataset in any disease or in any process, I would want to run a cytokine analysis using this new reference, because cytokines drive so many of the decisions. I hope our approach helps scientists make sense of any immune process, vaccine, disease, or therapy response, so that one can infer which cytokines are contributing to it. You could then block those cytokines in animal models and see what their roles are. We're excited to see what people will do with it. 	dictionary immunologist reveals cancer complexity medicine immune immunotherapies new scientists broad news		2023-12-06											Allessandra DiCorato	325	0
Count Me In patient-partnered research launches new project for Pediatric Hepatocellular Carcinoma (Pedi-HCC) and HCC-like tumors	"Count Me In (CMI), an initiative focused on patient-partnered cancer research, has announced the launch of a new cohort for individuals with hepatocellular carcinoma (HCC) and HCC-like tumors. Due to the rarity of these tumors, only a small number of patients have previously been in a position to provide their samples and clinical data for cancer research, until now. This cohort specifically encompasses pediatric patients with HCC (defined as diagnosed under the age of 21), as well as those with HCC-like tumors (referred to as mixed hepatoblastoma/HCC), aged 6 and above. Hepatoblastoma tumors diagnosed at or over the age of 6 years are believed to behave more similarly to a “mixed” hepatocellular carcinoma and hepatoblastoma (or HCC-like) tumor with features of both diseases. By enrolling those who have been diagnosed with HCN NOS or hepatoblastoma 6 years of age and above, CMI believes there is opportunity to be able to better understand the spectrum of these diseases and how to treat them. Participants do not need to be actively undergoing treatment to enroll. By engaging with patients directly, the new cohort will reflect comprehensive data from participants and their guardians, such as: medical history, genomic information, and unique experiences with cancer. The data will be freely released to the research community worldwide, following a de-identification process. ""Pediatric HCC is a rare and aggressive cancer that is challenging to treat,"" said Alli O’Neill of Dana-Farber Cancer Institute, a pediatric oncologist and lead researcher for the HCC cohort. ""Through Count Me In, we will be able to meaningfully collaborate with patients and families affected by these rare, under-studied tumors to gain a better understanding of tumor biology and to identify new treatments that can hopefully improve future outcomes for these children."" Count Me In is a patient-led initiative that empowers cancer patients living in the United States and Canada to share access to their medical records, their personal experiences, and biological samples for research. Count Me In is open to anyone who has been diagnosed with cancer living in the United States and Canada and currently has several other specific patient-partnered projects for various types of cancer (such as, metastatic breast cancer, brain tumors, and other rare diseases) and has collected data from over 12,500 patients to date. ""We are honored to launch this new cohort for pediatric HCC and to work with patients and families affected by this disease to accelerate research and improve outcomes,"" said Diane Diehl, Director of Count Me In. ""Our approach to empowering patients to enroll in research across other cancer types has continuously shown impactful results in increasing researchers’ availability to large datasets. We are committed to making this model available for rare disease communities where this valuable information is needed most.” Patients and/or their guardians interested in participating in the HCC or HCC-like project can visit JoinCountMeIn.org/PediHCC to learn more and sign up. The program is open to patients and/or guardians residing in the United States and Canada of all genders, ethnicities, and socioeconomic status, and participation is free of charge. "	research tumors pediatric carcinoma cancer patient hepatoblastoma tumor broad news		2023-11-28											Count Me In	326	0
Search algorithm reveals nearly 200 new kinds of CRISPR systems	Microbial sequence databases contain a wealth of information about enzymes and other molecules that could be adapted for biotechnology. But these databases have grown so large in recent years that they’ve become difficult to search efficiently for enzymes of interest. Now, scientists at the Broad Institute of MIT and Harvard, the McGovern Institute for Brain Research at MIT, and the National Center for Biotechnology Information (NCBI) at the National Institutes of Health have developed a new search algorithm that has identified 188 kinds of new rare CRISPR systems in bacterial genomes, encompassing thousands of individual systems. The work appears today in Science. The algorithm, which comes from the lab of CRISPR pioneer Feng Zhang, uses big-data clustering approaches to rapidly search massive amounts of genomic data. The team used their algorithm, called Fast Locality-Sensitive Hashing-based clustering (FLSHclust) to mine three major public databases that contain data from a wide range of unusual bacteria, including ones found in coal mines, breweries, Antarctic lakes, and dog saliva. The scientists found a surprising number and diversity of CRISPR systems, including ones that could make edits to DNA in human cells, others that can target RNA, and many with a variety of other functions. The new systems could potentially be harnessed to edit mammalian cells with fewer off-target effects than current Cas9 systems. They could also one day be used as diagnostics or serve as molecular records of activity inside cells. The researchers say their search highlights an unprecedented level of diversity and flexibility of CRISPR and that there are likely many more rare systems yet to be discovered as databases continue to grow. “Biodiversity is such a treasure trove, and as we continue to sequence more genomes and metagenomic samples, there is a growing need for better tools, like FLSHclust, to search that sequence space to find the molecular gems,” said Zhang, a co-senior author on the study and a core institute member at the Broad. Zhang is also an investigator at the McGovern Institute for Brain Research at MIT, the James and Patricia Poitras Professor of Neuroscience at MIT with joint appointments in the departments of Brain and Cognitive Sciences and Biological Engineering, and an investigator at the Howard Hughes Medical Institute. Eugene Koonin, a distinguished investigator at the NCBI, is co-senior author on the study as well. Searching for CRISPR CRISPR, which stands for Clustered Regularly Interspaced Short Palindromic Repeats, is a bacterial defense system that has been engineered into many tools for genome editing and diagnostics. To mine databases of protein and nucleic acid sequences for novel CRISPR systems, the researchers developed an algorithm based on an approach borrowed from the big data community. This technique, called locality-sensitive hashing, clusters together objects that are similar but not exactly identical. Using this approach allowed the team to probe billions of protein and DNA sequences — from the NCBI, its Whole Genome Shotgun database, and the Joint Genome Institute — in weeks, whereas previous methods that look for identical objects would have taken months. They designed their algorithm to look for genes associated with CRISPR. “This new algorithm allows us to parse through data in a time frame that’s short enough that we can actually recover results and make biological hypotheses,” said Soumya Kannan, who is a co-first author on the study. Kannan was a graduate student in Zhang’s lab when the study began and is currently a postdoctoral researcher and Junior Fellow at Harvard University. Han Altae-Tran, a graduate student in Zhang’s lab during the study and currently a postdoctoral researcher at the University of Washington, was the study’s other co-first author. “This is a testament to what you can do when you improve on the methods for exploration and use as much data as possible,” said Altae-Tran. “It’s really exciting to be able to improve the scale at which we search.” New systems In their analysis, Altae-Tran, Kannan, and their colleagues noticed that the thousands of CRISPR systems they found fell into a few existing and many new categories. They studied several of the new systems in greater detail in the lab. They found several new variants of known Type I CRISPR systems, which use a guide RNA that is 32 base pairs long rather than the 20-nucleotide guide of Cas9. Because of their longer guide RNAs, these Type I systems could potentially be used to develop more precise gene-editing technology that is less prone to off-target editing. Zhang’s team showed that two of these systems could make short edits in the DNA of human cells. And because these Type I systems are similar in size to CRISPR-Cas9, they could likely be delivered to cells in animals or humans using the same gene-delivery technologies being used today for CRISPR. One of the Type I systems also showed “collateral activity” — broad degradation of nucleic acids after the CRISPR protein binds its target. Scientists have used similar systems to make infectious disease diagnostics such as SHERLOCK, a tool capable of rapidly sensing a single molecule of DNA or RNA. Zhang’s team thinks the new systems could be adapted for diagnostic technologies as well. The researchers also uncovered new mechanisms of action for some Type IV CRISPR systems, and a Type VII system that precisely targets RNA, which could potentially be used in RNA editing. Other systems could potentially be used as recording tools — a molecular document of when a gene was expressed — or as sensors of specific activity in a living cell. Mining data The scientists say their algorithm could aid in the search for other biochemical systems. “This search algorithm could be used by anyone who wants to work with these large databases for studying how proteins evolve or discovering new genes,” Altae-Tran said. The researchers add that their findings illustrate not only how diverse CRISPR systems are, but also that most are rare and only found in unusual bacteria. “Some of these microbial systems were exclusively found in water from coal mines,” Kannan said. “If someone hadn’t been interested in that, we may never have seen those systems. Broadening our sampling diversity is really important to continue expanding the diversity of what we can discover.” 	neuroscience crispr bacterial algorithm new 200 scientists search genomes biotechnology broad news		2023-11-23											Allessandra DiCorato	327	0
A new method for prenatal genetic testing relies on just a blood draw	A team of investigators from Massachusetts General Hospital (MGH), Brigham and Women’s Hospital (BWH), and the Broad Institute of MIT and Harvard have developed a non-invasive genetic test that can screen the blood of pregnant individuals to survey all genes for fetal DNA sequence variants. The team evaluated the test by examining blood samples from 51 pregnant persons, finding that the test was able to capture variants that were inherited from the mother as well as new variants that were not present in the mother and associated with prenatal diagnoses. Results from their proof-of-principle analysis are published in the New England Journal of Medicine. “Our study suggests that it is feasible to screen most genes across the fetal genome using a blood test rather than requiring an invasive procedure such as amniocentesis,” explained senior author Michael Talkowski, director of MGH’s Center for Genomic Medicine, an associate professor of Neurology at Harvard Medical School (HMS), and institute member in the Program in Medical and Population Genetics and Center for Mendelian Genomics at Broad. Non-invasive prenatal testing (NIPT), also known as prenatal-cell-free DNA-screening, allows a pregnant individual to receive a blood test that screens for very large changes in fetal chromosomes such as an extra copy of chromosome 21, known as Down syndrome (trisomy 21); the gain or loss of entire copies of other chromosomes; the presence and number of X and Y sex chromosomes (indicating the sex of the fetus), and, more recently, for a small number of variants that are relevant for some fetal conditions. For many prenatal genetic diagnoses, however, it is necessary to determine individual nucleotide changes across the protein coding sequence of the genome, known as the exome. Exome screening currently requires genetic testing with an invasive medical procedure such as amniocentesis that involves significant cost and carries some inherent risks to the mother and fetus. The newly developed test could offer the capacity to discover and interpret variants across the fetal exome from DNA circulating in the mother’s blood. The method is referred to by the team as non-invasive fetal sequencing (NIFS). This high-resolution NIFS approach enabled the research team to survey the exome, discover sequence changes, and distinguish potentially pathogenic variants from likely benign variants inherited from the mother. They tested their NIFS approach on 51 pregnancies that spanned all three trimesters and were representative of the pregnant population receiving care at Massachusetts General Hospital and Brigham and Women’s Hospital. The NIFS screening method used a maternal blood draw without the need for a separate genetic test on the mother or father. The research team found that the method was highly sensitive for discovering single-base DNA changes and small insertions and deletions that were present in the fetal genome but not in the maternal genome, irrespective of the amount of fetal DNA detected. “In our retrospective analysis, we were able to accurately discover and predict fetal sequence variants from the NIFS approach with >99 percent sensitivity from the raw data and >90 percent sensitivity after filtering using our analysis methods,” said co-lead author Harrison Brand, an investigator in the department of neurology at MGH, and associate member at Broad, and an assistant professor at HMS. In 14 pregnancies referred for the current standard-of-care genetic testing that were also evaluated with the NIFS approach, NIFS detected all of the clinically relevant variants that were reported from invasive testing in the same individuals. The authors conducted this initial test on 51 pregnancies, but the findings suggest that the test could potentially be done on many samples. “The clinical implications of this research are potentially profound, particularly for pregnancies in which a fetal anomaly is suspected from ultrasound and an invasive test is indicated,” said co-senior author Kathryn Gray, an obstetrician and clinical geneticist at Brigham and Women’s Hospital and assistant professor of obstetrics and gynecology at HMS at the time of the study who is currently an associate professor at the University of Washington. “It has long been known that fetal sequence variants can be obtained from cell-free fetal DNA, and exome sequencing is already part of the standard-of-care, but it currently requires an invasive procedure,” Talkowski added. “These results suggest that non-invasive sequencing can likely capture the same genetic information from the fetal exome that is already being obtained in the standard-of-care, but from a blood test alone without the invasive procedure.” The team is currently working with other researchers to expand and validate these findings and to further develop the methods. “Our benchmarking suggests there is more room for optimization and that most variants currently captured in a standard exome test may be accessible to NIFS with further methods development,” says co-lead author Christopher Whelan, a computational scientist at the Broad Institute and the Talkowski laboratory. The team emphasizes that this is not currently a clinical test and that these early studies will need to be replicated in much larger samples. While this work is ongoing, Talkowski, Gray and their colleagues are already planning for how best to support patients as they navigate testing options and test results during pregnancy. As Gray notes, “We understand the fear and uncertainty that patients experience during pregnancy. In instances where a current standard-of-care test identifies an abnormality during prenatal diagnostic testing, we ensure that patients have access to a multi-disciplinary team, including maternal-fetal medicine and pediatric specialists, genetic counselors, and social workers to help patients understand complicated test results. Non-invasive tests, including currently available NIPT screening methods, will require the same support network.” Adapted from a press release written by Mass General Brigham. 	blood testing draw geneticist obstetrics gynecology genetic prenatal genetics ultrasound broad news		2023-11-23											Mass General Brigham Communications	328	0
Fairness, listening, and learning: A conversation with Broad’s chief equity officer	"Kedrick Perry got his start in diversity, equity, inclusion, and belonging (DEIB) work early in his career. As a doctoral student at the University of Virginia, he also worked as assistant director of graduate diversity programs where he designed and implemented various diversity initiatives. That kicked off a nearly 20-year career in DEIB at the University of Virginia, Suffolk University, University of California, Berkeley, and most recently at Loyola University New Orleans as vice president for equity and inclusion. He arrived at the Broad in September as chief equity officer and head of the Office of Inclusion, Diversity, Equity, and Allyship (IDEA). This early passion for DEIB work is rooted in Perry’s experiences growing up on a farm in rural North Carolina as the first person in his family to go to college and also to earn a master’s and doctorate degree. Picked on as a child “because I was different,” Perry says he always wanted to participate in clubs and programs in higher education that helped people “who came from places where they felt their voices could not be heard.” “Twenty years later, I'm still doing this work,” said Perry. “It's a calling for me.” Perry recently spoke at an event at Broad about how he thinks about DEIB, what he hopes to achieve at Broad, and what keeps him motivated, as well as a bit about his life outside of work (it includes reading, murder mystery and science fiction shows, and disco). The following text has been edited for length. A short video clip of Perry speaking at a recent Broad event about equity and his role at the institute. What brought you from a small town in North Carolina to here? Two things. One was reading. Reading was my way to learn about the world. On Friday nights during high school, people would go to see the movies or go out with their friends. I went to Barnes and Noble. That was exciting to me. Reading allowed me to know that there was more outside of Oak City, North Carolina. Second thing was: I didn't have many friends growing up, so I watched a lot of TV. And I watched a show called Dallas, which was about a rich oil family. And I said: ‘This is so amazing. These people are so rich, they can do anything they want.’ That seemed kind of unfair, that rich people can do anything they want. I loved the show, but it also made me think: ‘What about the rest of us?’ I want everybody else to have a fair shot at this too. So I think that's how I evolved. I knew that I wanted to help other people get fair shots and by reading, I learned that the world could be my oyster. What are your goals here at Broad? To listen and to learn. Many people come into a new place and say they're going to change this and that, without actually knowing the place. For me, I’m taking it back a few steps. I have to meet people, learn their identities, and learn how those identities interact with Broad and how Broad approaches those identities. I need to learn about the people here. I need to listen to their concerns and try to understand also how I fit into Broad, how I can work most effectively here. I think part of my job here, and it’s one of my priorities, is to try to be more targeted in our outreach. If we do a DEIB program, yes, often, it’s the same people who come all the time, but for me, I want some of those PIs who never come. I want some of those administrators who never come. So I’m going to meet people and let them know who I am, what I believe in, my vision, and to try to get them involved. I’m not necessarily saying my vision's the correct one, but I want people to understand how I go about doing things and let them know that DEIB is not only about increasing the number of Black and Brown people in the pipeline. It's about providing safer spaces for all people. It's about psychological safety. Can you talk more about that? What does DEIB mean to you? I think there’s a stereotype of DEIB work, that we're only about increasing representation. It’s about more than that. Equity is about fairness. Equity is not equality. Equality is sameness. You can't have equality until you have equity. So I'm going to try to make sure what we do here is fair, not just for underrepresented groups or marginalized groups, but for all Broadies, because I'm not just the chief equity officer for Black Broadies. I'm the chief equity officer for all Broadies. What do you hope Broad will look like in a year or two? In the short term, there will be more psychological safety here. Some Broadies might not feel safe at home, but when you come here you should be safe, physically safe and psychologically safe. That's what we're working towards. Over the long term, I want Broad to be a place of innovation in DEIB, where people say, ‘Oh, do you know what they're doing at Broad? They're ahead of the game. We haven't done that before.’ Diversity has gotten a very bad rap for being stale, that it’s all about seeking out problems. No, it's about seeking out opportunities, and it's about making change. And I want us to be at the forefront of that change in STEM. What are some things you accomplished at Loyola? Loyola has a lot of activist students who are really concerned and caring. When I got there, I found that our students wanted more space to build community, and so one of my first goals there was to open a multicultural center. Through a lot of advocacy and using my cache of being a new person and the grace that was given to me, I was able to get a central space and open Loyola’s first ever multicultural center. Another thing that I was very proud of is that I started the first international program for a DEI office within the Association of Jesuit Colleges and Universities (which Loyola belongs to). I wanted to provide students with the opportunity to study in another country, because the learning is in the immersion, particularly for students who had never traveled before. We went to Mexico City for two weeks to learn about activism, social justice, and the region’s history. It was phenomenal, and the best part, it was completely free for all students. I had to do a lot of fundraising for it. It was an amazing opportunity. I’m also very, very proud that I helped increase the number of underrepresented faculty members of color. That was not easy, but we had to be very intentional. We had to come up with a recruiting strategy. We had to go to places we had not gone to before to try to get these faculty members to come to Loyola. Why do you do this work? For me, this work is very personal. We choose this work because we care about people. We care about making spaces better. We care about making change. Another reason I do the work I do, is to make the path easier for people who come after me. There's a philosophy in western Africa called sankofa. I think it's in the Twi language and it really means ""to go back and get."" And it has evolved into going back and bringing people up to where you are. That's how I view my role here: it's about going back and bringing people up. Because if you're in this room, you are very fortunate. You have a privilege. And when we are awarded, earned, blessed with a privilege, it's not for us to keep this, it's for us to use this to help other people. That's what we should be doing, is going back and bringing other people up with us. That's how we keep the world moving. A short video clip of Perry speaking about what drives him in his work. "	president graduate conversation jesuit listening learning officer doctoral equity doctorate broad news		2023-11-15											Corie Lok	329	0
#WhyIScience Q&A: A computational biologist uses physics to find hidden patterns in cells	Niranj Chandrasekaran has always loved the night sky. Growing up, he spent nights on the terrace outside his family’s house in Chennai, India with his dad, a software engineer who’d studied physics. Together, they searched for meteorites and stared up at constellations, looking for patterns among the stars. Today, Chandrasekaran is still looking for patterns, this time in biological imaging data. After receiving his PhD in biophysics from the University of Chapel Hill at North Carolina, he joined the Broad Institute of MIT and Harvard as a postdoctoral associate in the Imaging Platform. There, he led the Joint Undertaking in Morphological Profiling with Cell Painting (JUMP-CP) consortium in creating the JUMP-CP database — a public reference collection of cell images generated with the Cell Painting microscopy assay to accelerate drug discovery. Developed by Anne Carpenter, senior director of the Imaging Platform at the Broad and others, Cell Painting reveals subtle features in cell images, turning biological traits into quantifiable variables that reveal the effect of turning genes on or off, or treating cells with a drug. The dataset, which was released in November 2022, contains information from more than 2 billion cells and 140,000 samples. Chandrasekaran says it was the first publicly available dataset of its kind. He’s been involved in every stage of the process, including managing the 10 pharmaceutical companies and two nonprofit organizations contributing to the database, designing experiments, and creating data analysis pipelines. We spoke with Chandrasekaran about his early interest in the physical sciences and his favorite parts of the JUMP project in this #WhyIScience Q&A. When did you first become interested in research? I've always been interested in basic science and asking questions about how things work. Because of my interest in astronomy, I was initially drawn to the physical sciences. But growing up, science was something that you studied at school. I never thought I’d be able to do research on my own. Then I read a book about Albert Einstein and the theory of relativity. The idea of finding something new, no matter how small, got me interested in research. During undergrad, I worked in industrial biotechnology, which is a combination of biology and physical sciences, so I was able to focus on doing biology research and scratch my itch for the physical sciences. When I came to the US to do my PhD, I shifted into molecular biophysics and studied how proteins wiggle inside the cell. Studying protein dynamics, you use the same kinds of equations and physics that you use to study planetary motion. I felt like a physicist. Afterwards, I had a brief foray into the world of genomics, and then I found image-based profiling at the Broad. I saw that all the coding and data analysis skills that I gained during my PhD translated into this space. I've shifted between a lot of fields within biology, which can be challenging, but I've always taken the experience I've gained from one of those fields and applied them to another. I think that’s given me a unique perspective. What is image-based profiling and what kind of impact do you hope it will have? Image-based profiling involves converting biological images into numbers and finding patterns in those numbers. We perturb cells — add chemical compounds to them, or knock out or over-express genes — and then study the impact of these changes on the cell by taking images of them. This methodology is gaining popularity, especially in pharmaceutical companies and biotechs who are interested in using it to figure out how chemical components work in a high throughput manner. It can also be used for screening compound libraries to identify potential drug candidates and assessing toxicity of drug candidates. Nowadays, drug discovery ends up being an extremely costly process because the research required at the initial discovery phase can be very time-consuming. Any way we can accelerate that process will help bring down the cost. What does an average day look like for you? My work has changed quite a lot over the last three years because in the beginning phase of the project, we were planning experiments. Now that the dataset has been generated, we’re focusing completely on data analysis. This is my bread and butter. I’d been waiting almost three years to get the data and immerse myself in it, trying to find interesting patterns. Data analysis can be frustrating when the numbers don’t make sense, but when I’m reminded of the translational impact my work could have and how it could help someone who is going through something difficult, I get motivated. What advice do you have for young scientists interested in biology? Don’t get bogged down by the pressure to decide which direction your career should go when you're a teenager. It's okay to take your time. I've been able to shift through so many fields. As long as you’re in an environment that encourages active learning, you'll be able to use the skills that you've gained and get up to speed. It's totally fine to explore, and you never know what fields are right around the corner. Image-based profiling didn't exist when I was an undergrad. I never could have predicted this when I was younger. How do you hope this field will develop in the next 10 years? The progress we've had in image-based profiling is in part due to advancements that have been happening in computer vision, where people have been coming up with new methods to extract information from images. In the past, when people invented new things, it might take a few years before it was used in our field. But now, whenever something new comes in computer vision, people adapt it immediately. I’m looking forward to the next decade and the advancements in computer vision and deep learning and how they’ll impact biology. I think this is the right time to be in this field. We’ve started generating large data sets. And people are going to start using these data sets and taking methods from other fields and making discoveries. In the past 10 years, we’ve overcome a lot of the problems any nascent field would have. Now, we can reap the rewards and make impactful discoveries. 	physics cells hidden physicist biotechs biophysics computational scientists biologist biotechnology broad news		2023-11-14											Allessandra DiCorato	330	0
Gerstner Center for Cancer Diagnostics receives additional commitment from Louis V. Gerstner, Jr., to advance technologies that could transform cancer care	"The Broad Institute of MIT and Harvard has received a new $20 million commitment by Louis V. Gerstner, Jr., former CEO and chairman of the board of IBM Corporation, and former chairman of the board of directors of the Broad Institute. This commitment to the Gerstner Center for Cancer Diagnostics includes $10 million for current support for the Center and $10 million in endowed funding, adding to the $15 million originally committed by Gerstner and an initial endowment of $10 million from the Eli & Edythe Broad Foundation to establish the Center in 2019. Directed by Viktor Adalsteinsson, the Gerstner Center for Cancer Diagnostics aims to advance liquid biopsies for cancer detection and monitoring and other innovative approaches to cancer diagnostics that could potentially benefit millions of patients worldwide. Liquid biopsies enable clinicians to find and analyze tumor DNA in a patient’s blood sample to detect cancer early, monitor cancer recurrence, assess the patient’s response to treatment, and measure other clinically important features in real time, without invasive procedures. The initial focus of the Gerstner Center is to develop an ultrasensitive liquid biopsy test to detect minimal residual disease (MRD) — the presence of tumor cells in the body after treatment. Doing so would guide treatment decisions, such as whether to continue therapy. ""We always knew that detecting cancer recurrence with a blood test would be an incredible feat, and the scientists in the Gerstner Center have risen to the challenge,"" said Todd Golub, director of the Broad Institute and faculty at Dana-Farber Cancer Institute and Harvard Medical School. ""This generous additional commitment recognizes this team’s incredible progress, and will enable them to expand on these efforts and make an even bigger impact on the field."" Adalsteinsson added, “With the continued visionary partnership of Lou Gerstner, we can expand on the kind of high-risk, high-reward work that in our first few years has begun to establish and advance technologies of transformative potential for cancer patients.” Although liquid biopsies could profoundly improve cancer care, they still need to be much more sensitive to reliably and accurately detect cancer at its earliest stages, identify MRD before relapse, and uncover clinically significant features that could inform cancer care. Since its launch, the Gerstner Center has been initially focused on improving liquid biopsies for MRD detection, which requires much higher levels of sensitivity. The challenge, however, is twofold — they are seeking not only to improve the sensitivity of the test, but to do so in a way that keeps costs down, a necessary step to make it an accessible tool in clinical settings. To overcome these hurdles, Gerstner Center scientists developed a method called MAESTRO, which detects low-abundance mutations using up to 100-fold less sequencing. The team is using MAESTRO to test for thousands of cancer mutations in a patient’s blood draw to achieve 10- to 100-fold higher sensitivity for MRD detection than existing methods. The MRD test is being used to analyze hundreds of samples from cancer patients, with promising data showing its ability to discern which patients respond to preoperative chemotherapy. Earlier this year, the Broad entered into an agreement with Exact Sciences to further develop the MAESTRO MRD test for clinical use. Such a test could help physicians detect recurrences earlier, intervene sooner, and tailor therapy to each patient. In addition to MAESTRO, Gerstner Center scientists have developed other promising new technologies, including CODEC, a technique that helps generate highly accurate sequencing data at low cost. The approach has potential uses beyond cancer diagnostics, and indeed, in other diseases beyond cancer. In addition, the team developed Duplex-Repair, a novel DNA repair method that could further enhance the accuracy of CODEC and MAESTRO, along with other sequencing methods. The researchers are also developing, together with the labs of Sangeeta Bhatia and J. Christopher Love at MIT, the first priming agents for liquid biopsies. These are injections given to a patient prior to a blood draw to boost the amount of tumor DNA recovered from a blood sample, enabling increased sensitivity. The additional commitment from Gerstner will allow the Gerstner Center to continue optimizing its MRD test; to push DNA sequencing to its limits using CODEC, Duplex-Repair, and other advances; to further develop priming agents that could enable more sensitive liquid biopsy testing; and to continue innovating to address other major unmet needs in cancer diagnostics. “I first partnered with the Broad to launch the Gerstner Center in order to impact clinical care for cancer patients, and I’ve been pleased to see that Viktor and his team have created an engine of innovation that could transform not only cancer treatment but possibly other fields as well,” said Gerstner. “That is why I’ve chosen to double down on this partnership and I am excited to see what emerges from the Center’s next phase.” "	diagnostics 2019 ceo cancer chemotherapy technologies harvard transform gerstner broad news		2023-11-13											Broad Communications	331	0
Cellular atlas built to guide precision treatment of rheumatoid arthritis	Rheumatoid arthritis (RA) is an autoimmune disease characterized by inflammation that leads to pain, joint damage, and disability, which affects approximately 18 million people worldwide. While RA therapies targeted to specific inflammatory pathways have emerged, only some patients’ symptoms improve with treatment, emphasizing the need for multiple treatment approaches tailored to different disease subtypes. To more precisely define cellular drivers of RA, an international research consortium co-led by researchers from the Broad Institute of MIT and Harvard and Brigham and Women’s Hospital analyzed tissues from RA donors at the single-cell level, integrating multiple forms of analysis to stratify RA by six subtypes of inflammation. The findings, published in Nature, shed new light on the variety of cellular causes of RA, which may inform more targeted, effective and patient-tailored therapeutic approaches. “In the treatment of individuals with rheumatoid arthritis, we struggle to find the right treatment for the right patient,” said corresponding author Soumya Raychaudhuri of the Brigham’s Division of Rheumatology, Inflammation and Immunity and the Broad Institute, where he is an institute member in the Program in Medical and Population Genetics. “We aimed to determine why some subsets of patients don’t respond to conventional treatments by looking at the subtypes of inflammation. We did so from many different angles, using multiple cutting-edge, single-cell techniques and integrating results in a way that hasn’t been done before for an inflammatory disease.” The findings from the study represent a major milestone in the Accelerating Medicines Partnership Rheumatoid Arthritis and Systemic Lupus Erythematosus program, a public-private partnership launched in 2014 to advance molecular- and cellular-level understandings of autoimmune diseases and identify promising drug targets. Through collaboration with researchers and clinicians across the US and UK, the investigators analyzed 79 donor samples of synovial tissue, the inflamed tissue in RA that normally helps cushion and sustain joints. In particular, the researchers examined tissue from patients with new-onset disease and from patients unresponsive to treatment to better identify both the initial drivers of RA as well as those of refractory disease. To “deconstruct” RA pathology on a cellular level, the researchers combined surface protein data and histologic analysis with multiple forms of single-cell RNA-sequencing and bulk RNA sequencing. Despite the variety of methods used to analyze over 314,000 cells, the researchers consistently found evidence of six major types of inflammation, which they stratified by associated cell type, called cell-type abundance phenotypes (CTAPs). While some CTAPS, such as those enriched with T and B cells, were expected finding for an autoimmune disease like RA, the researchers were surprised to see CTAPs associated with structural cells such as fibroblasts and endothelial cells, with relatively few inflammatory leukocytes. They also found that patients’ CTAPs were dynamic and could change over time in response to treatment. Going forward, the researchers aim to expand upon their knowledge of the cell types involved in RA by studying how interconnections between cells promote disease states. Furthermore, they hope this work will encourage increased synovial tissue analysis in RA patients, which is currently not standard practice. While blood tests are more common in RA patients, findings from this study and others emphasize that the cellular profile of synovial tissue differs substantially from that of blood. “What this study shows is that the tissue matters,” said co-senior author Michael Brenner of the Brigham’s Division of Rheumatology, Inflammation and Immunity. “Our findings point to the value of getting synovial tissue biopsies to evaluate the nature of the pathological process, which can be so different across patients. Clinical trials going forward will benefit greatly from assessing tissue characteristics alongside responses to a therapy. By providing this atlas of cell types and pathways involved in RA, we are better able to pursue our precision medicine goal of being able to select the right drug for the right patient and achieve a high response rate.” Co-first authors of the study are Fan Zhang (University of Colorado Anschutz Medical Campus), Anna Helena Jonsson (BWH), Aparna Nathan (Harvard University), and Nghia Millard (BWH). Co-senior authors alongside Raychaudhuri and Brenner are Kevin Wei (BWH), Deepak Rao (BWH), Laura Donlin (Hospital for Special Surgery) and Jennifer Anolik (University of Rochester Medical Center). Adapted from a press release issued by Brigham and Women's Hospital. 	arthritis pathology rheumatoid treatment rheumatology surgery cellular atlas broad news		2023-11-07											Brigham and Women's Hospital Communications	332	0
Q&A: How generative AI could help accelerate biomedical research	The recent explosion of generative AI tools has prompted many discussions in virtually all fields about the benefits and risks of these technologies. These tools, including ChatGPT, Bard and others, have been trained on huge amounts of content and can produce text and images that often look eerily like human-generated content. At the Broad Institute of MIT and Harvard, a group of researchers, software engineers, administrators, and communicators (yes, us) has been exploring the use of these chatbots and similar tools, surveying the community and developing recommendations. To dive deeper into this topic, we spoke with Mehrtash Babadi, an institute scientist, director of computational methods, and a machine learning and AI expert in Broad’s Data Sciences Platform. He talked about how generative AI techniques can be used not just to analyze human language but also the language of genes and cells — raw biological data — to shed light on how cells and tissues work in health and disease. He also shared his thoughts on the benefits of language-based generative models like ChatGPT, Bard, and GitHub Copilot for writing computer code, developing hypotheses, and other tasks. “I think these systems will become increasingly useful not only for software engineers and programmers, but also for basically everyone else in every profession in the same sense that a search engine has become an indispensable part of our lives for accessing information,” said Babadi, who routinely uses ChatGPT to search the internet and write emails and research summaries. The following conversation was edited (by humans) for length and clarity. How have you been thinking about generative AI in biology? Generative AI is something that has been brewing for a long time in the machine learning community, going back to the fundamental tenets of Bayesian statistics. We've been using those for a long while, for modeling various aspects of biology like genomic variation, experimental artifacts, single-cell biology, and other areas. Now with the advancement of these models, their combination with deep neural networks, vast amounts of training data and computing power, and in particular the progress of these models in generating images and natural language, they have really exploded and all of a sudden everybody is excited about them. We are now thinking about how the same approaches that have been so successful in modeling natural language and images could be used for learning the intrinsic, innate language of biological systems like cells and tissues, and predicting their fate and response to various stimuli in silico. That's an area of active research for us, and we have made a little bit of headway, but there's a lot of work that needs to be done. Can you explain more about how generative AI can be used to analyze biological data? Right now, there's a lot of excitement about ChatGPT and similar conversational AI systems, and for good reasons, because these are really capable and powerful systems, and there's also a lot of emerging work in the field showing that these models also have a good grasp of biology. You can ask them questions like ‘what is the function of this gene?’ and they will tell you because they have read textbooks and papers. So the models have learned what we know about biology. And that's exactly the problem, because we don’t know much about many aspects of biology! Our understanding of biology is still evolving and is very biased and some of the literature is not even reproducible. The natural language models are trained on that substrate, and so they're subject to the same biases and incomplete understandings of biology that we are subject to. So we are trying to directly learn the language of biological systems from raw biological measurements and data without any human interpretation in between. How would a researcher use a generative model trained on raw biological data? For example, you can envision a generative model that’s been trained on biological data describing how certain tissues or cells work, and then using that model to generate data that describe new cell states or new tissues. You can even make models that you could prompt with something like ‘here's a cell in a tissue, generate another cell nearby’ to make predictions about how different cells might work together to form a tissue, as an example. These models could also be fine-tuned on interventional data, such as genetic or pharmacological screens, to learn to predict future screens. In a nutshell, generative models have the potential to computationalize many aspects of cell and tissue biology and perturbation screens. What becomes very interesting now is to interface these models of cells and tissues with natural language models. So we can take natural language models and the more unbiased and comprehensive models of cells, and then fuse them together into a system that is more powerful than each of them separately. That's an active area of AI research called multimodal generative AI, where one basically combines generative models of different modalities, or interface them together, and allow them to talk to each other. The advantage of this is that with the models based on the innate language of biology, you avoid the bias that's inherent in the natural language models of biology. But you can use the natural language models to allow a human scientist to put in the right prompts. What progress has been made in multimodal generative AI for biology? We do now have multimodal generative AI of natural language and text, natural language and images, but generative AI models of biological systems are still in their infancy. We have yet to see multimodal AI systems that combine natural language with the language of biological systems. Can generative AI be useful for hypothesis generation? One potential example I can think of is a typical drug development project, where we want to understand the underlying mechanism for a disease and then identify a therapeutic target. Right now, this is typically done through a combination of subject matter expert insights and the design of very smart experiments that test smart hypotheses using innovative techniques to manipulate cells and whatnot. But as we do more and more of these types of experiments, each of these experiments is a sort of lesson for a generative AI system that says ‘here's a cell and here's how we intervened and here's what happened.’ And the more of these lessons we catalog, the more we can teach a generative AI system to predict future experiments without us needing to do all of them in the lab. There is this immense opportunity to reuse all of the experimental data that we've collected so far. But won’t some of those predictions be wrong? Even if these generative models are sometimes wrong, they're not entirely wrong. This means that if, for example, you use them to identify a certain therapeutic target, if the systems are appropriately trained, it is highly likely that at least some of those targets actually make some sense. That's probably one of the best applications of these systems: to take their outputs as potential hypotheses and then subject them to experimental validation. Depending on the nature of the outcome, the resulting data from the follow-up experiments will either reinforce the model’s belief or correct it, ultimately making it slightly more accurate for future queries. Let’s talk about the natural language models like ChatGPT. How useful are these tools for coding and software development? Some of us use GitHub Copilot, which is a system that helps coders and programmers write some of the more standard, boilerplate parts of code, rather than the most innovative and challenging parts. These systems are really good at helping you write parts of your code that everybody knows how to write, but you still need to do it anyway. These systems are also really good at helping you document your code and comment on your code. So we’re using these systems right now for these purposes and as smarter versions of the conventional code-completion systems. Do you have any concerns about these language models, like inaccuracies or potential misuse? The challenge is that these models are well known to “hallucinate” once in a while or just very confidently lie. So you have to do your own fact-checking. As for misuse, I'm less worried about the science and engineering communities because scientists and engineers are, by training, skeptics and they tend to not take things at face value. So even if they use a generative AI system to help them solve a problem, they would test the output of these systems. I think where I'd be worried more is how these systems could be exploited in other areas, such as generating misinformation and in other discourses where people are not as inclined to do their own fact-checking. That's where I'm worried, especially because these systems can generate content much, much faster than we can. So it's very easy to flood the space, so to speak, with lots of deliberately false, AI-generated content. But as tools for biological research and software development, I think there’s a lot of promise in helping to make some parts of research more efficient. The pace at which we’re generating data, which is exponentially increasing, is far exceeding our expert capability to make sense of that data. That’s where generative AI and in general, machine learning and other AI methods, could become extremely useful to help us uncover the regularities, commonalities, and differences in all this data in a way that is less biased and also more efficient and faster than we humans can do. 	research accelerate help biomedical chatbots hallucinate scientists excitement ai internet broad news		2023-11-02											Corie Lok	333	0
Bayer and Broad Institute extend cancer therapy research collaboration	Bayer and the Broad Institute of MIT and Harvard have renewed their research alliance, adding five years to a 10-year collaboration that has already yielded three clinical oncology candidates. This research collaboration is aimed at identifying cancer targets and exploring novel therapeutic approaches in oncology with the goal of bringing more medicines to patients. “In order to make a meaningful impact on the lives of patients, academia and industry need to partner and draw on each other’s expertise,” said William Sellers, core member of the Broad Institute and director of the institute’s Cancer Program. “Through this alliance, Broad and Bayer have done just that. Combining Broad’s expertise in cancer biology and state-of-the-art drug discovery methods with Bayer’s expertise in drug development greatly increases our power to bring transformative medicines to cancer patients.” “We are constantly working to discover novel ways to treat this devastating disease that affects millions of people worldwide. Our joint goal is to bring innovation to cancer patients by building a robust, sustainable pipeline in oncology,” said Dominik Ruettinger, Global Head of Research and Early Development for Oncology, Pharmaceuticals Division, Bayer AG. “Bayer’s established collaboration with the Broad Institute has already resulted in three clinical oncology candidates over the past decade. We look forward to continuing our work with renowned Broad scientists to advance additional innovative cancer targets into clinical development.” Established in 2013, the Bayer-Broad collaboration is uniquely structured to encourage close coordination and ongoing, face-to-face interactions between researchers at both organizations. The research is guided by joint project and governance teams. In addition to identifying investigational drugs for novel oncology targets and generating the associated intellectual property, the organizations will continue to openly share the biological knowledge generated with the scientific community, including through publicly available datasets and publications in academic journals. As a result of this collaboration, Bayer’s mutant EGFR/HER2 inhibitor is currently in Phase I of clinical trials. This is the first reversible small molecule inhibitor targeting EGFR exon 20 insertion mutations and HER2 activating mutations to undergo clinical testing. 	research biology cancer harvard collaboration bayer therapy scientists pharmaceuticals broad news		2023-11-02											Broad Communications	334	0
New patient-partnered research project will study heart disease and diabetes risk in South Asian populations 	People of South Asian ancestry around the world have more than double the risk of developing cardiometabolic diseases like diabetes, heart attack, and stroke compared to other populations. Researchers still do not fully understand why, in part because people of South Asian descent are largely underrepresented in genomic and cardiometabolic research. Researchers at the Broad Institute of MIT and Harvard, Massachusetts General Hospital, Harvard Medical School, Stanford School of Medicine, and Yale School of Medicine are looking to uncover the reasons for this heightened risk by launching OurHealth, a study that partners with patients to collect and analyze genetic, medical, and lifestyle data, such as diet and exercise patterns. The team aims to uncover how genetics and lifestyle affect cardiometabolic disease risk in South Asian populations and how to potentially decrease that risk, including through the development of new drugs and lifestyle modifications. “A previous study of ours showed that South Asians living in the United Kingdom had double the risk of developing heart disease despite their clinical predicted risk being the same as others around them. This result was striking and it inspired us to build a resource to understand the drivers of this risk,” said Amit Khera, co-principal investigator of OurHealth, a cardiologist at Brigham and Women’s Hospital, and vice president of genomic medicine at Verve Therapeutics. “We're hoping to investigate the central question of: what genetic, lifestyle, and clinical risk factors create such a high rate of cardiovascular disease in South Asians across the globe? From there, we hope to find certain modifiable risk factors that we can act upon immediately,” said Romit Bhattacharya, medical director of OurHealth, associate director of the Cardiac Lifestyle Program at Massachusetts General Hospital, and an associated scientist at Broad. To participate in the study, adults living in the United States and with self-identified ancestry in Bangladesh, Bhutan, India, the Maldives, Nepal, Pakistan, and Sri Lanka can easily enroll for free on the OurHealth website. Participants will answer questions about their background, lifestyle, and medical history. Some participants will receive a kit in the mail that they can use to send a saliva sample for DNA analysis. Participants will be updated as the study progresses on how their contributions are enabling new discoveries. They will also have the opportunity to inform the researchers on whether their health status changes over time. This study will recruit participants through community organizations, social media, and by word-of-mouth. The OurHealth researchers hope that this grassroots recruiting effort will help them fulfill another important goal of the project: to raise awareness in South Asian communities about their increased risk of cardiovascular disease. “Once I started talking about this initiative, people around me said: ‘my father had a heart attack, or my brother had a heart attack at a young age, and I didn't even suspect that they were at risk.’ And so the community intuitively knows that the risk is there, but they haven't seen data in part because the data are so rare,” said Bhattacharya. In the pilot phase of the project, the OurHealth team will work with Broad’s Genomics Platform to sequence the DNA, including the protein-coding portion of the genome and the non-coding regions, using a cost-effective sequencing approach recently developed by the Platform called the Blended Genome-Exome technology. They will use the data they collect to create a reference, anonymized dataset that they will share with other scientists to drive more research. Most known genetic variants linked to cardiometabolic risk have been discovered using data from people of European ancestry. People of South Asian ancestry constitute less than two percent of participants in genomic studies. The researchers hope that the resource they are building will help scientists find additional genetic variants associated with risk in South Asian and other communities. “We hope that OurHealth data will lead to discoveries in many different areas and will establish new clinical trials or lifestyle modifications that will lower the risk of heart disease, diabetes, and stroke,” said Whitney Hornsby, the operations director of OurHealth. “Now, 1 in 4 individuals across the world are of South Asian ancestry and an increased cardiometabolic disease risk is present across the diaspora. However, the infrastructure to study the mechanisms that contribute to this risk has been notably sparse, which is a major factor in this glaring knowledge gap. We are eager to take a patient-partnered approach and combine it with the extensive expertise of several collaborators across the scientific community to address a major health disparity for South Asians,” said Pradeep Natarajan, co-principal investigator of OurHealth, director of Preventive Cardiology at Massachusetts General Hospital, and an associate member at Broad. The OurHealth study is structured similarly to Count Me In, a project founded by the Broad, Dana-Farber Cancer Institute, and the Emerson Collective, which gives people who live with cancer a way to directly impact cancer research through sharing their experiences with cancer, medical records, and genetic data. OurHealth uses a similar online platform that Count Me In uses, which was developed by the Broad’s Data Sciences Platform. The OurHealth team includes advisors from Brigham and Women’s Hospital, Flagship Pioneering, University of California San Francisco, Duke University, Google Ventures, and Verve Therapeutics. 	research cancer asians patient diabetes genetics partnered cardiologist disease broad news		2023-10-23											Makenzie Kohler	335	0
#WhyIScience Q&A: A research scientist uses mass spectrometry to discover how metabolites affect human health	Amy Deik remembers the day in fifth grade when she learned the water cycle. As she drew arrows connecting the evaporation, condensation, and precipitation phases, she thought, “This makes sense to me. This is how my brain works.” That interest in science led her to a weekend science course and a field trip to a plant research laboratory, where she saw scientists hybridizing roses and genetically modifying tomatoes. At 11 years old, she knew she wanted to be a botanist. Deik received her bachelor's degree in botany from Connecticut College and immediately went to work at International Paper, a paper manufacturing company, where she engineered trees to grow faster. She’d always had an interest in genetics research and moved to Boston in 2002 to work for a genetics-focused startup. In the mid-2000s, mass layoffs at the startup left only Deik and two other people to continue the company’s research. Deik had to quickly learn how to operate the firm’s mass spectrometers — machines that can measure tiny amounts of molecules such as metabolites and proteins. After the startup folded, Deik worked as an analytical chemist at a drug-repositioning company called Gene Logic, where she first met Clary Clish, who would later become the director of the Metabolomics Platform at the Broad Institute of MIT and Harvard. Deik moved to the Broad in 2009 and joined Clish as a biochemist in the Platform, where she also serves as lab manager. In this #WhyIScience, we spoke with Deik about metabolomics (the large-scale systematic study of metabolites) and the intersectionality of being a woman of faith and a scientist. What do you do as a research scientist at Broad? A lot of what we do at the Metabolomics Platform is look for early indicators of disease and use metabolomics to monitor disease progression. We do that with metabolite profiling — determining the levels of hundreds of metabolites in a sample and how that connects to human health. I run mass spectrometers daily to analyze thousands of small molecules that are present in a variety of samples, such as plasma, a mouse liver, or a cell culture. I run our lipid method, which annotates over 250 different lipids. I also serve as our group's lab manager. For us, that means a lot of sample management. We are involved in dozens of collaborations each year inside and outside the Broad, so I'm always on call when samples are coming in and out. I also maintain the freezer inventory, know what samples are waiting to be aliquotted into smaller volumes for our four platform methods, and determine what methods we need to run on those samples. How do lipids relate to human health? Lipids are a type of metabolite that are insoluble in water. They are diverse in size, polarity, absorption capability, and solubility. They serve essential functions in the body, such as making up all the membranes in our cells and transporting large molecules. A commonly known lipid species is triglycerides, which you get a blood test for at your annual physical, but there are also a lot most people have never heard of. Different classes of metabolites change in different disease states. You might expect to see a change in lipids when a person has a metabolism-related disease like diabetes or cardiovascular disease. But you might not expect to see a change in various cancers. A few years ago, we discovered a lipid biomarker that helps diagnose a rare lung disease in women called lymphangioleiomyomatosis, which at the time had no known genetic cause and was previously very difficult to diagnose. How is metabolomics evolving? In the last decade, scientists have revolutionized mass spectrometers’ speed, precision, and specificity. I used to only be able to detect the difference of a full mass-unit. Now the resolution of these instruments is less than 1 part-per-million, which can correlate to the fourth decimal position. A new technology we are adding to our platform is imaging mass spectrometry. With it, we can take slices of a specific tissue and ionize them with the spectrometer. The machine shows you specific molecule masses at different places within the slices. For example, you can see if molecules are in certain regions of a slice of a mouse brain and not others. It’s a brand new technology, so there are a lot of potential applications that we just don’t know yet. I'm curious to see how we use it and the insights it might give us. How does your work intersect with other parts of your life? I’m a woman of faith and it's interesting to be at the intersection of Christianity and science. Most people believe that you can only have one worldview or the other, but I've never had a problem with having both. I love the idea that, as a scientist, I’m allowed to want to understand the natural world around me. I believe that it’s a God-given right for us to figure out how things work and be fascinated by that. From conversations with people who share my faith, I think scientists can be viewed as scary people who do whatever they want just because they can. But I believe that scientists are, or try to be, very thoughtful, moral, and ethical in their work. And so I try to speak about science to people in a way that makes it understandable and therefore less scary. 	research scientist metabolites botanist spectrometry health startup botany lymphangioleiomyomatosis biochemist broad news		2023-10-17											Makenzie Kohler	336	0
Marvin Caruthers receives inaugural Merkin Prize in ceremony at the Broad Institute for DNA synthesis technology	The inaugural Richard N. Merkin Prize in Biomedical Technology was awarded to Marvin H. Caruthers of the University of Colorado Boulder in a ceremony and symposium at the Broad Institute on September 21, 2023. The prize, created by the Merkin Family Foundation and administered by the Broad, recognizes novel technologies that have significantly improved human health and carries a $400,000 award. Nominations for the 2024 Merkin Prize opened on September 6, 2023 and close on December 6, 2023 at 11:59 pm ET. Caruthers was announced as the winner in June for his development, in 1981, of an efficient, automated technology for synthesizing DNA. Caruthers’ innovation of chemical reactions that quickly assemble nucleotides into strands of DNA became an indispensable element of modern molecular medicine. Today, scientists use such reactions to produce the customizable DNA and RNA molecules that enable genetic sequencing, drug and vaccine development, pathogen tests, cancer diagnostics, and more. Caruthers recalled how, at a conference in 1975, he was openly questioned for working on the idea of synthesizing DNA. “One individual who is now a member of the US National Academy of Sciences said, ‘Marv, why in the world are you wondering how to synthesize DNA? You’re a bright guy, why don’t you find something else to do?’ But because of my [chemistry] background, I knew there was an enormous need for synthetic DNA in a large number of applications.” As a postdoc at the University of Wisconsin from 1968 to 1970, Caruthers worked in the lab of Gobind Khorana, who won the Nobel Prize in 1968 with Marshall Nirenberg and Robert Holley for research that interpreted the genetic code. Caruthers credited Khorana for inspiring him to pursue his work on DNA synthesis, despite the fact that there were many doubters at the time: “Gobind had the philosophy that if you want to break new ground in research, you have to walk the path alone. That was his philosophy, and he pounded that into me more than once.” Richard N. Merkin praised Caruthers for the scope and impact of his prizewinning research. “The biotech industry would not be what it is today if it weren’t for Marv,” he said. “The Broad would not be what it is, or maybe even exist, if it weren’t for Marv. His work demonstrates the type of technology used in the life sciences that impacts patients’ care. And for all of you young people in the audience, I’d like to make this prize shine a light on innovation — and on making sure that you do not embrace the status quo.” Nobel laureate Harold E. Varmus, the Lewis Thomas University Professor at Weill Cornell Medicine and chair of the Merkin Prize selection committee, applauded the prize’s emphasis on technologies that have made a significant impact on biomedicine. “There are a lot of prizes in biomedical science, but very few of them are focused on technology,” he said. “Yet we all know as scientists that it’s technology that drives discovery. In this case the prize is designed to honor not just technologies that are exciting in the laboratory but technologies that have had an impact on public health and clinical care.” Todd Golub, director and founding core institute member of the Broad Institute, thanked Merkin, whose philanthropic partnership with the Broad has spanned more than 15 years. “Like Eli Broad, Merkin is one of those rare philanthropists who is not only generous, but also sees the value in being patient and investing in technologies and fundamental science that someday will pay off and benefit humanity,” Golub said. “He’s been one of our most important partners, making much of what we do here at the Broad possible.” Merkin’s partnership with the Broad includes programs like the Merkin Institute Fellows, established in 2012 as the Broad’s first endowed fellowship; the Merkin Institute for Transformative Technologies in Healthcare, launched in 2017 to support paradigm-shifting projects from researchers at the Broad, Harvard, MIT, and the Harvard-affiliated hospitals; the Richard Merkin Professorship (also established in 2017), an endowed professorship held by David Liu, who leads the Merkin Institute for Transformative Technologies in Healthcare; and a generous new commitment in 2021 that advanced the aforementioned programs and launched the Merkin Prize. It was also in 2021 that, in recognition of Merkin’s partnership, the Broad named its building at 415 Main Street the Richard N. Merkin Building. The symposium portion of the program began with a talk by Tom Cech, Nobel laureate and Caruthers’ longtime colleague at the University of Colorado Boulder. Cech praised Caruthers’ humility and cited two more applications of Caruthers’ prizewinning invention: its use in forensics and in tools that allow us to trace our ancestries. Cech also described his own recent research, published in Science, in which he and colleagues used an epigenetic gene-silencing complex essential for cell differentiation and often deregulated in cancers to demonstrate that RNA, in addition to serving as a messenger, regulates the process of transcription itself. The next symposium speaker was Laura Kiessling, institute member at the Broad and Novartis professor of chemistry at MIT. Kiessling lauded Caruthers’ use of fundamental chemistry. “As someone who grew up as a synthetic chemist making complex molecules, I was really inspired by his work, because it shows the power of chemistry in studying problems of biomedical interest,” she said. For her talk, Kiessling outlined a method called Lectin-Seq, reported in Science, that she and colleagues developed to elucidate the role of human lectins — soluble carbohydrate-binding proteins — in regulating microbiota. Xiao Wang, an institute member at the Broad and a Merkin Institute Fellow in 2022, gave the third symposium talk, describing her lab’s work on next-generation mRNA therapeutics. As reported last year in ACS Chemical Biology, Wang’s lab developed a way to construct messenger-oligonucleotide conjugated RNAs with chemically modified tails, a strategy that reduced RNA degradation while increasing therapeutic protein expression in cells. Wang concluded her presentation by expressing gratitude to Merkin. “I’m really thankful for the support of the Merkin Fellowship,” she said. “It is because we had the Fellowship that we could buy our very first DNA and RNA synthesizer in the lab.” The final symposium speaker was Caruthers himself, who discussed his latest research using thiomorpholino oligonucleotides (TMOs) to induce exon skipping in a Duchenne muscular dystrophy in vitro model. As reported last year in PNAS, Caruthers and colleagues showed that their TMOs induce excellent exon skipping potency compared with controls. Their TMOs also performed well at low concentrations, meaning dosages can be minimized — important for their prospective development as therapeutics. For further information on how to nominate for the 2024 Merkin Prize, please visit the prize website. Eligibility extends to all investigators who have developed relevant health innovations, regardless of their place of employment, including academia, the commercial sector, or government. Both teams and individuals who have made a profound impact on medicine by pioneering a transformative technology are eligible. About the Merkin Family Foundation The Merkin Family Foundation was founded by visionary health care executive Richard Merkin, MD. Richard Merkin, MD is the founder and CEO of Heritage Provider Network, Inc. (HPN). HPN is one of the largest physician founded and physician owned managed care organizations in the country dedicated to value-based healthcare delivery improvements. HPN develops and manages coordinated, patient-doctor centric, integrated health care systems that offer some of the strongest solutions for the future of health, care, and cost in the United States. HPN and its affiliates operate in New York, California, and Arizona, providing high-quality, cost-effective healthcare with over one million patient members. HPN is dedicated to quality, affordable health care, and putting patients’ wellness first. About Broad Institute of MIT and Harvard Broad Institute was launched in 2004 to empower this generation of scientists to transform medicine. The Broad Institute seeks to describe the molecular components of life and their connections; discover the molecular basis of major human diseases; develop approaches to diagnostics and therapeutics; and disseminate discoveries, tools, methods, and data to the entire scientific community. Founded by MIT, Harvard, Harvard-affiliated hospitals, and the visionary Los Angeles philanthropists Eli and Edythe L. Broad, the Broad Institute includes faculty, professional staff, and students from throughout the MIT and Harvard biomedical research communities and beyond, with collaborations spanning over 100 private and public institutions in more than 40 countries worldwide. 	marvin 2024 biotech inaugural ceremony 2022 2023 nobel prize dna broad news		2023-10-04											Ilan Mochari	337	0
Q&A: Broad’s newly renamed clinical lab marks a turning point for the institute’s Genomics Platform	Since the founding of the Broad Institute, Broad researchers have been conducting state-of-the-art, large-scale genome sequencing and analysis while also pioneering other ‘omics-based approaches such as proteomic and transcriptomic technologies. Ten years ago, the institute’s Genomics Platform launched a clinical lab, called the Clinical Research Sequencing Platform (CRSP), to offer high-quality molecular tests that can be used in a clinical setting. Now CRSP is changing its name to Broad Clinical Labs in part to raise awareness around how it can bring large-scale ‘omic approaches to the clinic and help realize the technologies’ potential for improving human health. We spoke with Niall Lennon, chief scientific officer and chair of the board of BCL, to learn more about the reasoning behind the name change and what it signifies for genomics and the Broad. Lennon is an institute scientist and director of the Genomics Platform at the Broad, where he is also an associate director of the Gerstner Center for Cancer Diagnostics. Q: What is Broad Clinical Labs? Broad Clinical Labs is a wholly owned, non-profit subsidiary of the Broad that offers services to external groups in both the research and clinical realms. BCL will continue to do what CRSP was doing, which is to offer high-scale, high-complexity ‘omics services, such as genome sequencing, proteome profiling, and translational analyses. BCL will partner with Broad and other organizations that want to sequence large numbers of genomes for things like genetic risk screening in newborns and adults, whole genome sequencing-based clinical diagnoses, clinical trials, and large-scale research projects. The Genomics Platform’s laboratory offerings and teams will continue as before, as will the way we partner with Broad-based investigators to support research studies. Q: Why are you changing the name to Broad Clinical Labs now? Over the years, our teams have become adept at taking powerful approaches like sequencing and scaling them up so that they’re accessible and cost-effective for our clients in the scientific and medical communities. More and more, we’re encountering groups who want to do genomic or other ‘omic profiling of a large population, but they want to do it in a way that also allows some return-of-results to participants or can integrate with electronic health records. Outside of our local community, not many people know that Broad actually has these capabilities. The current name of our clinical laboratory, CRSP, is not connected to Broad in an obvious way, and is sometimes confused with CRISPR. We felt that the time was right to rebrand to help us raise awareness and expand access to these kinds of services that are not currently offered by traditional commercial vendors. We plan to offer these services more broadly because they are central to our mission of advancing the science and making these technologies useful for the clinical community, and to the Broad’s mission to advance discovery and biomedical science for improved therapeutics and diagnosis. We will also continue to work with technology partners to advance the science of novel molecular tests and explore ways to maximize their clinical utility. We want to get these tests out into the world. Q: What kind of clinical services will the BCL support? Broad Clinical Labs intends to partner with groups looking for large-scale analyses, for example, a biobank that needs to sequence 10,000 genomes for a clinical study or a pharmaceutical company conducting a clinical trial involving thousands of people. We also hope to enable other studies that require large numbers of clinically validated measurements, such as efforts to develop polygenic scores using population-level data or to advance methods for newborn risk screening. Q: What advances made this possible at Broad? The capabilities and teams we have built in the Genomics Platform and the CRSP lab have enabled us to sequence and analyze more than 240,000 human genomes for All of Us Research Program, so far. When the pandemic hit, CRSP also allowed us to quickly establish a COVID diagnostic lab that went on to deliver nearly 38 million diagnostic test results in a three-year period. The success of those efforts allowed us to invest even more in our people and infrastructure, such as building out our professional interpretation teams and regulatory teams. We learned how to operate at a scale we’d never attempted before, and the COVID lab helped us hone our skills in interacting with hundreds of entities, such as hospitals, schools, and employers. We want to build on that success by establishing the BCL, so that we can deliver even more options to more partners who want high-quality, high-complexity services from a trusted team at the Broad. In doing so, we hope to increase the use of these cutting-edge technologies at scale in the clinical realm and to help improve clinical studies, research, and care. Q: Will this change the way that Broad Institute researchers collaborate with the Genomics Platform? While researchers outside the Broad who partner with us will only notice the name change, Broad-based investigators will continue to work with us in the same way as before, through the Genomics Platform. We will continue to offer the same cutting-edge services and expert guidance to those researchers as we’ve offered in the past. 	genomics lab newly institute cancer renamed biomedical rebrand biobank broad news		2023-10-03											Leah Eisenstadt	338	0
Broad Clinical Labs established to expand clinical services	"The Genomics Platform at the Broad Institute of MIT and Harvard has been one of the world’s leading academic genome sequencing centers since the days of the Human Genome Project. For the last decade, these services have included clinical sequencing and other molecular assays through its wholly-owned subsidiary, the Clinical Research Sequencing Platform. Now renamed Broad Clinical Labs (BCL), the lab is poised to further accelerate the power of ’omics technologies in clinical research, screening, and diagnostics. BCL supports large-scale projects for which results need to be generated under a clinical quality system, such as analyses for clinical trials, biobank profiling, and other projects where results may be returned to participants or integrated into health records. The team’s focus includes biomarker discovery, population genomics, genetic risk screening for newborns and adults, direct-to-patient research studies, and clinical diagnostics. The ability to scale up these services enables BCL to make them accessible and cost-effective for clients in the scientific and medical communities, while encouraging data-sharing throughout industry and academia. “We are excited to introduce the newly-named Broad Clinical Labs as a significant milestone in our mission to transform human health,” said Todd Golub, director of the Broad Institute and member of BCL’s board. “BCL is well-positioned to provide molecular assays that will have a profound impact in the clinical realm.” During the pandemic, the lab’s high-throughput system for COVID-19 testing enabled it to process more than 37.5 million tests throughout Massachusetts and the northeastern US, in service of public health needs. The lab also recently demonstrated its ability to operate at scale by sequencing more than 240,000 human genomes for the National Institutes of Health’s All of Us program, which aims to collect genetic and medical information from one million people in the US to build a diverse health database. ""We knew that the team at Broad Clinical Labs offered unrivaled expertise in genomic sequencing and a steadfast commitment to driving innovations in the field. By partnering with Broad, we are able to deliver sequencing of the highest caliber as part of our groundbreaking newborn screening service,” said Hans Keil, co-founder and CEO of Nurture Genomics. BCL further functions as a “learning laboratory,” developing and translating new technologies and novel molecular assays. The lab validates these high-complexity ’omics technologies, enabling broader access to them for both the research and clinical communities. “Our experience in rapidly scaling up COVID-19 diagnostics and other services has demonstrated that we can play a valuable role in this space, leveraging our unique resources to create access where there may have been little to none,” said Niall Lennon, chief scientific officer and chair of the board of BCL. “We’ve grown our capabilities to a point where we can significantly contribute to clinical research, clinical trials, population screening, and high-complexity diagnostics.” "	genomics expand biomarker labs established harvard clinical broad genomes biobank broad news		2023-10-03											Broad Communications	339	0
Scientists reveal cellular changes unique to early Alzheimer’s disease	Most Alzheimer’s disease research on human brain tissue has studied postmortem samples, making it difficult for scientists to discern the earliest events in the brain that might have triggered the buildup of plaques and the death of neurons. Knowing the molecular changes in neurons, glia, and other brain cells around plaques during the early phases of the disease could help scientists design treatments that work best when given early. Now, in a study appearing today in Cell, a team led by researchers at the Broad Institute of MIT and Harvard has analyzed an assembly of rare brain tissue samples from 52 living patients with varying degrees of other Alzheimer’s-related changes in the brain — including 17 individuals who were later clinically diagnosed with the disease. The scientists identified a suite of changes in cells unique to the early stages of Alzheimer’s, including some not seen before in animal studies. The team discovered a brief hyperactive state in a specific group of neurons that was associated with their death in later stages of the disease, and also increased inflammatory processes in immune cells called microglia as the disease progressed. Neurons are thought to produce the plaque-forming protein called amyloid beta, and the researchers found evidence for this in their data. They also found for the first time that another brain cell type, oligodendrocytes, which produce insulating sheaths around nerve fibers in the brain, may also contribute to plaque formation. A better understanding of how these cells spur the growth of plaques could one day help researchers identify new targets for Alzheimer’s drugs. The study is a result of close collaboration with Ville Leinonen, a neurosurgeon and professor from the University of Eastern Finland who has spent more than a decade collecting and studying brain tissue samples from patients who underwent routine surgeries for other neurological conditions and agreed to provide a small amount of brain tissue and other samples for research. “This was just a really rich opportunity to peer into the actual workings of cells with minimal artifacts and see what they're doing in the context of amyloid,” said Evan Macosko, senior author on the study, an institute member at the Broad, and associate professor and attending psychiatrist at Massachusetts General Hospital. Beth Stevens, an institute member at the Broad, an associate professor at Harvard Medical School, and a research associate in neurobiology at Boston Children’s Hospital, was a co-author on the study as well. “This was a really great synergy of computational, wet lab, and clinical work,” said Tushar Kamath, co-first author on the study and an MD/PhD student in Macosko’s lab when the study began. “It took a decade of neurosurgeries, patient involvement, thoughtful analyses, and really useful experiments. We couldn’t have done this study if any one of those things hadn’t happened.” Vahid Gazestani, a research scientist in Macosko’s lab when the study began and now a senior computational scientist at Johnson & Johnson, was the other co-first author on the study. An early look Cells — and in particular, neurons — change rapidly after losing their supply of oxygen postmortem, potentially making it difficult for scientists to accurately study how they work when just looking at postmortem samples. Macosko was discussing these limitations with other researchers at a neuroscience meeting five years ago when a colleague suggested he speak with Leinonen. Leinonen was studying early Alzheimer’s disease and normal pressure hydrocephalus (NPH), a neurological disorder characterized by excess fluid around the brain. He had a collection of brain tissue samples obtained from NPH patients during routine surgeries to reduce excess brain fluid. He’d collected other samples such as cerebrospinal fluid from the same patients, and followed the cohort over time, recording clinical data such as whether or not patients developed Alzheimer’s. Macosko knew samples from these living patients presented a rare chance to observe cells exposed to the initial stages of Alzheimer’s pathology. Over the next few years, his team used single-nucleus RNA sequencing, which maps gene expression in individual cell nuclei, to analyze the brain tissue. By cross-checking this data with Leinonen’s clinical notes and integrating with previous single-cell postmortem and mouse studies, the researchers identified key changes in various cell types at the early stages of the disease. “These samples gave us a high-quality anchor to reliably identify cell types in all the other datasets,” said Gazestani. “This whole integrative analysis was feasible because of the quality and the depth of the dataset that we had.” Capturing cell changes Researchers have long assumed that neurons produce the amyloid protein, but this has been difficult to prove in human tissue. In the new study, Macosko’s team found that neurons showed gene expression signatures associated with amyloid production. For the first time, they also observed the same signature in oligodendrocytes. “This is exciting because there are lots of ways you can make amyloid accumulate in the brain in mouse studies, but now we’ve seen what’s actually happening in a human,” Macosko said. The researchers also observed a hyperactive population of neurons in the upper layer of the brain. This group of neurons die early in the disease, and Macosko thinks that future studies could show that this hyperactivity precipitates more widespread loss of neurons in patients. 	alzheimer neuroscience neurosurgeon cellular neurosurgeries changes scientists disease psychiatrist broad news		2023-09-28											Allessandra DiCorato	340	0
Broad Institute welcomes Kedrick Perry as new Chief Equity Officer	"Kedrick Perry has joined the Broad Institute of MIT and Harvard as chief equity officer. He is a member of the executive leadership team and oversees the Inclusion, Diversity, Equity, and Allyship (IDEA) Office, directing the continuation of Broad’s critical equity and inclusion priorities. Perry comes to Broad from Loyola University New Orleans, where he served as vice president for equity and inclusion, leading university-wide efforts to support and sustain inclusive excellence. “Kedrick will help strengthen all the great work going on at Broad to create deeper and more meaningful inclusion and engagement,” said Todd Golub, director of the Broad Institute. “He brings a wealth of knowledge and insight and I look forward to partnering with him as we continue to build a diverse and inclusive community and culture."" “I'm tremendously excited and honored to be joining Broad,” Perry said. “For me, this job represents the culmination of almost two decades of work promoting DEI, access, and opportunity. I absolutely love working in DEI, even with all of its challenges, and I hope my passion for creating environments in which all community members can be their authentic selves and thrive is contagious."" ""Kedrick is an accomplished leader with extensive experience leading equity and inclusion efforts at complex academic institutions. His passion and enthusiasm for expanding opportunity, knowledge, and access across diverse groups shined through in our conversations, and we're thrilled that he'll oversee the continuation of Broad's important DEI work,"" said Lex Jackson-Presley, chief people officer at Broad. Perry brings more than 15 years of experience working on and leading institutional equity and inclusion efforts at academic institutions. He has focused on strategic planning and providing access and opportunity in complex, decentralized organizations, including recruiting, retaining, and mentoring highly talented and diverse graduate student populations. Perry earned a bachelor’s degree from the University of North Carolina, Chapel Hill, a master’s in public administration from North Carolina State University, and a doctorate in higher education administration from the University of Virginia, where he studied logic modeling and academic motivation. He began doing diversity, equity, and inclusion (DEI) work early in his career. While pursuing his doctoral degree, Perry served as assistant director of graduate diversity programs at the University of Virginia, where he designed and implemented diversity initiatives to promote cross-cultural dialogue. After receiving his doctorate, Perry joined Suffolk University as director of the Prelaw Undergraduate Scholars Program and the McNair Post-Baccalaureate Achievement Program. For the prelaw program, he recruited undergraduate students from diverse backgrounds and developed and delivered programs that prepared students to apply for and succeed in law school and the legal profession. He also developed and gave bias training for faculty, staff, and law student mentors. For the McNair program, he led efforts to prepare underrepresented, low-income, and first-generation undergraduates for success in doctoral studies. Perry then worked as head of diversity and outreach for the National Science Foundation’s Center for Energy Efficient Electronics Science and executive director of the Grand Challenges Scholars Program at the University of California, Berkeley. He spearheaded initiatives that increased the participation of women, racial and ethnic minorities, people with disabilities, and first-generation individuals at the center. Most recently as vice president for equity and inclusion at Loyola University New Orleans, Perry was a member of the executive team, where he led a DEI strategic planning effort to integrate DEI into all facets of university operations. He built and led a DEI team, developed and helped implement equity plans and standards across campus, provided guidance to leadership on DEI matters, and worked with leaders, staff, and students to promote a culture of belonging. At Broad, Perry aims to bring people-oriented, inclusive, and equity-minded practices that will further engage the Broad community. “Our ability to quickly adapt and be successful requires us to bring diverse solutions to society. This is work that can only be done with the very best talent that represents the communities we aim to serve,” Perry said. Broad remains committed to honoring the legacy of René Salazar, our inaugural chief equity officer who passed away in October 2022, and to carrying his vision of inclusive excellence forward. “I honor the work that has already been done by Dr. Salazar and the IDEA Office, and I look forward to building upon this strong foundation to further our purpose, increase levels of belongingness, and strengthen the sense of community our colleagues and other stakeholders deeply value,"" Perry said. "	academic welcomes institute undergraduates harvard perry new doctoral equity doctorate broad news		2023-09-11											Broad Communications	341	0
New machine learning techniques boost predictions for virtual drug screening with less data	Scientists using machine learning tools to analyze biomedical data often turn to neural network algorithms, but before these models became popular, another simpler type of machine learning algorithm called kernel methods were commonly used. Kernel methods work by first applying straightforward operations to transform data and then training a simple model on the transformed data. Now, in a new paper recently published in Nature Communications, researchers at the Eric and Wendy Schmidt Center at the Broad Institute of MIT and Harvard have developed a new way of using kernel methods that could make them more useful for a wider range of applications, such as virtual drug screening. They came up with the first “transfer learning” techniques for kernel methods that can be successfully applied to large-scale datasets. Transfer learning allows researchers to improve machine learning models by training them on one task in a way that enhances their performance on a second task — without having to spend the time and resources training a new model for each new task. In their paper, the team showed how their transfer learning framework allowed them to predict which drugs might be most effective in certain cancer cell lines where little data is available. They did this by transferring from cell lines in which many drugs have already been tested. “Before our paper, there was no transfer learning method for kernel methods that could scale to the large datasets of most interest in the biomedical field and beyond. We’ve shown for the first time that transfer learning using kernels in these settings is possible and I think that is really exciting,” said Caroline Uhler, the senior author on the paper and a Broad core institute member, co-director of the Schmidt Center at Broad, and a professor in the Department of Electrical Engineering and Computer Science as well as the Institute for Data, Systems, and Society at MIT. The team’s key innovation was creatively adapting transfer learning methods used in neural network algorithms so that they can be applied to kernel methods. This advance could find uses in other applications. “Particularly for healthcare and biomedical applications, it's very hard to collect a lot of data for every question of interest. When you have very little data for a certain task but a related task has abundant data, this is exactly a setting where our method is effective,” said Adityanarayanan Radhakrishnan, a co-first author on the study and a Schmidt Center fellow, who worked on this study while completing his PhD as an Eric and Wendy Schmidt Center Fellow in Uhler’s lab at Broad and MIT, and is currently the George F. Carrier Postdoctoral Fellow at Harvard School of Engineering and Applied Sciences. Transferring knowledge The research team focused on kernel methods because they found in a previous paper that these performed better than typical neural network models on virtual drug screening tasks. But they wanted to make it possible for researchers to quickly reuse their kernel method algorithms to identify drugs for a wide range of cancer types without having to train a new model for each new type of cancer. They realized that transfer learning techniques are necessary for this, but because existing techniques don’t work well for kernel methods, they had to come up with new ones. They decided to take inspiration from two transfer learning techniques that work well for neural network models, which they called projection and translation. The team adapted them to work with kernel methods and then tested their approach in a virtual drug screen. The researchers analyzed performance of their transfer learning algorithms on two massive Broad datasets, one from the Connectivity Map (CMAP) and the other from the Cancer Dependency Map (DepMap). These datasets describe the effects of drugs on cancer cell lines across millions of drug and cell line combinations. The team trained their kernel method algorithms to predict either the genes expressed by a certain cell type after it was treated with a certain drug (using the CMAP dataset), or the proportion of cancer cells that survived after treatment with the same drug (using the DepMap dataset). The scientists then applied their projection and translation techniques to their model so that it could complete the second task: to predict the effect of the drug on new cancer cell lines that have much less data. The projection transformation corrects the model’s predictions on the second task by recognizing when the prediction errors are falling into categories that can be easily corrected to the right category. And the translation technique fine-tunes the model by applying a correction term that shifts the model’s predictions so that it’s more accurate on the second task. The team found that their transfer learning techniques allowed their original kernel method to be successfully “transferred” to the second task, without needing to be retrained. Compared to a new model trained only on the second task, the transfer learning techniques greatly boosted the accuracy of their model in predicting the effect of drugs for new cancer cell lines. And on a common machine learning task where the team trained their kernel method algorithms to recognize images, their approach surprisingly boosted the accuracy by up to 10 percent. Moreover, the researchers were also able to pinpoint exactly how much extra data they would need to collect to increase the performance of the model. Uhler said this could be helpful to scientists trying to decide whether it’s worthwhile to collect more data in the lab. “That's really quite exciting because you can ask ‘how much is it worth for me to have a little bit better performance of my model if I know that we’ll need to collect, say, 10 or 20 percent more data?’” said Uhler. Beyond drug screening Two additional advantages of kernel methods are that they provide interpretability as well as a quantification of how uncertain the model is on a given prediction. To take advantage of the interpretability aspect, the research team is working on pinning down the features of a drug that lead their model to predict that it will be effective. In addition, the research team hopes that the uncertainty estimates provided by their kernel approach will be helpful in identifying which new drug and cell line combinations should be screened experimentally for a more effective drug discovery pipeline. They also have plans to expand their framework to other applications, such as screening cancer genes that tumors heavily depend on for survival and might be targeted with new drugs. The team adds that their transfer learning approach for kernel methods may also open up other, unexpected applications. Because kernel methods make it easy for scientists to mathematically understand what the model is doing, they can investigate what kinds of biomedical questions will be the best fit to study. “It now gives us a more thorough or deeper understanding of transfer learning and where the power comes from, so that we can analyze which tasks it will actually work for,” said Uhler. 	researchers algorithms screening cancer learning drug biomedical virtual scientists predictions broad news		2023-09-10											Allison Whitten	342	0
New research alliance with Novo Nordisk to identify therapeutic targets for type 2 diabetes and cardiometabolic diseases	The Broad Institute of MIT and Harvard today announced a new research alliance with Novo Nordisk aimed at addressing critical unmet clinical needs in diabetes and cardiometabolic diseases. The collaboration will focus on advancing three programs over the next three years. Two programs aim to identify drug targets for clinically important subtypes of type 2 diabetes, which affects more than 37 million people in the United States alone, and one program aims to unravel the genetic roots of cardiac fibrosis, or scarring of the heart, which occurs in many cardiovascular diseases that can lead to heart dysfunction and failure. “Diabetes and cardiac fibrosis are two conditions in dire need of new therapies,” said Todd Golub, director of the Broad Institute. “These kinds of cross-disciplinary and cross-institutional collaborations that span both academia and industry are key to making the breakthroughs that patients all over the world need.” “The conditions we’re exploring impact millions of people worldwide,” said Uli Stilz, head of Novo Nordisk’s Bio Innovation Hub in Boston. “Together, we’re able to leverage the full breadth of scientific expertise between our two organizations. This collaboration has the potential not only to accelerate our understanding of the diseases, but also potentially enable scientific advancements in disease-modifying interventions — a true game changer in addressing cardiometabolic diseases.” Identifying therapeutic targets for diabetes subtypes Most current diabetes treatments target high blood sugar, in part because it has been challenging to fully understand the disease’s underlying heterogeneity, as there are many root causes for developing type 2 diabetes. The two diabetes programs will aim to identify therapeutic targets for both non-weight mediated insulin resistance and loss of beta cell function. For both patient populations, there are no safe and effective therapies for reversing disease. The aim is that this collaboration will lead to treatments that address the cause and not just symptoms of disease. The alliance will utilize state-of-the-art genetics and genomics methods to interrogate subtypes of diabetes and, with Broad’s Center for the Development of Therapeutics, probe the relationships between genes and pathways that could be therapeutic targets using large-scale cell screens. “This is potentially transformative,” said Jose Florez, who will co-direct the new initiative. Florez is an institute member at the Broad, where he directs the Diabetes Research Group. He is also chair of the Department of Medicine at MGH. “Right now we have nothing that reverses diabetes. Addressing these processes at the root, rather than simply treating the symptoms, would really change how we treat this disease.” Investigating cardiac fibrosis The third program, focused on cardiac fibrosis, will leverage genetics, genomics, and machine learning to investigate the role of cardiac fibrosis in heart disease. The team aims to identify and validate genes that could serve as therapeutic targets to inhibit or possibly reverse fibrosis — a condition that has few effective therapies. “I think this will be a framework for future investigation into the cardiometabolic space,” said Patrick Ellinor, who will co-direct the alliance as well as direct the cardiac portion. Ellinor is interim chief of cardiology and co-director of the Corrigan Minehan Heart Center at MGH. He is also an institute member and director of the Cardiovascular Disease Initiative at the Broad. “This is a real convergence of vision,” Florez said. “Novo Nordisk has decades of experience in drug development, and we at the Broad are leaders in genetics and understand the clinical space. We look forward to leveraging resources generated by the community to produce what’s really needed for treating these diseases.” The Novo Nordisk side of the collaboration is anchored through the Novo Nordisk Bio Innovation Hub, an R&D unit designed to bring cutting-edge life science innovation from bench to bedside through co-creation partnerships, with a strategic focus within cardiometabolic, rare blood, and rare endocrine disorders. 	research cardiometabolic nordisk genomics therapeutic harvard diabetes genetics insulin broad news		2023-09-06											Broad Communications	343	0
#WhyIScience Q&A: A computational biologist helps build datasets for genetic disease diagnosis	It was a chance conversation with a friend that led Katherine Chao to a career in computational biology. After graduating with a bachelor’s degree in biological sciences and spending a year teaching English in South Korea, Chao wasn’t sure what her next step would be. Her friend mentioned that the National Institutes of Health (NIH) was looking for biologists who wanted to learn coding. Chao joined the NIH as a Post-Baccalaureate Intramural Research Training Award fellow, where she processed and analyzed genomic data in the context of rare disease. After two years at the NIH, Chao landed at the Broad Institute of MIT and Harvard, where she first worked as a clinical genomic variant analyst in the Center for Mendelian Genomics. In that role, Chao continued to work in rare disease genomic analysis, identifying sections of duplicated or deleted genomic sequences called copy number variants. She is now the product manager for the Genome Aggregation Database (gnomAD), a public database of human genetic variation with over 200,000 genome and exome sequences that researchers use to study the genetic basis of human disease. In this #WhyIScience Q&A, we spoke with Chao about her career path and what makes gnomAD unique. What drew you to computational biology? My introduction to computational biology was through the world of rare disease. I was intrigued by the unfamiliarity of everything I worked on. When I was at the NIH, it was always rewarding to find a diagnosis that would be taken back to patients. Helping someone reach their goal of getting a diagnosis was a way of making an impact. And I love the puzzle aspect of coding. When there’s a problem, it’s on you to figure out how to solve it. What do you do as product manager of gnomAD? I’m responsible for maintaining the product vision, which is the goal behind building a product. Part of that is figuring out what value our product brings and deciding how to guide the product’s growth. I’m also on the steering committee for gnomAD. I ensure that everyone's opinions are heard and that we're balancing where we're heading with gnomAD as a whole. We cannot do too much of one thing and everyone has to be included. It requires effective communication to make sure the different teams working on the product are aligned. What makes gnomAD unique? Our team is all staff scientists. That's quite unique in our field. A lot of academic software is produced by trainees or graduate students during their training. So they develop something, it’s really impactful, and then it will never get supported again because they move on. But because we’re a team of staff scientists, gnomAD has continuity, and behind the scenes, my team members are doing immense amounts of quality control, which is an important but typically unrecognized part of the research process. My team in the Translational Genomics Group is really inspiring to work with. The science we do is awesome, but I really like working with such genuinely wonderful people. Everyone is kind, talented, and hardworking. Members of my team lead by example and I want to be more like that. I've learned a lot from working with them, and I feel really fortunate to have worked with other computational scientists like Julia Goodrich, Kristen Laricchia, and Mike Wilson for years. What do you like about working with gnomAD? gnomAD is exciting because we’re always working on the cutting edge. As the dataset grows, we continue to push the limits of what can be done computationally. The next gnomAD release, v4, will contain over 800,000 individuals, 25 percent of which have been inferred to have non-European genetic ancestries. The scale of v4 will allow us to release aggregate allele frequencies — how often an allele is present in the general population — for a lot of previously undiscovered variants. We'll also be much better powered in our calculations of constraint against different types of variation. Moving forward, I think the most exciting thing will be continuing to increase the diversity within the dataset. Primary investigators on our team push for diversity in gnomAD by emphasizing the need for global data-sharing and encouraging scientists to bring us their diverse datasets. Some of the researchers on the gnomAD steering committee are also working to include more diverse samples in their own sequencing projects. Why is diversifying the gnomAD database so important? More diversity means more genetic variation in the database. The more variation we have in a dataset like gnomAD, the more valuable it will be to the research community. When you’re looking for a genetic cause of a rare disease, one of the most important pieces of information you need is the aggregate allele frequency. If you don't have that piece of information, it’s much harder to find a diagnosis for a patient with a rare disease. You could dig through the literature and maybe do some functional work. But if you had the aggregate allele frequency and were able to see that a certain genetic variant was very common in the population, you could immediately exclude that variant as being a driver of severe, early-onset genetic diseases. Having greater diversity in a database of human genetic variation gives us a better understanding of the landscape of human genetic variation. This includes identifying genes and regions that are intolerant to mutation, which means you’ll hopefully be able to quickly identify and prioritize disease-causing variants for more patients. That’s the core mission at gnomAD: to produce these aggregate allele frequencies so that people are better able to functionally or clinically interpret genome variation. 	genomics diagnosis biology scientists harvard genetic biologists computational disease biologist broad news		2023-08-17											Makenzie Kohler	344	0
Nuclear DNA influences variation in mitochondrial DNA	The energy-producing machines inside cells, called mitochondria, have their own DNA that’s passed down from mother to child. The mitochondrial genome, which encodes just 13 proteins, is smaller and comparatively less well studied than the genome in the cell’s nucleus, even though mutations in mitochondrial DNA can cause a number of rare diseases. Now a new study of both mitochondrial and nuclear genomes from hundreds of thousands of people may change how scientists think about the mitochondrial genome and how it interacts with the nuclear genome. The findings could inform future studies of how this crosstalk helps mitochondria power the cell, and shed light on when they cause disease. Scientists have long known that cells can have hundreds, even thousands, of copies of the mitochondrial genome, and that this “copy number” can vary widely from one cell type to the next. There is also much variation in the sequences of all that mitochondrial DNA in a single cell, called heteroplasmy, which researchers had previously linked to rare inherited mitochondrial disease. The new study from scientists at the Broad Institute of MIT and Harvard has shown that the number of copies of the mitochondrial genome is a trait that varies from person to person and is controlled by the nuclear genome. The researchers also found that heteroplasmy is also influenced by mutations in the nuclear genome and is pervasive even among healthy people. The findings, published today in Nature, suggest that scientists can now quantitatively analyze copy number and heteroplasmy in mitochondria DNA in future studies to learn how the nuclear genome regulates levels of mitochondrial DNA across cells and tissues, how this relationship has evolved, and the connection between mitochondrial DNA and disease. The work is the first of its kind of this size to study both nuclear and mitochondrial DNA from humans of diverse ancestries to date. The research team includes co-senior author Vamsi Mootha, an institute member at the Broad, investigator at the Howard Hughes Medical Institute, investigator in the department of molecular biology at Massachusetts General Hospital; co-senior author Benjamin Neale, an institute member and co-director of the Program in Medical and Population Genetics at the Broad; and first author Rahul Gupta, an MD-PhD student jointly advised by Mootha and Neale. “We’ve long been interested in the question of how variation in the nuclear DNA influences mitochondrial DNA — it is so exciting to be able to finally answer this long standing problem,” Mootha said. “The whole project was a perfect storm of whole genome sequence availability, statistical power, and the right people with the right skills.” “Mitochondrial DNA is a very ancient molecule and has co-evolved with the nuclear genome,” Gupta said. “Our work provides a window into how these two genomes coexist and might influence each other to facilitate one of the most important processes in our cells: the pathway that generates energy.” Mitochondrial genomics The mitochondria rely on more than 1,000 proteins to function, most of which are encoded by DNA in the nucleus, so scientists have long suspected that nuclear DNA can influence mitochondrial DNA but they didn’t know how. For more than a decade, Mootha wanted to study these questions, but the team didn’t have enough human whole genome sequences to be able to do this thoroughly. Then, in 2022, the UK Biobank and the National Institutes of Health’s All of Us program published whole genome sequences, which contained often-discarded information on mitochondrial DNA sequences. Gupta and colleagues jumped on the opportunity to finally tackle these questions and gathered sequences from more than 250,000 individuals across six ancestry groups. “These large-scale biobanks with an open science philosophy are transforming what is possible in biomedical research and are accelerating the pace of discovery across the community,” Neale said. Building on a workflow previously developed by Broad Institute’s Sarah Calvo, a computational biologist in Mootha’s lab, Gupta constructed a computational pipeline to efficiently analyze variation in mitochondrial DNA within the whole genome sequences. They studied the copy number of mitochondrial DNA, mutations present within the mitochondrial DNA itself, and the places in the nuclear genome influencing these traits. They found that copy number declines consistently with age, which is in line with previous studies. But the researchers were surprised to discover, once they accounted for confounding factors, that copy number is not associated with most common diseases. This is contrary to previous studies, which did not account for these factors. The researchers found that copy number is influenced by the nucleus and pinpointed 92 locations in the nuclear genome that regulate copy number, many of which have been linked to rare genetic disorders related to mitochondrial DNA maintenance. Mitochondrial messages The team also found that heteroplasmy follows two patterns over a person’s life. Single-letter changes called single nucleotide variants accumulated with age, particularly after 70. In contrast, the number of short insertions or deletions — called “indels” — in mitochondrial DNA, which are common, stay the same throughout life and are passed down from mother to child. The researchers identified 42 different locations in the nuclear genome, including some involved in replication and maintenance of mitochondrial DNA, that influence the levels of these mitochondrial indels across the human population. “Almost every person has these mitochondrial indels, and the relative amount of those variants is influenced by variation in the nuclear genome, and that’s profound,” Mootha said. “We believe that this phenomenon represents ‘genetic interactions’ between the nuclear genome and the mitochondrial DNA that are crucial for their joint success. These influences had long been theorized to exist but we’ve now been able to pinpoint many convincing instances.” The work also suggests that the nuclear genome favors the replication of certain mitochondrial DNA variants. Mootha said that insight could one day help improve mitochondrial replacement therapies, which aim to replace disease-causing mitochondrial DNA with DNA from a healthy donor. “Our work is beginning to reveal the mechanistic logic of nuclear and mitochondrial DNA matching and could have long-term implications for new therapies that aim to prevent the transmission of mitochondrial disease,” he said. Gupta said that further study of even more genomes could reveal more subtle effects of the nuclear DNA on the mitochondrial genome. And because the scientists found that the mitochondrial DNA mutations under nuclear control are passed down from mother to child, Gupta added that he’d like to use family structure to better understand how heteroplasmy changes over generations. “A lot of people think about human genetics being applied to GWAS [genome-wide association studies] for important traits like height or type 2 diabetes,” Gupta said. “But it’s really cool to be able to apply it to gain insights into very basic cellular phenomena as well — and now we have some really exciting candidates we can use to dissect mitochondrial biology.” 	genomics mitochondrial biobanks variation diabetes genetics dna nuclear influences biobank broad news		2023-08-16											Allessandra DiCorato	345	0
A surprising new role for a major immune regulator	A signaling protein known as STING is a critical player in the human immune system, detecting signs of danger within cells and then activating a variety of defense mechanisms. STING is primarily on the lookout for DNA, which can indicate either a foreign invader such as a virus or damage to the host tissue or cell. When STING detects that danger signal, it can turn on at least three different pathways — one leading to interferon production, one to non-canonical autophagy (involved in recycling cell components and clearing pathogens), and a third to formation of the inflammasome, a complex of proteins that activates inflammatory responses. The mechanism by which STING stimulates interferon production is well characterized, but it has not been understood how it activates the other two processes. Now, a team of MIT, Massachusetts General Hospital (MGH), Broad Institute of MIT and Harvard, and Harvard Medical School (HMS) researchers has discovered how STING activates those two pathways. They found that STING has a surprising and previously unknown function: It can act as an ion channel that allows protons to leak out of an organelle known as the Golgi body. This makes it the first human immune sensor that can translate danger signals into ion flow. “Arriving at this new idea that STING is a proton channel required connecting prior findings by other labs that either STING or proton flux could activate the inflammasome and non-canonical autophagy, which led us to hypothesize that STING initiates or mediates proton flux to trigger both downstream processes,” said Nir Hacohen, an institute member at Broad, a professor of medicine at MGH and HMS, and a senior author of the study. “Because of its importance to host immunity, there is a great interest in developing drugs that can activate or suppress STING activity, and the discovery of STING’s ion channel activity will provide new ways to think about designing therapeutics to modulate STING,” said Darrell Irvine, the Underwood-Prescott Professor at MIT with appointments in the departments of Biological Engineering and of Materials Science and Engineering; a member of MIT’s Koch Institute for Integrative Cancer Research and the Ragon Institute of MGH, MIT, and Harvard; and a senior author of the study. MIT biology PhD student Bingxu Liu and Rebecca Carlson PhD ’23, a recent graduate of the Medical Engineering and Medical Physics program through the Harvard-MIT Division of Health Sciences and Technology, are the lead authors of the paper, which appears in Science. Paul Blainey, the Karl Van Tassel Associate Professor of Biological Engineering at MIT, a core institute member of Broad, and a member of the Koch Institute, is also an author of the paper. A surprising role STING (short for stimulator of interferon genes) is considered one of the major factors that triggers the immune response in the context of infection, autoimmunity, and cancer. Drugs that activate STING have been developed and tested in clinical trials as cancer immunotherapy drugs that would help stimulate the immune system to destroy tumors. STING is a protein that can span membranes, and it is usually found embedded in the membrane of an organelle called the endoplasmic reticulum (ER). Once it detects DNA, it relocates to the Golgi body, where it begins to activate proteins that turn on genes required for interferon production. “People know pretty well how STING induces interferon, but how STING induces autophagy and inflammasome formation has been an open debate in the field for the last 10 years,” Liu said. Previous research has shown that both autophagy and formation of inflammasomes (large protein complexes that stimulate inflammation) can be provoked by protons leaking from cell organelles, which makes the inside of the cell more acidic. Because of that, the researchers wondered if STING might somehow induce proton leakage. To explore this possibility, the researchers labeled the Golgi with a protein that fluoresces when the pH goes up. When they treated the cells with a molecule that activates STING, the Golgi became less acidic, meaning that it was losing protons. A genetic screen minimized the possibility of another ion channel controlling this ion flow, so the researchers hypothesized that STING itself was acting as a proton channel. “In addition to its biological significance, this study is a notable example of the maturing functional genomics field, where pooled screening data are sufficiently reliable to set the direction of focused investigation — even from negative results, as was the case here,” Blainey said. After running the structure of the STING protein through a computer model that can predict whether a given protein structure might contain a pore, the researchers found that the STING protein is predicted to contain a region that resembles a pore. Serendipitously, last year a company that was seeking STING agonists (molecules that activate STING) found a new molecule that was later shown by an academic group to bind in this precise location. The MIT/Harvard team hypothesized that the agonist, known as C53, blocks the putative pore. When C53 was added to cells, protons did not leak out of the Golgi, and downstream pathways activating autophagy and inflammasome formation were not turned on, even if STING was activated through other means. However, interferon activation, which goes through a different pathway, still occurred. “For the first time, we were able to decouple these downstream processes, where we can activate interferon with C53, but inhibit those other two pathways leading to autophagy and inflammasome formation,” Carlson said. “In the context of inflammatory diseases where STING is overactivated, we can now start asking which of those molecular mechanisms is most important and contributes the most to the phenotype that we’re seeing.” Selective control In future studies, the researchers hope to use C53 to determine the relative importance of these three pathways and try to figure out which ones would be most useful to stimulate or to block to treat a variety of diseases. The U.S. Food and Drug Administration has not approved any STING agonist thus far, although multiple clinical trials are currently underway. One potential reason that other STING agonists have not made it beyond clinical trials is that the treatment can result in unwanted cell death mediated by STING. Drugs that stimulate interferon production but not cell death or other inflammatory pathways could offer a way to overcome that obstacle, according to the MIT/Harvard team. The researchers hope to explore whether STING might play a role in influencing the behavior of other cellular activities known to be controlled by ion channels. “Now that we know that STING is an ion channel, we can propose other effects that we think could occur based on this knowledge that STING does transport protons,” Carlson said. Adapted from a story published by MIT News. 	immunotherapy biology tumors cancer immune new regulator virus major surprising broad news		2023-08-07											Anne Trafton, MIT News	346	0
A look back at the first year of NeuroDev	Some of the most diverse genomes in the world come from populations of African descent. However, most genome databases lack a robust collection of these populations’ data due to a lack of representation in research. As such, people of African descent are grossly underrepresented in genetic databases worldwide. These missing data could potentially reveal the answers to questions surrounding genetics and disease, but their absence limits the ability to make scientific discoveries that could help a broader range of people. 	disease underrepresented look african neurodev genetic genetics year broad news		2023-07-20											Makenzie Kohler	347	0
A how-to for performing quantitative bioimaging 	Starting something new can be overwhelming to a person who does not know what they will need or where to start. Quantitative bioimaging, the process of obtaining quantitative data through images (sometimes thousands of them) and computational approaches, like machine learning, are relatively new to the field of microscopy. Because of its novelty and complexity, biologists who do not have a computational background can have a difficult time incorporating quantitative bioimaging into their experiments. Resources do exist to teach everything needed to perform quantitative bioimaging, however, the volume of educational materials can intimidate those who are just getting started. 	quantitative intimidate learning performing biologists microscopy bioimaging broad news		2023-07-13											Makenzie Kohler	348	0
A scientist devotes her career to tackling inequity in genomics	The small prairie town of Cottonwood, Idaho might be the last place in the world where you'd expect someone who studies global human genetic variation to grow up. But that is where Alicia Martin began her journey that would lead to a career highlighting the importance of diversity in genomics. Named for the trees that used to flank its creek, Cottonwood has two churches, a small hotel shaped like a beagle, and a restaurant where visitors stop for burgers before getting back on route 95. For decades, its population has hovered around 1,000; there are still no stoplights. While many Cottonwood kids grow up interested in farming and raising large families, Martin from a young age was curious about the world outside Idaho. She loved reading and math problems and threw herself into school. As a teenager, she moved with her mother to Spokane, a mid-sized city in eastern Washington, and later to Seattle, where she became the first in her family to attend a university. Martin went on to earn a PhD in human genetics from Stanford University. 	genomics scientist tackling decades burgers inequity genetics cottonwood career broad news		2023-07-10											Allessandra DiCorato	349	0
More diverse datasets lead to better genetic risk prediction for heart disease 	Over the past decade, researchers have been developing polygenic scores — calculations of a person’s likelihood of getting a disease based on the millions of small genetic differences across their genome. The accuracy of these scores has improved for some diseases and groups of people, but they continue to fall short for those of non-European ancestry, mainly because the genetic datasets used to calculate these scores have largely come from people of European ancestry. A new approach from a team led by researchers in the Cardiovascular Disease Initiative at the Broad Institute of MIT and Harvard and at Massachusetts General Hospital (MGH) significantly improves the accuracy of genetic risk prediction of heart disease across all ancestries. The scientists built a polygenic score using data from genetic studies involving more than 1 million people. To further improve the score, they also incorporated in their calculations genetic changes associated with 10 related traits such as blood pressure and body mass index. Their new score outperformed all existing scores in predicting risk for coronary artery disease — the leading cause of death worldwide — among participants of African, European, Hispanic, and South Asian ancestry. The approach may one day allow clinicians to identify more high-risk individuals earlier in life and recommend interventions such as cholesterol-lowering medicines or lifestyle changes that have been shown to offset and even normalize high genetic risk. Described in Nature Medicine, the results suggest that the framework can be applied to improve genetic risk prediction for other traits and diseases, too. “The ability to identify genetic risk early in life – technically possible even at birth – is powerful, because we don’t have to wait for clinical factors like elevated cholesterol to arise,” said co-senior author Amit V. Khera, who developed polygenic scores as a Merkin Institute Fellow at the Broad and is now vice president of genomic medicine at Verve Therapeutics and a cardiologist at Brigham and Women’s Hospital. “Using larger, more diverse datasets, our score can better identify individuals at high risk who would otherwise fly under the radar,” said co-senior author Pradeep Natarajan, a Broad associate member who is director of preventive cardiology and the Paul & Phyllis Fireman Endowed Chair in Vascular Medicine at MGH, and an associate professor of medicine at Harvard Medical School. Prediction progress To build the new score, the scientists gathered data on more than a million people, including nearly 270,000 individuals with coronary artery disease — far more than their previous 2018 study that analyzed only tens of thousands of individuals with the disease. With new, more diverse studies released in the past year, such as the US Veterans Affairs Million Veteran Program, the team was also able to incorporate data on more people with African, Hispanic, and South Asian ancestry. “The European-based scores developed in 2018 didn’t work so well in predicting risk for people with other ancestries,” said Aniruddh Patel, co-first author of the new study and a cardiologist and researcher in the Natarajan lab at MGH. “So the scientific community has been focusing on improving prediction across different ancestries.” In addition, Minxian (Wallace) Wang, a study co-first author and former computational biologist at the Broad, developed a pipeline to more precisely capture the influence of genetic variants with smaller impacts on heart disease risk, by prioritizing DNA changes known to influence both risk for heart disease and related traits, such as body mass index, smoking status, and blood pressure. Interestingly, about half of the score’s predictive power came from studies of heart disease itself and the other half from studies of these other risk factors. When applied to a separate dataset from individuals of diverse ancestries, the new score, called GPSMult, identified more people at the highest and lowest risk of heart disease than all previous scores. For example, those in the lowest percentile of the score had a less than 1% chance of being diagnosed with heart disease by middle age, as compared to a 16% chance for those in the highest percentile. Strikingly, the team was able to identify 3% of unaffected individuals who – based on common DNA variation alone – have a risk for a future cardiac event such as a heart attack as high as people who’ve already been diagnosed with the disease. The results demonstrate the benefits of combining traits and multi-ancestry data when calculating polygenic risk scores, and suggest that the approach could improve risk prediction for other illnesses. The scientists are continuing to refine their method by incorporating even larger, more diverse datasets, by employing new computational approaches that account for complex genome architecture, and by integrating clinical risk factors to improve the scores’ relevance for physicians. “What’s exciting is that we still haven’t reached the theoretical maximum for how good a genetic predictor for heart disease can be, so these tests will continue to get even better in coming years,” said Khera. “We also have a lot of work to do to figure out how best to integrate these tests into clinical practice and ultimately make them standard of care.” 	cardiology prediction heart genetic cardiologist scientists disease biologist better broad news		2023-07-06											Leah Eisenstadt	350	0
New image-based cellular profiling tool peers deeply into metabolic biology	The field of microscopy has advanced immensely over the last fifty years in its ability to extract both quantitative and qualitative data from microscopy images. In a paper published in Cell Genomics, researchers at the Broad Institute, Harvard Medical School, Massachusetts General Hospital, Technical School of Munich (TUM), and the University of Oxford have presented LipocyteProfiler, a new, high-throughput quantitative bioimaging tool to help bridge the gap between morphological observation and functional profiling. LipocyteProfiler is a powerful imaging technique that generates comprehensive microscopy-based profiles of cells using multiple fluorescent dyes chosen specifically for studies of cardiometabolic biology. Image analysis software captures information about more than 3,000 cellular features, providing a deep view into the impacts of genetic variants, small molecule or genetic perturbations, and more on cellular shape, structure, and function. “It moves the community from a very targeted, hypothesis-driven, unidimensional cell-based assay framework to one that allows us to survey biological processes in a cell and assign function to genes and genetic variations in an unbiased manner,” said Melina Claussnitzer, who is a Broad institute member, associate director of the institute's Novo Nordisk Foundation Center for Genomic Mechanisms of Disease, faculty of the Center for Genomic Medicine at Mass General, and the senior researcher of the study. Common genetic variants associated with cardiometabolic disease can produce phenotype changes of such small effect that they can be difficult to characterize. The current proof-of-concept study showcases how the use of a set of dyes chosen with a disease or trait in mind can illuminate cellular and subcellular behaviors at unprecedented depth and scale. LipocyteProfiler builds on the concept of image-based profiling that was first introduced in the context of morphology mapping by Cell Painting, a high-content imaging assay developed by Broad institute scientist and Imaging Platform senior director Anne Carpenter. Whereas Cell Painting labels eight general organelles or components of the cell, LipocyteProfiler uses six fluorescent dyes that together illuminate the morphology and activity of nine cellular compartments: the nucleus, nucleoli, mitochondria, endoplasmic reticulum (ER), Golgi apparatus, cytoplasmic RNA, f-actin cytoskeleton, and plasma membrane, and lipid droplets (fat-storing organelles that regulate lipids within every type of cell and which are particularly common in adipocytes). It then extracts features from images of stained cells and creates cellular profiles, categorizing cells based on patterns (often imperceptible to the human eye) that they share with other cells, which directly inform disease biology. 	genomics biology metabolic profiling harvard cellular new bioimaging lipocyteprofiler broad news		2023-06-30											Makenzie Kohler	351	0
Scientists pinpoint where thousands of individual proteins are made in intact tissue and single cells	For researchers studying how proteins can cause human disease, knowing precisely where proteins are made within cells and tissues could help them learn about their role in disease and come up with new treatments. Now, researchers at MIT and the Broad Institute of MIT and Harvard have developed RIBOmap, a technique that lets them pinpoint and visualize the precise locations of thousands of proteins being produced within an intact tissue and even individual cells. Each colored dot in a vast RIBOmap readout represents one mRNA molecule as it is being used to produce the corresponding protein — a process called translation. The method, described today in Science, provides a way for scientists to learn new details on how translation is regulated within individual cell types and how that changes in disease. In the paper, the team used RIBOmap to study the translation of more than 5,000 genes in mouse brain tissue. They found key differences between where mRNAs are made and where the corresponding proteins are being translated in several cell types, suggesting that cells are regulating translation in ways that existing transcriptomic methods, which analyze mRNA production, aren’t able to detect. “RIBOmap can reveal spatial patterns in translation at a resolution that has never before been possible,” said Xiao Wang, a core institute member and Merkin Institute Fellow at the Broad and an assistant professor of chemistry at MIT. “When we use RIBOmap to look at individual cells within tissues, we can start to discover how different cell types are regulating translation differently.” Tool for translatomics Wang and her lab recognized that scientists needed new tools that focus on translation. Researchers often use levels of mRNA as a proxy for protein levels; in general, an increase in an mRNA molecule within a cell boosts levels of the corresponding protein. However, this is not always a strong correlation: a long-lasting mRNA may be translated into protein over and over, for instance, leading to much higher levels of a protein compared to translation from a short-lived mRNA molecule. Cells also regulate rates of translation — cancer cells, for example, often turn up translation, producing more proteins than healthy cells even when they have similar levels of mRNA. To develop RIBOmap, the team started with a technique called STARmap that Wang and colleagues previously built to visualize the spatial organization of mRNA molecules within intact tissue. RIBOmap, like STARmap, uses molecular probes that bind to specific mRNA sequences in tissue and single cells. Each probe contains a unique barcode, allowing the researchers to identify each mRNA molecule. And by using a confocal microscope to analyze fluorescent signals generated by in situ sequencing reactions in the tissue sample, the team could map the location of each mRNA. While the STARmap probes can light up any mRNA molecule, the RIBOmap probes only attach to mRNA molecules that are also bound to ribosomes — the cellular machines that carry out translation. “This means we’re seeing only RNA that is actively being used to produce proteins,” said Jingyi Ren, a co-first author of the new paper and a graduate student in Wang’s lab. “This is incredibly powerful information, because we can start to draw conclusions about which RNA is actually being translated into proteins at any given time and location.” Running RIBOmap To test the utility of RIBOmap, the team used it to map where proteins were being made from 5,413 genes expressed in the mouse brain. For some genes, they found STARmap revealed high levels of the corresponding mRNA, but RIBOmap showed that the mRNA was not being actively translated in some regions of the brain. This suggests that cells in those regions are dampening translation of the protein. In neurons, Wang and her colleagues found that RIBOmap generates such high-resolution data that they could even tell where within a single neuron — the central cell body or the long, branched neurites and associated synapses — certain proteins were being made. “We think this method can be easily applied to tissues other than the brain,” said postdoctoral fellow Hu Zeng, a co-first author of the paper along with Jiahao Huang, a graduate student, both in Wang’s lab. “Because there is no genetic manipulation of cells required, it also means we can easily apply it to isolated human tissues, not just animal models.” In the future, the researchers imagine using RIBOmap to compare healthy and diseased tissue or see how drugs impact protein production within different cell types or areas of a tissue. They also plan to use the technology to investigate the basic mechanisms cells use to tune levels of translation. 	proteins transcriptomic tissue thousands cells mrnas cancer translatomics scientists broad news		2023-06-29											Sarah C.P. Williams	352	0
Inaugural Merkin Prize in Biomedical Technology awarded to Dr. Marvin Caruthers for developing technology that efficiently synthesizes DNA	Dr. Marvin H. Caruthers of the University of Colorado, Boulder, has won the inaugural Richard N. Merkin Prize in Biomedical Technology for developing an efficient, automated technology for synthesizing DNA. The chemical reactions that he discovered in the early 1980s to accurately and quickly assemble nucleotides into strands of DNA provided an essential element in the development of modern molecular medicine. Today, scientists use these reactions to produce customizable DNA and RNA molecules that enable genetic sequencing, drug and vaccine development, pathogen tests, cancer diagnostics, and many aspects of basic biomedical research. “I am honored to acknowledge the incredible and transformative impact of Dr. Caruthers’ technology on human health over the last four decades,” said Dr. Richard Merkin, founder and CEO of Heritage Provider Network, one of the country’s largest physician founded and physician owned integrated healthcare systems. “He deserves our support and recognition. I hope this prize not only raises awareness of this work, but underscores and encourages others to realize the broader importance of developing new scientific technologies to transform healthcare.” The Merkin Prize, which recognizes novel technologies that have improved human health, carries a $400,000 cash award. The prize was created by the Merkin Family Foundation and is administered by the Broad Institute of MIT and Harvard. Dr. Caruthers will be honored in a prize ceremony held this fall. 	marvin synthesizes cancer harvard dr biomedical dna scientists broad news		2023-06-28											Broad Communications	353	0
Researchers uncover new CRISPR-like system in animals that can edit the human genome	A team of researchers led by Feng Zhang at the Broad Institute of MIT and Harvard and the McGovern Institute for Brain Research at MIT has uncovered the first programmable RNA-guided system in eukaryotes — organisms that include fungi, plants, and animals. In a study in Nature, the team describes how the system is based on a protein called Fanzor. They showed that Fanzor proteins use RNA as a guide to target DNA precisely, and that Fanzors can be reprogrammed to edit the genome of human cells. The compact Fanzor systems have the potential to be more easily delivered to cells and tissues as therapeutics than CRISPR/Cas systems, and further refinements to improve their targeting efficiency could make them a valuable new technology for human genome editing. CRISPR/Cas was first discovered in prokaryotes (bacteria and other single-cell organisms that lack nuclei) and scientists including Zhang’s lab have long wondered whether similar systems exist in eukaryotes. The new study demonstrates that RNA-guided DNA-cutting mechanisms are present across all kingdoms of life. “CRISPR-based systems are widely used and powerful because they can be easily reprogrammed to target different sites in the genome,” said Zhang, senior author on the study and a core institute member at the Broad, an investigator at MIT’s McGovern Institute, the James and Patricia Poitras Professor of Neuroscience at MIT, and a Howard Hughes Medical Institute investigator. “This new system is another way to make precise changes in human cells, complementing the genome editing tools we already have.” Searching the domains of life A major aim of the Zhang lab is to develop genetic medicines using systems that can modulate human cells by targeting specific genes and processes. “A number of years ago, we started to ask, ‘What is there beyond CRISPR, and are there other RNA-programmable systems out there in nature?’” said Zhang. Two years ago, Zhang lab members discovered a class of RNA-programmable systems in prokaryotes called OMEGAs, which are often linked with transposable elements, or “jumping genes,” in bacterial genomes and likely gave rise to CRISPR/Cas systems. That work also highlighted similarities between prokaryotic OMEGA systems and Fanzor proteins in eukaryotes, suggesting that the Fanzor enzymes might also use an RNA-guided mechanism to target and cut DNA. 	researchers neuroscience human genome animals edit dna scientists genomes broad news		2023-06-28											Leah Eisenstadt	354	0
#WhyIScience Q&A: How a summer at Broad helped foster a love of research for a young scientist	Chanell Mangum’s love of science sprouted in her family’s garden. As a child growing up in Durham, North Carolina, she learned when to plant seeds, what type of soil to use, and how best to fertilize the tomatoes, zucchinis, and many other vegetables she and her family cultivated in their large backyard garden. In fifth grade, Mangum joined a Girl Scout troop and the troop leaders, who had PhDs in science or engineering, further nurtured her interests by introducing her and her fellow troop members to many STEM activities — science camps for girls, LEGO robotics competitions, DNA extractions from strawberries. Although Mangum attended the local arts high school, she was accepted into the North Carolina School of Science and Math, where she took science classes online in addition to her dance, orchestra, and other academic courses at the arts school. Mangum studied bioengineering at North Carolina Agricultural and Technical State University with the goal of getting a job in industry. But after a couple of summers working in research labs, including one summer in the lab of Broad institute director Todd Golub through the Broad Summer Research Program (BSRP) in 2021, she decided that she wanted to focus on research. Last year, she joined the Optical Profiling Platform at the Broad Institute of MIT and Harvard as a research associate through the Broad’s Biomedical Post-baccalaureate Scholars Program. She plans to apply to graduate schools this fall to pursue a PhD. As BSRP is celebrating its 20th anniversary this year, we spoke with Mangum about her career journey so far and what impact BSRP has had on it. What do you do at Broad and what have you learned the most from this experience so far? Currently I am in the Optical Profiling Platform where our main focus is to understand how cells communicate with each other and make up a tissue. To answer this question, I am doing multiplexed immunofluorescence, which allows us to image proteins in the tissue samples spatially. I help design experiments with many of our collaborators and generate data spanning many different tissue types from human brain to mouse gut. One thing that I have learned from this experience is that scientific communication is important. In this past year, I have been in many collaborations and have been able to mentor students. I have been able to explain my research to senior scientists and also to middle school students since I started working at the Broad. 	research scientist robotics love young summer phds bioengineering scientists strawberries broad news		2023-06-26											Corie Lok	355	0
Low oxygen levels restore balance and coordination in a mouse model of a movement disorder	Friedreich’s ataxia is a rare, inherited disease that causes progressive nervous system damage, impairing balance and coordination and leaving patients unable to walk by early adulthood. Now, researchers at the Broad Institute of MIT and Harvard have found that treatment with continuous hypoxia — low-oxygen conditions comparable to levels at a Mount Everest base camp — restores balance and coordination in a mouse model of Friedreich’s ataxia. With further development, the findings could inform a potential treatment that lowers oxygen levels in certain tissues in humans to reverse advanced disease. The study appeared recently in Human Molecular Genetics. “If we accept that disease stems from the interaction of genes and environment, then why not manipulate the environment?” said Vamsi Mootha, senior author of the study, an institute member at the Broad, professor of systems biology and medicine at Harvard Medical School, and professor of molecular biology at Massachusetts General Hospital. “Through a series of papers we have reported a strong interaction between genetic pathways related to energy metabolism and environmental oxygen. By attacking disease from the environment side of things, we think our quest for a hypoxia-in-a-pill approach could impact a number of genetically diverse diseases.” Mootha’s lab has been studying hypoxia as a potential treatment for rare neurological diseases since 2016. Previous work from his lab suggested that hypoxia could prevent ataxia — impaired balance and coordination — in Friedreich’s ataxia mice, and the new findings now show that the approach can even reverse it in animals with more advanced disease. The latest study also adds to a growing body of evidence that hypoxia could treat a broad range of conditions. Last month, for instance, Mootha’s team showed that a mouse model of an accelerated aging disease lived 50 percent longer and showed slower neurological decline in low-oxygen conditions. The work appeared in PLOS Biology. “Oxygen restriction is an exciting experimental modality, and it's now been shown to have pretty potent beneficial effects across multiple models of aging and disease,” said Robert Rogers, first author on the PLOS study, postdoctoral fellow in Mootha’s lab, and an instructor in the Division of Pulmonary and Critical Care Medicine at Massachusetts General Hospital. “It deserves a lot of further exploration to understand its mechanism so that we can recapitulate it in a form that’s easier to deliver, like a pill.” Treatment comparison Friedreich’s ataxia is caused by loss of a mitochondrial protein called frataxin, which helps make molecular complexes called iron-sulfur clusters required for a number of cellular pathways, including those involved in energy metabolism. Patients with Friedreich’s ataxia have fewer of these clusters than people without the disease, resulting in impaired energy production in the affected cells. In 2019, Mootha’s team found that continuously exposing young mice with Friedreich’s ataxia to 11 percent oxygen, as opposed to 21 percent at sea level, early in the disease prevented ataxia. They also found that hypoxia restored iron-sulfur cluster levels in cells. However, most patients are diagnosed later in the disease, after symptoms develop, so the researchers wanted to test whether hypoxia could reverse — rather than simply prevent — advanced disease. And because extreme hypoxia can be harmful, the scientists knew they’d have to keep optimizing the treatment. To look for other possible regimens, Mootha’s team, in their latest study, tested seven different hypoxia treatments in the same mouse model of Friedreich’s ataxia and included animals in later stages of the disease. A few treatments stood out. Intermittent hypoxia — 16 hours of 11 percent oxygen and 8 hours of 21 percent oxygen — was harmful, and mice developed cardiac stress and died more quickly than those without treatment. The group hypothesized that the animals’ red blood cell levels increased due to hypoxia, and then when exposed to normal oxygen levels, created a temporary but toxic flood of oxygen. They supported this hypothesis by using a drug that pharmacologically blocks this response. The team reported that treatment with mild hypoxia — 17 percent oxygen, equivalent to the levels in Denver — was moderately beneficial, and mice developed ataxia later than those without treatment. But the researchers were excited when they found that continuous hypoxia at 11 percent oxygen reversed neurological symptoms and ataxia, even at advanced disease. “We've shown how amenable the nervous system is to recovering from damage,” said Tslil Ast, a co-first author on the study along with Hong Wang, a research scientist in Mootha’s lab. Ast was a postdoctoral fellow in Mootha’s lab when the study began and is currently a team leader at the Weizmann Institute of Science in Israel. “Even with profound ataxia, these mice can still, under the correct therapeutic regimen, reverse course.” The treatment did not improve the disease’s cardiovascular symptoms, suggesting that more work, potentially towards a combination therapy, is needed to transform these insights into a curative treatment. In the PLOS study from last month, Mootha’s group demonstrated that the same treatment — continuous exposure to 11 percent oxygen — increased lifespan by 50 percent in mice with mutations in the Ercc1 gene that lead to accelerated aging and early death in the animals. In the future, the researchers aim to continue to uncover the full mechanism by which hypoxia alleviates ataxia, which could inform hypoxia-inspired therapies such as a pill that could decrease oxygen or blunt the body’s ability to deliver oxygen to tissues. In the meantime, Ast and Mootha say that hypoxia can be deadly if not done in a controlled clinical setting. For example, in the current work they noted that not only were intermittent regimens not helpful, but even harmful, underscoring the need for and value of continued pre-clinical testing before moving into humans. 	oxygen balance everest medicine cardiac disorder mouse disease low neurological broad news		2023-06-21											Allessandra DiCorato	356	0
Researchers identify gut microbiome signatures linked to precancerous colon polyps	Ramnik Xavier 	xavier researchers signatures colon microbiome ramnik polyps broad news		2023-06-14											MGH News And Public Affairs	357	0
UV radiation plays role in development of rare leukemia in the skin	Cancer Program 	leukemia cancer radiation program rare uv skin broad news		2023-06-13											Rob Levy, Dana-Farber Cancer Institute	358	0
Multi-ancestry study reveals genetic risk factors for two common pregnancy complications	Pregnancy complications related to hypertension, or high blood pressure, affect 15 percent of childbearing women and are a leading cause of maternal death worldwide. Without prompt diagnosis and treatment, hypertensive disorders of pregnancy (HDPs) can lead to organ failure and potentially fatal complications. But scientists lack the tools to predict, prevent, and treat them. Researchers at the Broad Institute of MIT and Harvard are beginning to uncover genetic factors contributing to gestational hypertension and preeclampsia, two common HDPs. The findings, which appeared recently in Nature Medicine, provide insight into the biological mechanisms underlying pregnancy complications and could help improve patient care. By studying previously published genomes of individuals with HDPs, the researchers identified 18 places in the genome that influence an individual’s risk of developing one of these conditions. They also developed polygenic risk scores, which distill a person’s likelihood of developing a condition down to a single number based on their genes. The scores could help doctors identify and treat at-risk individuals earlier in pregnancy with existing but underutilized strategies such as low-dose aspirin. “This is potentially an ideal use case for polygenic risk scores to refine risk assessment,” said Michael Honigberg, a co-first author on the study, associate member at the Broad, and a cardiologist at Massachusetts General Hospital. “Not only is this a population where clinical risk factors do a poor job predicting who will develop these conditions, but there’s also actually something we can do with better predictions.” The work was co-led by senior author Pradeep Natarajan, an associate member at the Broad, the director of preventive cardiology at Massachusetts General Hospital, and an assistant professor of medicine at Harvard Medical School. Buu Truong, a computational researcher and postdoctoral fellow in Natarajan’s lab, was a co-first author as well. Maternal meta-analysis Scientists have long thought that HDPs are caused in part by genetics. About one-third of a person’s risk of developing preeclampsia is estimated to stem from genetic causes, but until now, researchers weren’t sure which parts of the genome influenced risk. Honigberg, Natarajan, and their team analyzed separately the DNA of about 11,000 individuals with gestational hypertension (high blood pressure that arises during pregnancy) and 20,000 individuals with preeclampsia/eclampsia (gestational hypertension with additional symptoms such as high levels of protein in the urine and seizures, as in eclampsia). The cohort, which also included more than 400,000 controls for each condition, has the widest range of ancestries in a genome-wide association study of HDPs to date. The team identified 18 locations in the genome, associated with preeclampsia/eclampsia and/or gestational hypertension, 12 of which had not been identified previously. This suggests that a range of biological pathways related to blood vessel growth, dysregulation of the immune system, embryo development, kidney function, and hormone signaling play a role in the conditions and could be targeted by future therapies. Honigberg was particularly surprised to find that patients with lower levels of signaling by peptides produced in the heart were predisposed to developing HDPs, suggesting that doctors could use synthetic peptides — similar to some developed previously — to prevent or treat them. “The possibility that a cardiac-derived molecule influences placental development has been suggested in mice before, but this is the first human genetic confirmation of that finding,” Honigberg said. “It’s a newly appreciated phenomenon that opens a lot of future avenues of research.” The researchers also used the data to develop polygenic risk scores, which accurately predicted both preeclampsia and gestational hypertension in new patient cohorts even without conventional clinical risk factors. When used together, polygenic risk scores and risk factors identified nearly half of all patients with preeclampsia/eclampsia, up from just 18 percent pinpointed by risk factors alone. The authors say the scores could be used in a clinical setting to identify and treat at-risk patients earlier with low-dose aspirin, currently given to individuals with certain risk factors. Patients with polygenic risk of HDPs could also make lifestyle changes to minimize other sources of risk, such as obesity. In the future, the researchers plan to continue studying the function of the genetic loci identified by their analysis. Honigberg also wants to use the data to shed light on why some patients develop hypertension in multiple pregnancies and others do only once. 	cardiology complications ancestry obesity hypertension medicine genetic pregnancy factors broad news		2023-06-01											Allessandra DiCorato	359	0
Artificial intelligence system predicts consequences of disruptions to genetic networks	Patrick Ellinor 	networks genetic intelligence consequences disruptions patrick ellinor broad news		2023-05-30											Sarah C.P. Williams	360	0
#WhyIScience Q&A: A process development lead returns to her research roots	Isabella Teixeira-Soldano began her career in science sifting through mud. She had joined Néva Meyer’s lab at Clark University as an undergraduate student research assistant because she was interested in learning more about development. The lab focused on neuronal development of annelids, or saltwater worms, and she was tasked with acclimating the worms to the lab from their natural environment — the mud. At first, Teixeira-Soldano was reluctant to handle the slimy creatures, but once she saw under the microscope how annelids started from single cells and developed into larvae, then adults, Teixeira-Soldano was hooked. She realized the importance of her role in keeping the worms healthy, so she could later study their gene expression and behavior in response to different drug treatments. After graduating, Teixeira-Soldano discovered new definitions of development that intrigued her. In the summer of 2020, she joined the Broad Institute of MIT and Harvard as one of the first accessioning technicians in the COVID-19 diagnostic lab in the Broad’s Genomics Platform. She worked long shifts to help quickly deliver test results, while watching Broad engineers develop faster, more automated ways to process more COVID tests. Within a few months, she transitioned into a role as a process development associate and later a process development lead within the Klarman Cell Observatory (KCO) at Broad, which studies single cells to better understand disease progression and potential targets for treatments. Today, Teixeira-Soldano works on developing efficient processes to analyze large numbers of tissue samples at the single-cell level. In this #WhyIScience, she talks about her role as a COVID-19 lab technician, how she transitioned into a process development role, and how her definition of development has changed throughout her career. What inspired you to do research as an undergrad? When I went to school, I was set on becoming a doctor. I majored in biology and minored in chemistry, but the classes were challenging and I had a conversation with my pre-med advisor, David Thurlow, that I’ll never forget. I told him I was struggling with my classes and that I didn’t think I'd make it to medical school. And if I did, I wouldn’t be happy. Then he asked, “Well, why do you want to be a doctor?” and I responded with, “Because I want to help people.” Then he said, “You don’t have to be a doctor to help people. There are so many ways you can do that!” Before that conversation, I had never considered doing research and he gave me the extra push to try it out. During my junior year of undergrad, I found a lab at my school that studied neuronal development in annelids, which are saltwater worms. I fell in love with the research and forgot all about medical school. What did you do as a COVID-19 accessioning technician? I’d work 12-hour shifts to ensure the COVID-19 samples we received were in good condition before the testing process. Then, I started working in shipping and handling, where I was responsible for shipping testing kits to schools, hospitals, and other places. From there, I started working on the science side of things — adding lysis buffer to deactivate the virus, extracting the virus from the sample, and then moving it to a qPCR machine to get a positive or negative result. What surprised you about working as a COVID-19 technician at the Broad? I had just graduated and I never thought I’d be able to help anyone during the pandemic — that was unexpected and rewarding. I was also surprised that my coworkers had such different backgrounds. I was expecting everyone to be recent college graduates, but many were in the midst of career transitions and hoping to break into the sciences. After many 12-hour shifts, we really got to know each other, and we all worked really well together. We still keep in contact, and many have transitioned to being full-time employees in different labs at the Broad. How did you transition to your current role and what do you do? As a COVID-19 technician, I was working under contract, but I wanted something that had more structure, like a 9-to-5 job, so I applied to a position at the KCO as a process development associate. During the interview, I realized their work with single-cell technology was similar to my undergraduate research, which I loved, and I got really excited in the interview. A few months after being hired, I was promoted to Process Development Lead and now my position helps implement single-cell technology in projects related to inflammatory disease. We are studying biopsied tissue from patients with colorectal cancer, Crohn’s disease, ulcerative colitis, and other inflammatory diseases to see which genes are elevated or lowered. Our hope is that studying changes in gene expression will lead to a better understanding of the progression of these diseases and better ways of treating them. What does development mean to you? Has that changed? At first, I saw development as how cells communicate to divide and build a living thing. When I got into development of automation at the Genomics Platform, it came to mean how machines and people communicate with each other to work together. Now, I think development is a mixture of both definitions because I use technological processes to learn about how cells communicate to either cause a disease. What inspires you to keep working in your field? One of the reasons I like development is because I can see it. One of my favorite things is looking under the microscope to see cells. Similarly, I had a hard time understanding the computational side of things at first, but as I've learned more, I can see how the process I worked on helped obtain necessary data. Seeing the final result of something I've helped develop is really cool. I love working on medical samples that are provided by patients because it motivates me to find them an answer or even a potential treatment. Advancing technologies have created many ways to target diseases. Yet there’s still room to improve that process. And I bet in 10 years, there’s going to be a better way to do science and I’ve loved playing a little part in that. 	research biology process roots lab returns cancer chemistry development colitis broad news		2023-05-30											Andrea Tamayo	361	0
Study finds how a genetic variant raises diabetes risk through an unexpected mechanism	Melina Claussnitzer 	study claussnitzer genetic diabetes melina risk unexpected broad news		2023-05-25											Andrea Tamayo	362	0
Alumni of the Broad’s summer research programs discuss the personal and professional impact of their time at Broad	The alumni of the Broad Institute’s summer research programs for college and high school students have gone on to a wide range of positions, from lab heads in academia to industry research jobs and studies at top-notch universities and medical schools. While their paths have diverged, they say the Broad Summer Research Program (BSRP; for college students from across the US) and the Broad Summer Scholars Program (BSSP; for Boston-area high school students) helped give them the skills, support, and the passion they needed to propel themselves into careers in STEM. For many, the programs have been pivotal in their career development, exposing the students to new opportunities for the first time, enabling them to picture themselves as scientists, and teaching them skills they continue to use today. To mark the 20-year anniversary of BSRP and the 10-year anniversary of BSSP, we spoke with more than a dozen alumni about the impact these programs have had on their careers and lives. Here is what they told us. 	research professional alumni summer scholars students universities scientists personal broad news		2023-05-24											Broad Communications	363	0
Broad’s summer research programs for high school and college students have helped shape the careers of more than 300 young scientists	High school junior Michelle Mantilla was ready for something new. Mantilla loved biology but had never done research before. She got her first taste as part of the 2017 cohort of the Broad Summer Scholars Program (BSSP), a six-week-long research program for high school students at the Broad Institute of MIT and Harvard. She loved the lab so much that she decided to apply for and return two years later as an undergraduate student for the nine-week long Broad Summer Research Program (BSRP), where she studied the genetic risk factors contributing to type 2 diabetes among people of Mexican and Latin American descent. Mantilla, who is from a low-income background, was the first in her family to attend college. Before coming to Broad, she had never met anyone with a PhD. Now a senior in chemical and biological engineering at MIT, Mantilla credits the programs with helping transform her idea of a career in science from just an interesting possibility to something real and attainable. She began to see herself as a scientist and now aims to pursue an MD-PhD and work in translational medicine. After her graduation this spring, she will work in an immunology lab at Stanford Medicine studying T cells for clinical applications. “This was an incredibly formative experience that showed me that scientists and researchers can look like me,” Mantilla said. Mantilla is one of more than 340 alumni of BSRP and BSSP, which this year are celebrating their 20th and 10th anniversaries, respectively. The programs have helped students from a range of backgrounds not only acquire the skills they need to succeed in the lab, but also feel a sense of belonging in those spaces. The impact of the programs is visible in the alumni; more than 80 percent have gone on to pursue biomedical research or graduate programs at top-tier institutions. Many have become medical students, industry scientists, or professors, and include three Rhodes Scholars, 12 Gates Millennium Scholars, two Fulbright Scholars, four Goldwater Scholars, one Intel International Science and Engineering Fair winner, and other award recipients. Some said that the experience taught them how to think and solve problems independently. For others, the programs helped them discover which part of science they enjoyed the most and the wide range of career paths open to them. (A 2017 Boston Globe editorial pointed out that three out of the eight African-American women interested in science who had earned U.S. Rhodes Scholarships in the prior decade participated in the Broad’s programs.) 	college biology 300 summer harvard students diabetes mexican scientists broad news		2023-05-24											Allessandra DiCorato	364	0
Cells can use uridine, a component of RNA, as a source of energy	Our bodies burn carbohydrates, proteins, and fat for fuel, and now, researchers at the Broad Institute of MIT and Harvard and the University of Lausanne have discovered another important energy source for cells: uridine, the chemical building block unique to RNA. Their new findings reveal that cells ranging from healthy immune cells to cancer cells can process uridine from RNA like they do with sugar to sustain growth when glucose is limited. Previous research has shown that a diet rich in uridine leads to obesity and pre-diabetes in mice, but scientists didn’t know if or how cells convert RNA into ATP, the molecule cells burn for energy. In a study published today in Nature Metabolism, the research team pinpointed a biochemical pathway that cells use to break down uridine-derived sugar that they then burn for energy. The researchers say that targeting this pathway could potentially help treat cancers and metabolic disorders such as diabetes, and could help tune the immune response. The findings are from a team including co-senior authors Alexis Jourdain, an assistant professor at the University of Lausanne in Switzerland; and Vamsi Mootha, an institute member at the Broad, a professor of systems biology and medicine at Harvard Medical School, and a professor of molecular biology at Massachusetts General Hospital; as well as co-first authors Owen Skinner, a postdoctoral fellow in Mootha’s lab, and Joan Blanco-Fernández, a PhD student in Jourdain’s lab. “Living organisms are packed with RNA, generally in the form of ribosomes, and therefore uridine,” said Jourdain, who was a postdoctoral fellow in Mootha’s lab when the study began. “You can eat a low-carb diet, but as long as there is RNA in your food, your body is able to convert that RNA into sugar.” Uridine as food As a researcher in Mootha’s lab, Jourdain wanted to know which genes and pathways cells might use to stay alive when nutrients are limited. Using a genetic screen, Jourdain and his colleagues found that the expression of two genes, UPP1 and UPP2, dramatically increases the growth of cells in media without glucose. These genes encode enzymes that help break down uridine, and cells expressing UPP1 and UPP2 grew when uridine was their only food source. Jourdain wondered if cells could also derive uridine from RNA, so he added RNA to a dish of cancer cells in sugar-free media. To his surprise, the cells grew, suggesting they were able to process uridine even when it’s part of RNA. “I remember telling my friends that I did a crazy experiment where I tried to feed cells with RNA,” Jourdain remembers. “I did not think this was going to work — I was very surprised to see the cells grow.” To further probe how common the pathway is across cancer types, the team used PRISM, a technology at the Broad that allows for high throughput screening of hundreds of human cancer cell lines. Together with David Fisher’s team at Harvard Medical School, they found that glycolysis from uridine is especially prominent in melanoma, but also occurs in other cancers. The scientists also showed that this process occurs in immune cells, where uridine may help sustain the immune response by providing energy to cells. Gene expression patterns documented by other researchers suggest the pathway likely occurs in blood cells, the lungs, brain, and kidneys. Though glycolysis from RNA and uridine is widespread, it is not regulated by the cell, which could have important implications in metabolic diseases. This lack of regulation means that cells continue to burn RNA or uridine even when they don’t need energy, and could help explain why diets high in uridine are associated with obesity, fatty liver disease, and pre-diabetes in mice. Harnessing glycolysis from uridine Jourdain sees a range of ways to exploit this pathway for therapeutic purposes. Scientists could inhibit the pathway in cancers to starve them, or dial back the activity of overactive immune cells in autoimmune disorders. Conversely, they could promote the pathway to boost immune cells that fight pathogens. Jourdain’s lab is now working to find inhibitors of the pathway and their physiology in animal models. Ultimately, they’d also like to study the effects of RNA-rich foods on obesity in humans. “We’ve been underestimating how much energy we can get from eating nucleotides,” Jourdain said. “This is really a new player in the field of metabolism and nutrition.” 	cancers cells rna cancer obesity diabetes atp uridine energy component broad news		2023-05-17											Allessandra DiCorato	365	0
Viruses in the guts of centenarians may help them resist pathogens	New research suggests that centenarians — people who live to be at least 100 — have a diverse collection of viruses in their gut that could help protect them from infectious diseases. The findings, published today in Nature Microbiology, shed light on some of the biological pathways that may help centenarians live long, healthy lives. In the study, a team of researchers led by Joachim Johansen, Ramnik Xavier, Simon Rasmussen, and Damian Plichta at the Broad Institute of MIT and Harvard analyzed the gut viromes — communities of viruses within the gut — from 195 individuals from Japan and Sardinia. They found that centenarians had a greater diversity of bacteria and viruses in their guts. They also found that viruses found in centenarians increased the ability of the healthy gut bacteria to break down sulfate, which could help preserve the gut’s ability to fight bacterial infections. The study adds to a growing body of evidence showing that the interactions between bacteria, viruses, and fungi in the gut play an important role in preventing age-related conditions. “This snapshot of how the virome interacts with gut microbiomes could tell us about how microbial and viral ecology evolves over the lifetime of a person,” said Ramnik Xavier, a core institute member, director of the Immunology Program, and co-director of the Infectious Disease and Microbiome Program (IDMP) at the Broad. “This offers an important starting point for uncovering the mechanisms behind how the gut ecosystem maintains health.” Xavier is also a professor of medicine at Harvard Medical School and Massachusetts General Hospital. He is a co-senior author on the study along with Rasmussen, a visiting scientist at the Novo Nordisk Foundation Center and an associate professor at the University of Copenhagen; and Plichta, a group leader in the IDMP at Broad. A closer look Previously, Xavier’s team found that intestinal bacteria in centenarians produced unique bile acids that could help keep infections at bay. Other researchers have found that bacteriophages — or viruses that infect bacteria — had an effect on cognition and memory in mice. But the role that the viruses play in the gut and aging in humans remains unknown, in part because viral DNA can be difficult to extract from complex samples. In this study, the Broad team collaborated with researchers from Japan, including Kenya Honda, a professor of microbiology and immunology at the Keio University School of Medicine in Tokyo. They also teamed up with researchers from the University of Copenhagen to apply a deep-learning based framework to pull out viral information from metagenomes, or the DNA present in complex samples such as stool. By homing in on viral genomes, the researchers compared the viromes of young adults over 18, older adults over 60, and centenarians aged 100 and over. The data came from previously published datasets in Japan and Sardinia, two regions with an unusually high proportion of centenarians. In centenarians, the team found not only more diverse bacteria and viruses, but also more viruses in the lytic life cycle, during which viruses are active and burst and kill the bacteria they infect — a phase that is more common in infants than adults. At least a quarter of the viruses found in centenarians encoded genes that support key stages of sulfate metabolism. The researchers think this could help sustain the integrity of the mucosal barrier, a highly selective collection of tightly-bound cells that allows the body to absorb nutrients in the gut while keeping bacteria and toxins at bay. “It’s extremely exciting to work on the microbiome, including viruses, because there's so much diversity and so many unknown species,” Plichta said. “There's always something to discover, whether that’s new organisms or previously uncharacterized enzymes.” 	immunology viruses help pathogens bacteria bacteriophages microbiology centenarians genomes guts broad news		2023-05-15											Allessandra DiCorato	366	0
How one lab uses machine learning to solve a key gene therapy problem	When Ben Deverman joined the Broad Institute of MIT and Harvard in 2018, he was tackling a longstanding challenge in his research. Deverman had spent years at CalTech building a technology that could quickly screen large numbers of inactivated adeno-associated virus (AAV) — viral vectors that don’t cause disease but are engineered to deliver potentially life-changing gene therapies to specific cells in the body. Deverman’s technology could find AAVs that can cross the blood-brain barrier and deliver their therapeutic cargo to the brain — a potential way to treat certain neurological disorders. But it had only identified AAVs that work in mice. To find AAVs that can deliver gene therapies in humans and to specific organs in the body such as the brain, Deverman knew he needed a new approach. He wanted to harness machine learning — computational tools that can be “trained” to analyze and detect important signals in data — to find AAVs that could one day lead to more and better gene therapies. It wasn’t until Deverman met and joined forces with Broad researcher and machine learning expert Fatma Elzahraa Eid that the Deverman lab was finally able to work toward this elusive goal. 	gene lab machine viral learning harvard therapy caltech virus broad news		2023-05-08											Alex Viveros	367	0
